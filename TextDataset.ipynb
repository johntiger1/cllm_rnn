{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.ascii_letters + string.digits\n",
    "string.printable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for the dataset:\n",
    "import torch\n",
    "# class for text-datasets\n",
    "# Jama, NEJM and lancet\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import unicodedata\n",
    "class TextDataset(Dataset):\n",
    "\n",
    "    SPECIAL_CHARS = [None, \"\\n\"]\n",
    "    def __len__(self):\n",
    "        return len(self.total_examples)\n",
    "        pass\n",
    " \n",
    "    # generates tensors for the vocab\n",
    "    # i.e. assigns a number to each character\n",
    "    # Q: possible to do one-pass?\n",
    "    def make_vocab(self):\n",
    "        \n",
    "        self.char2index = {}\n",
    "        self.index2char = {}\n",
    "        index = 0\n",
    "        with open(self.text_file) as file:\n",
    "            for line in file:\n",
    "                for char in line:\n",
    "                    if char not in self.char2index:\n",
    "                        self.char2index[char] = index\n",
    "                        self.index2char[index]  = char\n",
    "                        index+=1\n",
    "        \n",
    "        for char in self.SPECIAL_CHARS:\n",
    "#             print(\"this is the char\")\n",
    "            if char not in self.char2index:\n",
    "                self.char2index[char] = index\n",
    "                self.index2char[index] = char\n",
    "                index += 1\n",
    "        \n",
    "        print(self.char2index[None])\n",
    "        # potentially need to add 2 for the None and \\n characters\n",
    "        self.vocab_size = len(self.char2index)\n",
    "    \n",
    "    # this allows the model to handle all possible strings passed into it!!\n",
    "    def full_vocab(self):\n",
    "        self.char2index = {}\n",
    "        self.index2char = {}\n",
    "        index = 0\n",
    "        all_letters = string.printable \n",
    "        for char in all_letters:\n",
    "            if char not in self.char2index:\n",
    "                self.char2index[char] = index\n",
    "                self.index2char[index]  = char\n",
    "                index+=1\n",
    "                \n",
    "        for char in self.SPECIAL_CHARS:\n",
    "#             print(\"this is the char\")\n",
    "            if char not in self.char2index:\n",
    "                self.char2index[char] = index\n",
    "                self.index2char[index] = char\n",
    "                index += 1\n",
    "                \n",
    "        self.vocab_size = len(self.char2index)   \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def generate_tensor_for_char(self, char):\n",
    "        temp = torch.zeros(1, self.vocab_size)\n",
    "        temp[0][self.char2index[char]] = 1 \n",
    "        return temp\n",
    "\n",
    "#     def generate_char_from_tensor(self, char):\n",
    "#         temp = torch.zeros(self.vocab_size, 1)\n",
    "#         temp[self.char2index[char]][0] = 1 \n",
    "#         return temp\n",
    "    def lineToTensor(self,line):\n",
    "        tensor = torch.zeros(len(line), 1, self.vocab_size)\n",
    "#         print(line)\n",
    "        for li, letter in enumerate(line):\n",
    "            tensor[li][0][self.char2index[letter]] = 1\n",
    "        return tensor\n",
    "    \n",
    "    # wrap the lines!\n",
    "    def train_example_builder(self, line):\n",
    "        tensor = torch.zeros(len(line), 1, self.vocab_size)\n",
    "        for li, letter in enumerate(line):\n",
    "            tensor[li][0][self.char2index[letter]] = 1\n",
    "        return tensor\n",
    "      \n",
    "#     could do more of a common build api\n",
    "    def get_None_tensor(self):\n",
    "        tensor = torch.zeros(1, 1, self.vocab_size)\n",
    "        tensor[0][0][self.char2index[None]] = 1\n",
    "        return tensor\n",
    "    \n",
    "    def list_to_tensor(self, input_list):\n",
    "        tensor = torch.zeros(len(input_list), 1, self.vocab_size)\n",
    "        for elt in input_list:\n",
    "            tensor[li][0][self.char2index[letter]] = 1\n",
    "            \n",
    "#     def get_training_pair(self, line):\n",
    "        \n",
    "        \n",
    "    \n",
    "    def get_new_line_tensor(self):\n",
    "        tensor = torch.zeros(1, 1, self.vocab_size)\n",
    "        tensor[0][0][self.char2index[\"\\n\"]] = 1\n",
    "        return tensor\n",
    "\n",
    "        \n",
    "#         tensor[li][0][self.char2index[letter]] \n",
    "#         temp \n",
    "    def unicodeToAscii(self,s):\n",
    "        return ''.join(\n",
    "            c for c in unicodedata.normalize('NFD', s)\n",
    "            if unicodedata.category(c) != 'Mn'\n",
    "            and c in self.char2index\n",
    "        )\n",
    "\n",
    "    def __init__(self, text_file,  convert_to_ascii = True):\n",
    "        self.string = string\n",
    "        self.text_file = text_file\n",
    "\n",
    "        self.training_examples = []\n",
    "\n",
    "        total_inputs = []\n",
    "        total_outputs = []\n",
    "        \n",
    "#         make the vocab\n",
    "        self.full_vocab()\n",
    "        \n",
    "        with open(text_file) as file:\n",
    "            for raw_line in file:\n",
    "                \n",
    "                line = self.unicodeToAscii(raw_line) if convert_to_ascii else raw_line\n",
    "                # zero pad to start\n",
    "                \n",
    "                \n",
    "#                 think about how to make this a vector or tensor line! \n",
    "#                 print()\n",
    "                \n",
    "#                 inputs = self.get_None_tensor() + line_to_tensor(line)\n",
    "#                 inputs = [None] + [x for x in line]\n",
    "                inputs = self.lineToTensor([None] + [x for x in line])\n",
    "                \n",
    "                targets = self.lineToTensor([x for x in line] + [\"\\n\"])  # we need a 0 as well!\n",
    "\n",
    "                # append: will be a list of list (of lines)\n",
    "                # extend: will be a list of lines\n",
    "                total_inputs.append(inputs)\n",
    "                total_outputs.append(targets)\n",
    "\n",
    "        assert len(total_inputs) == len(total_outputs)\n",
    "        \n",
    "        # this is now a LIST of lists!\n",
    "        self.total_examples = list(zip(total_inputs, total_outputs))\n",
    "        \n",
    "        #                 for char in line:\n",
    "        # how many chars before the target? or all chars before the target?\n",
    "        # so we simply pair up x with [x+1] i think\n",
    "        # ok, and then we iterate them in the loader?\n",
    "        #                     inputs = [x for x in ]\n",
    "        #                     targets = []\n",
    "\n",
    "        # we should also have some big list of entries \n",
    "\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    # ok, now let us just try adding the transforms\n",
    "    # actually the transforms should take responsibility for all of the vocab stuff\n",
    "    \n",
    "    # number of items in the dataset. This involves a rather large computation!\n",
    "    # we can either do a feed forward cllm in the style of bengio, or we can just \n",
    "    # do the RNN approach (as specified by Sean Robertson in his tutorial)\n",
    "\n",
    "    # the indices should represent examples inside the list\n",
    "    # one strange thing is the following: we need to precompute al the indices earlier, imo, and then simply return the list\n",
    "    # at that element! (perhaps with some transforms!)\n",
    "    def __getitem__(self, index):\n",
    "        return self.total_examples[index]\n",
    "\n",
    "        # build a list, return elements from that list? we need to internally keep track of some index\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# ok, so it works now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = TextDataset( \"data\\\\names\\\\English.txt\", False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(abc.char2index[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.generate_tensor_for_char(\"a\")\n",
    "# abc.index2char[2]\n",
    "abc.lineToTensor(\"abcd\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for (a,b) in abc:\n",
    "    pass\n",
    "#     this should give two lines/tests\n",
    "#     print(a,b)\n",
    "#     print()\n",
    "    \n",
    "#     realistically, we should also have it as tensors/vectors\n",
    "# finally, we should also have some way where we run the rnn forward and \n",
    "#  iteratoring over the set, does not consume the elements! It is not a genertor! Rather, we simply index into the elements we would like\n",
    "for(a,b) in abc:\n",
    "    pass\n",
    "#     print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_x = [None] + [\"e\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ok, so now let's just do the stuff\n",
    "# the RNN actually makes one-character over predictions! \n",
    "# rnn_forward is a utility function that does a lot of stuff\n",
    "len(char_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok, so now we can start building the network that will process these!!\n",
    "# simply: iterate the dataset, and run train on it, do the log likelihood and etc.\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "    \n",
    "n_hidden = 128\n",
    "\n",
    "\n",
    "rnn = RNN(abc.vocab_size, n_hidden, abc.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.lineToTensor(\"we\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# WE NEED THIS LINE TO RESET THE RNN!!\n",
    "rnn = RNN(abc.vocab_size, n_hidden, abc.vocab_size)\n",
    "learning_rate = 0.0005 # If you set this too high, it might explode. If too low, it might not learn\n",
    "#  we had to set it a big lower to force convergence\n",
    "\n",
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(rnn.parameters(), lr = 0.01)\n",
    "\n",
    "# returns the loss for a line\n",
    "\n",
    "def train(input_tensor, target_tensor):\n",
    "    \n",
    "        \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "#     print (input_tensor)\n",
    "    \n",
    "#     print(\"changed3\")\n",
    "#     print(input_tensor[1])\n",
    "    criterion = nn.NLLLoss()    \n",
    "    hidden = rnn.initHidden()\n",
    "    loss = 0\n",
    "    rnn.zero_grad()\n",
    "#     print(input_tensor.size())\n",
    "#     print(target_tensor[0])\n",
    "#     print(target_tensor)\n",
    "    for i in range(input_tensor.size()[0]):\n",
    "        output, hidden = rnn(input_tensor[i], hidden)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         find where the one is:\n",
    "# \n",
    "#         torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "        max_tensor = torch.argmax(target_tensor[i])\n",
    "#         print(max_tensor)\n",
    "        ind = (torch.argmax(target_tensor[i])).item()\n",
    "#         print(\"this the target\")\n",
    "#         print(target_tensor[i])\n",
    "#         print(ind)\n",
    "        true_target_tensor = torch.tensor([ind], dtype=torch.long)\n",
    "    \n",
    "#     Evaluate the loss on each character!\n",
    "        loss += criterion(output, true_target_tensor)\n",
    "        \n",
    "#         expects JUST a single target class:\n",
    "\n",
    "#     print (\"loss for i \" + str(loss.item()))    \n",
    "#         print()\n",
    "# should be do the loss on each thing, or each batch! no, we should accumulate it! \n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "#     for p in rnn.parameters():\n",
    "#         p.data.add_(-learning_rate, p.grad.data)\n",
    "\n",
    "    return output, loss.item()\n",
    "\n",
    "# why not run this just on all the tensors!! \n",
    "\n",
    "# then, we just call it with the dataset class, and then just iterate everything!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.index2char[0]\n",
    "abc.index2char[1]\n",
    "\n",
    "abc.char2index[\"A\"]\n",
    "\n",
    "# ok some weird stuff here...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (x,y) in abc:\n",
    "#     print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del rnn\n",
    "# rnn = RNN(abc.vocab_size, n_hidden, abc.vocab_size)\n",
    "\n",
    "epoch_loss = 0\n",
    "# loss every k iters\n",
    "# \n",
    "total_loss = 0\n",
    "total_length  = 0\n",
    "epoch_length = 0\n",
    "\n",
    "\n",
    "num_epochs = 0\n",
    "for k in range(num_epochs ):\n",
    "    \n",
    "    for i,(x,y) in enumerate(abc):\n",
    "    #     print(x)\n",
    "    #     print(x)\n",
    "    #     print(y)\n",
    "        _, loss = train(x,y)\n",
    "        epoch_loss += loss\n",
    "        epoch_length += x.size()[0]\n",
    "        total_loss += loss\n",
    "        total_length += x.size()[0]\n",
    "\n",
    "    #     print(i)\n",
    "    #     abc = i\n",
    "#         if i % 100 == 0:\n",
    "#             print (\"loss for {} is {}\".format(i,other_loss/100))\n",
    "#             other_loss = 0\n",
    "    \n",
    "    print(\"epoch {} loss is {}\".format(k, epoch_loss/i))\n",
    "    print(\"per character loss is {}\".format(epoch_loss/epoch_length))\n",
    "    epoch_loss = 0\n",
    "    epoch_length = 0\n",
    "#     ideally: we would be able to compute the quintile losses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the entire model under the given filename\n",
    "def save_model(model,filename):\n",
    "    torch.save(model, filename)\n",
    "    \n",
    "    return\n",
    "\n",
    "# Saves the model parameters only (for maximum usability)\n",
    "\n",
    "def save_model_params(model, filename):\n",
    "\n",
    "    torch.save(model.state_dict(), filename)\n",
    "\n",
    "    return filename\n",
    "\n",
    "#  ideally, I could get per character loss, then I would also be able to get the total expected loss\n",
    "# so: we want to get total loss, then divide it by all the length of the number of examples we saw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_params(filename):\n",
    "    model = RNN(abc.vocab_size, n_hidden, abc.vocab_size)\n",
    "    model.load_state_dict(torch.load(filename))\n",
    "    return model #vs return model.eval()??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"draft.pt\"\n",
    "\n",
    "if False:\n",
    "\n",
    "    filename = save_model_params(rnn, \"draft.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (i2h): Linear(in_features=229, out_features=128, bias=True)\n",
       "  (i2o): Linear(in_features=229, out_features=101, bias=True)\n",
       "  (softmax): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model = load_model_from_params(filename)\n",
    "eval_model.eval() # this is a mutating operation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# returns the loss for the entire line (requires normalization for comparison)\n",
    "def get_loss_on_line(rnn, line):\n",
    "    input_tensor =  abc.lineToTensor([None] + [x for x in line])\n",
    "    target_tensor = abc.lineToTensor([x for x in line] + [\"\\n\"])\n",
    "    criterion = nn.NLLLoss()    \n",
    "    hidden = rnn.initHidden()\n",
    "    loss = 0\n",
    "    rnn.zero_grad()\n",
    "    \n",
    "    \n",
    "#     print(input_tensor.size())\n",
    "#     print(target_tensor[0])\n",
    "#     print(target_tensor)\n",
    "    for i in range(input_tensor.size()[0]):\n",
    "        output, hidden = rnn(input_tensor[i], hidden)\n",
    "        \n",
    "        \n",
    "        # had to do this simply because of how the NLLL and CrossEntropy are defined\n",
    "        max_tensor = torch.argmax(target_tensor[i])\n",
    "        ind = (torch.argmax(target_tensor[i])).item()\n",
    "        true_target_tensor = torch.tensor([ind], dtype=torch.long)\n",
    "    \n",
    "#     Evaluate the loss on each character!\n",
    "        loss += criterion(output, true_target_tensor)\n",
    "    \n",
    "    return loss.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.155973434448242\n"
     ]
    }
   ],
   "source": [
    "# out = eval_model)\n",
    "\n",
    "# so there's a couple possibilities: we can have jim and ask to predict as well as just get the loss of the example\n",
    "# out = train()\n",
    "# ()\n",
    "#lineToTensor\n",
    "\n",
    "# get it as tensors, then run it, then do loss addition\n",
    "\n",
    "STRING_TO_TEST =  \"David\"\n",
    "print(get_loss_on_line(eval_model, STRING_TO_TEST )/len(STRING_TO_TEST ))\n",
    "\n",
    "# we now want to implement sampling:\n",
    "#  is that useful though? \n",
    "# will it be good?\n",
    "# instead, we can also try and get text for the inputs \n",
    "#  then train on that, then run it on some numerical numbers\n",
    "\n",
    "# visualization would be super useful \n",
    "# for pretty printing, we can colour the terminal output\n",
    "# otherwise, we will need to somehow encode the colour so that it is output to the file\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  print(\"\\x1b[31m\\\"red\\\"\\x1b[0m\")\n",
    "\n",
    "# if no thresholding, then we should at least like somehow graphically display?\n",
    "# no,... this is a different concern. Don't put frontend and backend together! (or visualization and etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Fore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mBilly\n",
      "\n",
      "loss2.187842686971029\n",
      "\u001b[34mJoe\n",
      "\n",
      "loss2.927530288696289\n",
      "\u001b[34mBob\n",
      "\n",
      "loss3.550493001937866\n",
      "\u001b[34mThornton\n",
      "\n",
      "loss1.9199905395507812\n",
      "\u001b[34mElliot\n",
      "\n",
      "loss2.500835418701172\n",
      "\u001b[34mRandom\n",
      "\n",
      "loss2.389070783342634\n",
      "\u001b[34mderivative\n",
      "\n",
      "loss3.6175897771661933\n",
      "\u001b[31m';3[39\n",
      "\n",
      "loss8.677899496895927\n",
      "\u001b[31mj0hn_person1\n",
      "\n",
      "loss5.2926177978515625\n",
      "\u001b[34mEnglish\n",
      "\n",
      "loss2.915396213531494\n",
      "\u001b[31mwkijkq\n",
      "\n",
      "loss6.433131626674107\n",
      "\u001b[34mWord\n",
      "\n",
      "loss1.381985855102539\n",
      "\u001b[31mAdditional_names\n",
      "\n",
      "loss4.289423325482537\n",
      "\u001b[31mQuixotic\n",
      "\n",
      "loss4.087853749593099\n",
      "\u001b[31m24uirfejkfk\n",
      "\n",
      "loss6.100430170694987\n",
      "\u001b[34mJavier\n",
      "\n",
      "loss2.5835887363978793\n",
      "\u001b[34mJason\n",
      "\n",
      "loss2.2196717262268066\n",
      "\u001b[31mJiao\n",
      "\n",
      "loss4.139523696899414\n",
      "\u001b[34mChen\n",
      "\n",
      "loss2.830333137512207\n",
      "\u001b[34mAkshay\n",
      "\n",
      "loss2.998241424560547\n",
      "\u001b[34mMbaay\n",
      "\n",
      "loss3.496740976969401\n",
      "\u001b[34mGovind\n",
      "loss3.070594151814779\n"
     ]
    }
   ],
   "source": [
    "# print(Fore.RED + \"yoo\")\n",
    "\n",
    "# print(Fore.BLUE + \"haha\")\n",
    "\n",
    "# if on average more than twice as high loss on this sample, then we should flag it for further review\n",
    "THRESHOLD =  1.8332151545300774 * 2\n",
    "\n",
    "\n",
    "# some more powerful model: uses LSTM as well as additional fields and operators!\n",
    "# ok, so now let us just iterate the text file\n",
    "with open(\"data\\\\test-cases.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        example_loss = get_loss_on_line(eval_model, line)/len(line )\n",
    "        if (example_loss > THRESHOLD):\n",
    "            print(Fore.RED + line)\n",
    "        else:\n",
    "            print(Fore.BLUE + line)\n",
    "        \n",
    "        print(\"loss\" + str(example_loss))\n",
    "    \n",
    "# perhaps we should train on google news corpus for a little while..\n",
    "# this \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")\n",
    "\n",
    "sentences = reuters.raw().splitlines()\n",
    "# print(reuters.raw())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# these are not exactly tokenized on sentences; but that is OK!\n",
    "sentences[:100]\n",
    "\n",
    "with open(\"reuters_news.txt\", \"w\") as file:\n",
    "    file.write(reuters.raw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reuters dataset has umlauts and other non-standard characters, so we should try and account for that! \n",
    "# also: we should try and do a sort of full merge: merge between the train dataset and test dataset vocabs\n",
    "# other than that, we can just apply a regularizer to both sets, to get out the processed data\n",
    "# for now, let's just apply a regularization\n",
    "import time\n",
    "\n",
    "start = time.\n",
    "reuters_dataset = TextDataset( \"reuters_news.txt\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191926\n"
     ]
    }
   ],
   "source": [
    "print(len(reuters_dataset))\n",
    "from tqdm import tqdm\n",
    "def general_train_function(dataset):\n",
    "# del rnn\n",
    "# rnn = RNN(abc.vocab_size, n_hidden, abc.vocab_size)\n",
    "\n",
    "    epoch_loss = 0\n",
    "    # loss every k iters\n",
    "    # \n",
    "    loss_per_k = 0\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_length  = 0\n",
    "    epoch_length = 0\n",
    "\n",
    "\n",
    "    num_epochs = 10\n",
    "    \n",
    "    for k in range(num_epochs ):\n",
    "\n",
    "        for i,(x,y) in enumerate(tqdm(dataset)):\n",
    "        #     print(x)\n",
    "        #     print(x)\n",
    "        #     print(y)\n",
    "            _, loss = train(x,y)\n",
    "            epoch_loss += loss\n",
    "            epoch_length += x.size()[0]\n",
    "            total_loss += loss\n",
    "            total_length += x.size()[0]\n",
    "            loss_per_k += loss\n",
    "        #     print(i)\n",
    "        #     abc = i\n",
    "            if i % 100 == 0:\n",
    "                print (\"loss for {} is {}\".format(i,loss_per_k/100))\n",
    "                loss_per_k = 0\n",
    "                \n",
    "\n",
    "        print(\"epoch {} loss is {}\".format(k, epoch_loss/i))\n",
    "        print(\"per character loss is {}\".format(epoch_loss/epoch_length))\n",
    "        epoch_loss = 0\n",
    "        epoch_length = 0\n",
    "#     ideally: we would be able to compute the quintile losses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# WE NEED THIS LINE TO RESET THE RNN!!\n",
    "rnn = RNN(abc.vocab_size, n_hidden, reuters_dataset.vocab_size)\n",
    "learning_rate = 0.0005 # If you set this too high, it might explode. If too low, it might not learn\n",
    "#  we had to set it a big lower to force convergence\n",
    "\n",
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(rnn.parameters(), lr = 0.01)\n",
    "\n",
    "# returns the loss for a line\n",
    "\n",
    "def general_train(input_tensor, target_tensor):\n",
    "    \n",
    "        \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "#     print (input_tensor)\n",
    "    \n",
    "#     print(\"changed3\")\n",
    "#     print(input_tensor[1])\n",
    "    criterion = nn.NLLLoss()    \n",
    "    hidden = rnn.initHidden()\n",
    "    loss = 0\n",
    "    rnn.zero_grad()\n",
    "#     print(input_tensor.size())\n",
    "#     print(target_tensor[0])\n",
    "#     print(target_tensor)\n",
    "    for i in range(input_tensor.size()[0]):\n",
    "        output, hidden = rnn(input_tensor[i], hidden)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         find where the one is:\n",
    "# \n",
    "#         torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "        max_tensor = torch.argmax(target_tensor[i])\n",
    "#         print(max_tensor)\n",
    "        ind = (torch.argmax(target_tensor[i])).item()\n",
    "#         print(\"this the target\")\n",
    "#         print(target_tensor[i])\n",
    "#         print(ind)\n",
    "        true_target_tensor = torch.tensor([ind], dtype=torch.long)\n",
    "    \n",
    "#     Evaluate the loss on each character!\n",
    "        loss += criterion(output, true_target_tensor)\n",
    "        \n",
    "#         expects JUST a single target class:\n",
    "\n",
    "#     print (\"loss for i \" + str(loss.item()))    \n",
    "#         print()\n",
    "# should be do the loss on each thing, or each batch! no, we should accumulate it! \n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "#     for p in rnn.parameters():\n",
    "#         p.data.add_(-learning_rate, p.grad.data)\n",
    "\n",
    "    return output, loss.item()\n",
    "\n",
    "# why not run this just on all the tensors!! \n",
    "\n",
    "# then, we just call it with the dataset class, and then just iterate everything!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                       | 0/191926 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 0 is 2.3144712829589844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                              | 98/191926 [00:01<56:46, 56.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 100 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                             | 197/191926 [00:03<51:45, 61.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 200 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                             | 297/191926 [00:05<58:19, 54.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 300 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                            | 400/191926 [00:06<56:27, 56.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 400 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                          | 500/191926 [00:08<1:00:44, 52.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 500 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                          | 596/191926 [00:10<1:01:01, 52.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 600 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                            | 696/191926 [00:12<56:45, 56.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 700 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                            | 796/191926 [00:14<56:50, 56.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 800 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                          | 899/191926 [00:16<1:09:34, 45.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 900 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|                                                                            | 999/191926 [00:18<57:18, 55.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 1000 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|                                                                           | 1098/191926 [00:19<53:24, 59.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 1100 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|                                                                           | 1197/191926 [00:21<53:48, 59.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 1200 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|                                                                           | 1297/191926 [00:23<59:38, 53.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 1300 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|                                                                           | 1397/191926 [00:25<55:17, 57.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 1400 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|                                                                           | 1495/191926 [00:27<56:28, 56.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 1500 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|                                                                           | 1598/191926 [00:28<55:19, 57.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 1600 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|                                                                           | 1696/191926 [00:29<39:35, 80.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 1700 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|                                                                           | 1794/191926 [00:31<56:05, 56.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 1800 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|                                                                           | 1896/191926 [00:33<56:43, 55.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 1900 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|                                                                           | 1998/191926 [00:34<42:33, 74.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 2000 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|                                                                           | 2096/191926 [00:36<49:03, 64.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 2100 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|                                                                           | 2197/191926 [00:37<50:38, 62.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 2200 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|                                                                           | 2298/191926 [00:39<53:45, 58.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 2300 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|                                                                           | 2398/191926 [00:41<53:00, 59.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 2400 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|                                                                         | 2500/191926 [00:43<1:11:54, 43.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 2500 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|                                                                           | 2592/191926 [00:44<33:12, 95.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 2600 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|                                                                         | 2696/191926 [00:46<1:06:36, 47.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 2700 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|                                                                           | 2799/191926 [00:48<56:13, 56.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 2800 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                          | 2894/191926 [00:49<52:35, 59.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 2900 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                          | 2998/191926 [00:51<52:12, 60.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 3000 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                          | 3094/191926 [00:52<46:06, 68.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 3100 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                          | 3199/191926 [00:54<56:07, 56.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 3200 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                          | 3299/191926 [00:56<53:10, 59.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 3300 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                          | 3396/191926 [00:57<40:41, 77.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 3400 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                          | 3496/191926 [00:59<57:36, 54.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 3500 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                          | 3598/191926 [01:01<47:15, 66.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 3600 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                          | 3699/191926 [01:02<56:53, 55.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 3700 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                        | 3797/191926 [01:04<1:06:26, 47.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 3800 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                          | 3900/191926 [01:06<51:35, 60.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 3900 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                          | 3995/191926 [01:08<59:14, 52.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 4000 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                          | 4097/191926 [01:10<55:29, 56.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 4100 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                        | 4200/191926 [01:12<1:00:02, 52.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 4200 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                        | 4300/191926 [01:14<1:08:44, 45.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 4300 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                          | 4399/191926 [01:16<59:23, 52.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 4400 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                          | 4498/191926 [01:17<54:25, 57.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 4500 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                          | 4595/191926 [01:19<49:16, 63.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 4600 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                        | 4694/191926 [01:21<1:04:56, 48.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 4700 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                        | 4797/191926 [01:22<1:04:31, 48.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 4800 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|                                                                          | 4894/191926 [01:24<49:50, 62.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 4900 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|                                                                        | 4999/191926 [01:26<1:09:28, 44.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 5000 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|                                                                        | 5100/191926 [01:29<1:22:58, 37.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 5100 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|                                                                        | 5195/191926 [01:31<1:06:43, 46.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 5200 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|                                                                        | 5297/191926 [01:37<1:46:31, 29.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 5300 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|                                                                        | 5399/191926 [01:40<1:27:23, 35.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 5400 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|                                                                        | 5500/191926 [01:43<1:25:29, 36.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 5500 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|                                                                       | 5596/191926 [01:47<2:11:04, 23.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 5600 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|                                                                       | 5697/191926 [01:50<1:29:15, 34.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 5700 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|                                                                       | 5799/191926 [01:52<1:25:47, 36.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 5800 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|                                                                       | 5900/191926 [01:54<1:23:10, 37.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 5900 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|                                                                       | 5995/191926 [01:56<1:10:56, 43.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 6000 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|                                                                       | 6098/191926 [01:59<1:25:19, 36.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 6100 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|                                                                       | 6200/191926 [02:02<1:30:24, 34.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 6200 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|                                                                       | 6297/191926 [02:04<1:20:45, 38.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 6300 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|                                                                       | 6396/191926 [02:06<1:18:15, 39.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 6400 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|                                                                       | 6499/191926 [02:09<1:08:58, 44.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 6500 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|                                                                       | 6595/191926 [02:11<1:29:49, 34.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 6600 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|                                                                       | 6700/191926 [02:13<1:10:32, 43.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 6700 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                       | 6799/191926 [02:15<1:22:35, 37.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 6800 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                       | 6899/191926 [02:19<1:58:27, 26.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 6900 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                       | 6996/191926 [02:21<1:16:05, 40.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 7000 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                       | 7099/191926 [02:23<1:10:09, 43.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 7100 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                       | 7199/191926 [02:25<1:08:38, 44.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 7200 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                       | 7300/191926 [02:28<1:08:27, 44.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 7300 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                       | 7400/191926 [02:30<1:06:29, 46.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 7400 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 7497/191926 [02:32<49:57, 61.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 7500 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                       | 7596/191926 [02:34<1:10:55, 43.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 7600 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                       | 7696/191926 [02:36<1:18:45, 38.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 7700 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                       | 7796/191926 [02:39<1:27:31, 35.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 7800 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                        | 7896/191926 [02:41<46:03, 66.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 7900 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                       | 7999/191926 [02:43<1:05:54, 46.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 8000 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                       | 8099/191926 [02:45<1:13:33, 41.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 8100 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                      | 8199/191926 [02:47<1:14:07, 41.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 8200 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                        | 8298/191926 [02:49<45:11, 67.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 8300 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                        | 8400/191926 [02:51<59:07, 51.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 8400 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                      | 8498/191926 [02:53<1:06:27, 46.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 8500 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                      | 8599/191926 [02:55<1:03:51, 47.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 8600 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|                                                                      | 8697/191926 [02:57<1:03:52, 47.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 8700 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|                                                                        | 8797/191926 [02:58<58:16, 52.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 8800 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|                                                                        | 8898/191926 [03:00<56:11, 54.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 8900 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|                                                                        | 8996/191926 [03:02<56:39, 53.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 9000 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|                                                                        | 9095/191926 [03:04<58:50, 51.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 9100 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|                                                                        | 9200/191926 [03:06<59:53, 50.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 9200 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|                                                                        | 9300/191926 [03:08<55:46, 54.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 9300 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|                                                                      | 9396/191926 [03:10<1:14:32, 40.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 9400 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|                                                                      | 9500/191926 [03:13<1:15:35, 40.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 9500 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|                                                                        | 9599/191926 [03:15<57:05, 53.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 9600 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|                                                                      | 9698/191926 [03:17<1:21:41, 37.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 9700 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|                                                                        | 9797/191926 [03:19<56:01, 54.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 9800 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|                                                                      | 9896/191926 [03:22<1:18:02, 38.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 9900 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|                                                                      | 9996/191926 [03:25<1:04:50, 46.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 10000 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|                                                                     | 10095/191926 [03:27<1:06:55, 45.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 10100 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|                                                                       | 10198/191926 [03:29<54:21, 55.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 10200 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|                                                                       | 10300/191926 [03:30<56:23, 53.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 10300 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|                                                                     | 10398/191926 [03:33<2:14:39, 22.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 10400 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|                                                                     | 10497/191926 [03:38<1:21:58, 36.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 10500 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|                                                                     | 10599/191926 [03:41<1:23:36, 36.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 10600 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|                                                                     | 10700/191926 [03:44<1:48:50, 27.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 10700 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|                                                                     | 10797/191926 [03:47<1:07:36, 44.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 10800 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|                                                                    | 10899/191926 [03:49<1:33:08, 32.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 10900 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|                                                                      | 11000/191926 [03:51<44:17, 68.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 11000 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|                                                                    | 11100/191926 [03:53<1:16:45, 39.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 11100 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|                                                                      | 11199/191926 [03:55<57:40, 52.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 11200 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|                                                                      | 11300/191926 [03:57<57:49, 52.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 11300 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|                                                                      | 11399/191926 [03:59<54:57, 54.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 11400 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|                                                                    | 11495/191926 [04:01<1:04:47, 46.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 11500 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|                                                                      | 11600/191926 [04:03<58:38, 51.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 11600 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|                                                                    | 11698/191926 [04:05<1:06:26, 45.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 11700 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|                                                                    | 11799/191926 [04:07<1:13:49, 40.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 11800 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|                                                                    | 11896/191926 [04:09<1:02:07, 48.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 11900 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|                                                                    | 12000/191926 [04:11<1:01:06, 49.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 12000 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|                                                                    | 12095/191926 [04:13<1:23:58, 35.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 12100 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|                                                                      | 12200/191926 [04:15<50:17, 59.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 12200 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|                                                                    | 12299/191926 [04:18<1:26:06, 34.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 12300 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|                                                                    | 12398/191926 [04:20<1:23:22, 35.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 12400 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|                                                                    | 12495/191926 [04:23<1:25:47, 34.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 12500 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|                                                                    | 12598/191926 [04:25<1:04:13, 46.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 12600 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|                                                                    | 12697/191926 [04:28<1:27:26, 34.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 12700 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|                                                                    | 12798/191926 [04:30<1:08:02, 43.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 12800 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|                                                                    | 12898/191926 [04:33<1:13:10, 40.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 12900 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|                                                                    | 12999/191926 [04:35<1:16:54, 38.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 13000 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|                                                                    | 13097/191926 [04:38<1:23:50, 35.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 13100 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|                                                                    | 13200/191926 [04:41<1:27:47, 33.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 13200 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|                                                                    | 13299/191926 [04:43<1:19:35, 37.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 13300 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|                                                                    | 13397/191926 [04:46<1:22:19, 36.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 13400 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|                                                                   | 13494/191926 [04:49<1:22:06, 36.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 13500 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|                                                                   | 13597/191926 [04:52<1:17:24, 38.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 13600 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|                                                                   | 13700/191926 [04:55<1:24:01, 35.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 13700 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|                                                                   | 13795/191926 [04:57<1:14:56, 39.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 13800 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|                                                                   | 13896/191926 [04:59<1:16:07, 38.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 13900 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|                                                                   | 13999/191926 [05:02<1:34:57, 31.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 14000 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|                                                                   | 14100/191926 [05:05<1:33:19, 31.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 14100 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|                                                                   | 14199/191926 [05:08<1:23:48, 35.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 14200 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|                                                                   | 14296/191926 [05:11<1:11:38, 41.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 14300 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|                                                                   | 14397/191926 [05:14<1:29:22, 33.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 14400 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|                                                                   | 14494/191926 [05:16<1:34:21, 31.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 14500 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|                                                                   | 14598/191926 [05:19<1:28:53, 33.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 14600 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|                                                                   | 14695/191926 [05:22<1:08:47, 42.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 14700 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|                                                                   | 14796/191926 [05:24<1:03:57, 46.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 14800 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|                                                                   | 14899/191926 [05:26<1:11:56, 41.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 14900 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|                                                                   | 14996/191926 [05:28<1:02:57, 46.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 15000 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|                                                                     | 15096/191926 [05:30<56:29, 52.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 15100 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|                                                                   | 15199/191926 [05:32<1:02:11, 47.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 15200 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|                                                                   | 15298/191926 [05:34<1:02:48, 46.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 15300 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|                                                                   | 15398/191926 [05:37<1:11:13, 41.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 15400 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|                                                                   | 15497/191926 [05:39<1:25:28, 34.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 15500 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|                                                                   | 15596/191926 [05:41<1:00:03, 48.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 15600 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|                                                                    | 15700/191926 [05:44<57:19, 51.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 15700 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|                                                                    | 15800/191926 [05:46<51:50, 56.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 15800 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|                                                                   | 15895/191926 [05:48<1:00:02, 48.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 15900 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|                                                                   | 16000/191926 [05:50<1:04:17, 45.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 16000 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|                                                                   | 16100/191926 [05:52<1:05:53, 44.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 16100 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|                                                                    | 16197/191926 [05:54<57:10, 51.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 16200 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|                                                                  | 16295/191926 [05:56<1:02:00, 47.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 16300 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|                                                                  | 16399/191926 [05:58<1:10:24, 41.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 16400 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|                                                                    | 16496/191926 [06:00<49:28, 59.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 16500 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|                                                                    | 16596/191926 [06:02<53:50, 54.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 16600 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|                                                                    | 16698/191926 [06:04<55:07, 52.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 16700 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|                                                                    | 16799/191926 [06:06<50:35, 57.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 16800 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|                                                                  | 16894/191926 [06:08<1:15:02, 38.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 16900 is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|                                                                  | 16952/191926 [06:09<1:05:51, 44.28it/s]"
     ]
    }
   ],
   "source": [
    "general_train_function(reuters_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# returns the loss for a line, evaluating on a BASIC rnn, and using the provided optimizer\n",
    "def prototype_general_train(input_tensor, target_tensor, basic_rnn, optimizer):\n",
    "    \n",
    "        \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    criterion = nn.NLLLoss()    \n",
    "    hidden = rnn.initHidden()\n",
    "    loss = 0\n",
    "    basic_rnn.zero_grad()\n",
    "    for i in range(input_tensor.size()[0]):\n",
    "        output, hidden = basic_rnn(input_tensor[i], hidden)\n",
    "        \n",
    "        max_tensor = torch.argmax(target_tensor[i])\n",
    "        ind = (torch.argmax(target_tensor[i])).item()\n",
    "        true_target_tensor = torch.tensor([ind], dtype=torch.long)\n",
    "        #     Evaluate the loss on each character!\n",
    "        loss += criterion(output, true_target_tensor)\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return output, loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "def",
   "language": "python",
   "name": "def"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
