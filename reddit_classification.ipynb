{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.ascii_letters + string.digits\n",
    "string.printable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for the dataset:\n",
    "import torch\n",
    "# class for text-datasets\n",
    "# Jama, NEJM and lancet\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import unicodedata\n",
    "class TextDataset(Dataset):\n",
    "\n",
    "    SPECIAL_CHARS = [None, \"\\n\"]\n",
    "    def __len__(self):\n",
    "        return len(self.total_examples)\n",
    "        pass\n",
    " \n",
    "    # generates tensors for the vocab\n",
    "    # i.e. assigns a number to each character\n",
    "    # Q: possible to do one-pass?\n",
    "    def make_vocab(self):\n",
    "        \n",
    "        self.char2index = {}\n",
    "        self.index2char = {}\n",
    "        index = 0\n",
    "        with open(self.text_file) as file:\n",
    "            for line in file:\n",
    "                for char in line:\n",
    "                    if char not in self.char2index:\n",
    "                        self.char2index[char] = index\n",
    "                        self.index2char[index]  = char\n",
    "                        index+=1\n",
    "        \n",
    "        for char in self.SPECIAL_CHARS:\n",
    "#             print(\"this is the char\")\n",
    "            if char not in self.char2index:\n",
    "                self.char2index[char] = index\n",
    "                self.index2char[index] = char\n",
    "                index += 1\n",
    "        \n",
    "        print(self.char2index[None])\n",
    "        # potentially need to add 2 for the None and \\n characters\n",
    "        self.vocab_size = len(self.char2index)\n",
    "    \n",
    "    # this allows the model to handle all possible strings passed into it!!\n",
    "    def full_vocab(self):\n",
    "        self.char2index = {}\n",
    "        self.index2char = {}\n",
    "        index = 0\n",
    "        all_letters = string.printable \n",
    "        for char in all_letters:\n",
    "            if char not in self.char2index:\n",
    "                self.char2index[char] = index\n",
    "                self.index2char[index]  = char\n",
    "                index+=1\n",
    "                \n",
    "        for char in self.SPECIAL_CHARS:\n",
    "#             print(\"this is the char\")\n",
    "            if char not in self.char2index:\n",
    "                self.char2index[char] = index\n",
    "                self.index2char[index] = char\n",
    "                index += 1\n",
    "                \n",
    "        self.vocab_size = len(self.char2index)   \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def generate_tensor_for_char(self, char):\n",
    "        temp = torch.zeros(1, self.vocab_size)\n",
    "        temp[0][self.char2index[char]] = 1 \n",
    "        return temp\n",
    "\n",
    "#     def generate_char_from_tensor(self, char):\n",
    "#         temp = torch.zeros(self.vocab_size, 1)\n",
    "#         temp[self.char2index[char]][0] = 1 \n",
    "#         return temp\n",
    "    def lineToTensor(self,line):\n",
    "        tensor = torch.zeros(len(line), 1, self.vocab_size)\n",
    "#         print(line)\n",
    "        for li, letter in enumerate(line):\n",
    "            tensor[li][0][self.char2index[letter]] = 1\n",
    "        return tensor\n",
    "    \n",
    "    # wrap the lines!\n",
    "    def train_example_builder(self, line):\n",
    "        tensor = torch.zeros(len(line), 1, self.vocab_size)\n",
    "        for li, letter in enumerate(line):\n",
    "            tensor[li][0][self.char2index[letter]] = 1\n",
    "        return tensor\n",
    "      \n",
    "#     could do more of a common build api\n",
    "    def get_None_tensor(self):\n",
    "        tensor = torch.zeros(1, 1, self.vocab_size)\n",
    "        tensor[0][0][self.char2index[None]] = 1\n",
    "        return tensor\n",
    "    \n",
    "    def list_to_tensor(self, input_list):\n",
    "        tensor = torch.zeros(len(input_list), 1, self.vocab_size)\n",
    "        for elt in input_list:\n",
    "            tensor[li][0][self.char2index[letter]] = 1\n",
    "            \n",
    "#     def get_training_pair(self, line):\n",
    "        \n",
    "        \n",
    "    \n",
    "    def get_new_line_tensor(self):\n",
    "        tensor = torch.zeros(1, 1, self.vocab_size)\n",
    "        tensor[0][0][self.char2index[\"\\n\"]] = 1\n",
    "        return tensor\n",
    "\n",
    "        \n",
    "#         tensor[li][0][self.char2index[letter]] \n",
    "#         temp \n",
    "    def unicodeToAscii(self,s):\n",
    "        return ''.join(\n",
    "            c for c in unicodedata.normalize('NFD', s)\n",
    "            if unicodedata.category(c) != 'Mn'\n",
    "            and c in self.char2index\n",
    "        )\n",
    "\n",
    "#     OK, so given the raw lines of text, then we want to get it! (but it is json, so we need to process it anyways)\n",
    "# \n",
    "    def __init__(self, text_files,  convert_to_ascii = True):\n",
    "        self.string = string\n",
    "        self.text_files = text_files\n",
    "\n",
    "        self.training_examples = []\n",
    "\n",
    "        total_inputs = []\n",
    "        total_outputs = []\n",
    "        \n",
    "#         make the vocab\n",
    "        self.full_vocab()\n",
    "    \n",
    "        from tqdm import tqdm\n",
    "        for target_class, file_name in enumerate(tqdm(text_files)):\n",
    "            with open(file_name,  encoding=\"utf8\") as file:\n",
    "                for counter, raw_line in enumerate(file):\n",
    "#                     if counter > 500:\n",
    "#                         break\n",
    "\n",
    "                    line = self.unicodeToAscii(raw_line) if convert_to_ascii else raw_line\n",
    "                    line = line[0:139]\n",
    "                    # zero pad to start\n",
    "\n",
    "\n",
    "    #                 think about how to make this a vector or tensor line! \n",
    "    #                 print()\n",
    "\n",
    "    #                 inputs = self.get_None_tensor() + line_to_tensor(line)\n",
    "    #                 inputs = [None] + [x for x in line]\n",
    "                    inputs = self.lineToTensor([None] + [x for x in line])\n",
    "\n",
    "                    targets = torch.zeros((1,4))  # we need a 0 as well!\n",
    "                    targets[0,target_class] = 1\n",
    "                \n",
    "#                     print(targets)\n",
    "\n",
    "                    # append: will be a list of list (of lines)\n",
    "                    # extend: will be a list of lines\n",
    "                    total_inputs.append(inputs)\n",
    "                    total_outputs.append(targets)\n",
    "\n",
    "        assert len(total_inputs) == len(total_outputs)\n",
    "        \n",
    "        import random\n",
    "        \n",
    "        \n",
    "        # this is now a LIST of lists!\n",
    "        self.total_examples = list(zip(total_inputs, total_outputs))\n",
    "        random.shuffle(self.total_examples)\n",
    "        #                 for char in line:\n",
    "        # how many chars before the target? or all chars before the target?\n",
    "        # so we simply pair up x with [x+1] i think\n",
    "        # ok, and then we iterate them in the loader?\n",
    "        #                     inputs = [x for x in ]\n",
    "        #                     targets = []\n",
    "\n",
    "        # we should also have some big list of entries \n",
    "\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    # ok, now let us just try adding the transforms\n",
    "    # actually the transforms should take responsibility for all of the vocab stuff\n",
    "    \n",
    "    # number of items in the dataset. This involves a rather large computation!\n",
    "    # we can either do a feed forward cllm in the style of bengio, or we can just \n",
    "    # do the RNN approach (as specified by Sean Robertson in his tutorial)\n",
    "\n",
    "    # the indices should represent examples inside the list\n",
    "    # one strange thing is the following: we need to precompute al the indices earlier, imo, and then simply return the list\n",
    "    # at that element! (perhaps with some transforms!)\n",
    "    def __getitem__(self, index):\n",
    "        return self.total_examples[index]\n",
    "\n",
    "        # build a list, return elements from that list? we need to internally keep track of some index\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# ok, so it works now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:24<00:00, 21.10s/it]\n"
     ]
    }
   ],
   "source": [
    "files = [r\"C:\\Users\\johnp\\Downloads\\CSC401_A1\\data\\Left-reduced\",r\"C:\\Users\\johnp\\Downloads\\CSC401_A1\\data\\Center-reduced\", \n",
    "        r\"C:\\Users\\johnp\\Downloads\\CSC401_A1\\data\\Right-reduced\", r\"C:\\Users\\johnp\\Downloads\\CSC401_A1\\data\\Alt-reduced\"]\n",
    "abc = TextDataset( files, True)\n",
    "\n",
    "\n",
    "#think about unicode issues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(abc.char2index[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.generate_tensor_for_char(\"a\")\n",
    "# abc.index2char[2]\n",
    "abc.lineToTensor(\"abcd\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for (a,b) in abc:\n",
    "    pass\n",
    "#     this should give two lines/tests\n",
    "#     print(a,b)\n",
    "#     print()\n",
    "    \n",
    "#     realistically, we should also have it as tensors/vectors\n",
    "# finally, we should also have some way where we run the rnn forward and \n",
    "#  iteratoring over the set, does not consume the elements! It is not a genertor! Rather, we simply index into the elements we would like\n",
    "for(a,b) in abc:\n",
    "    pass\n",
    "#     print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_x = [None] + [\"e\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ok, so now let's just do the stuff\n",
    "# the RNN actually makes one-character over predictions! \n",
    "# rnn_forward is a utility function that does a lot of stuff\n",
    "len(char_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok, so now we can start building the network that will process these!!\n",
    "# simply: iterate the dataset, and run train on it, do the log likelihood and etc.\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "#         combined = F.relu(combined)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "    \n",
    "n_hidden = 128\n",
    "\n",
    "\n",
    "rnn = RNN(abc.vocab_size, n_hidden, 4) #since 4 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.lineToTensor(\"we\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# WE NEED THIS LINE TO RESET THE RNN!!\n",
    "rnn = RNN(abc.vocab_size, n_hidden, 4)\n",
    "learning_rate = 0.0005 # If you set this too high, it might explode. If too low, it might not learn\n",
    "#  we had to set it a big lower to force convergence\n",
    "\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(rnn.parameters())\n",
    "\n",
    "# returns the loss for a line\n",
    "\n",
    "def train(input_tensor, target_tensor):\n",
    "    \n",
    "        \n",
    "#     print(input_tensor)\n",
    "#     print(input_tensor.shape)\n",
    "\n",
    "#     print(target_tensor)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "#     print (input_tensor)\n",
    "    \n",
    "#     print(\"changed3\")\n",
    "#     print(input_tensor[1])\n",
    "    criterion = nn.NLLLoss()    \n",
    "    hidden = rnn.initHidden()\n",
    "    loss = 0\n",
    "    rnn.zero_grad()\n",
    "#     print(input_tensor.size())\n",
    "#     print(target_tensor[0])\n",
    "#     print(target_tensor)\n",
    "#     print(input_tensor.size()[0])\n",
    "    \n",
    "#     we want EVERYTHING to come and output a single value\n",
    "    for i in range(input_tensor.size()[0]):\n",
    "        output, hidden = rnn(input_tensor[i], hidden)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         find where the one is:\n",
    "# \n",
    "#         torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "    \n",
    "    true_target_tensor = torch.tensor([torch.argmax(target_tensor)], dtype=torch.long)\n",
    "    \n",
    "#     true_target_tensor = target_tensor\n",
    "#     print(output)\n",
    "#     print(output.shape)\n",
    "#     print(true_target_tensor)\n",
    "#     print(true_target_tensor.shape)\n",
    "# it needs a single max value interestingly!\n",
    "#     Evaluate the loss on each character!\n",
    "    \n",
    "    \n",
    "    loss += criterion(output,true_target_tensor)\n",
    "        \n",
    "#         expects JUST a single target class:\n",
    "\n",
    "#     print (\"loss for i \" + str(loss.item()))    \n",
    "#         print()\n",
    "# should be do the loss on each thing, or each batch! no, we should accumulate it! \n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "#     for p in rnn.parameters():\n",
    "#         p.data.add_(-learning_rate, p.grad.data)\n",
    "\n",
    "    return output, loss.item()\n",
    "\n",
    "# why not run this just on all the tensors!! \n",
    "\n",
    "# then, we just call it with the dataset class, and then just iterate everything!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.index2char[0]\n",
    "abc.index2char[1]\n",
    "\n",
    "abc.char2index[\"A\"]\n",
    "\n",
    "# ok some weird stuff here...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (x,y) in abc:\n",
    "#     print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                        | 0/40029 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 0 is 0.002968559265136719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                             | 497/40029 [00:14<18:44, 35.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 500 is 139.8873632671982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▉                                                                            | 998/40029 [00:25<16:37, 39.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 1000 is 1.3824091597795487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▉                                                                          | 1498/40029 [00:37<15:54, 40.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 1500 is 1.3982573626041412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▊                                                                         | 1995/40029 [00:48<15:23, 41.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 2000 is 1.3712460067272185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▊                                                                        | 2496/40029 [01:00<15:03, 41.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 2500 is 1.377080337524414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▊                                                                       | 2997/40029 [01:12<14:56, 41.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 3000 is 1.3586693996191024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████▋                                                                      | 3496/40029 [01:26<15:01, 40.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 3500 is 1.3653027491569518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▋                                                                     | 3999/40029 [01:39<14:58, 40.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 4000 is 1.347836929321289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████▋                                                                    | 4499/40029 [01:59<15:41, 37.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 4500 is 1.3598309816122056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▌                                                                   | 5000/40029 [02:17<16:01, 36.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 5000 is 1.3440278347730636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████▌                                                                  | 5500/40029 [02:30<15:47, 36.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 5500 is 1.3459812880754471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████▌                                                                 | 5999/40029 [02:45<15:37, 36.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 6000 is 1.3467162059545517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▍                                                                | 6497/40029 [02:58<15:20, 36.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 6500 is 1.331077435851097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████▍                                                               | 6997/40029 [03:12<15:06, 36.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 7000 is 1.3547852874994277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████▍                                                              | 7500/40029 [03:26<14:54, 36.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 7500 is 1.3474173778295517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▍                                                             | 7999/40029 [03:40<14:42, 36.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 8000 is 1.337123574912548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████▎                                                            | 8496/40029 [03:53<14:27, 36.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 8500 is 1.3234411484599113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████▎                                                           | 8998/40029 [04:08<14:15, 36.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 9000 is 1.3210561389923097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████▎                                                          | 9498/40029 [04:25<14:14, 35.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 9500 is 1.334065930366516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████████████▉                                                         | 10000/40029 [04:42<14:07, 35.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 10000 is 1.3409496245384216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████▉                                                        | 10499/40029 [04:59<14:03, 35.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 10500 is 1.347807429909706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████████████▉                                                       | 10999/40029 [05:16<13:56, 34.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 11000 is 1.3259420388936995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████▊                                                      | 11498/40029 [05:32<13:45, 34.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 11500 is 1.360347783923149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████▊                                                     | 11996/40029 [05:49<13:35, 34.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 12000 is 1.3425923278331757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███████████████████████▋                                                    | 12497/40029 [06:05<13:24, 34.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 12500 is 1.2959300985336304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████▋                                                   | 12997/40029 [06:17<13:05, 34.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 13000 is 1.3357609923481941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████████████▋                                                  | 13497/40029 [06:28<12:44, 34.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 13500 is 1.3242256577014924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████▌                                                 | 13998/40029 [06:40<12:25, 34.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 14000 is 1.3368586592674256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████▌                                                | 14497/40029 [06:52<12:06, 35.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 14500 is 1.3300259046554566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|████████████████████████████▍                                               | 14996/40029 [07:05<11:51, 35.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 15000 is 1.3563017480373383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|█████████████████████████████▍                                              | 15493/40029 [07:18<11:34, 35.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 15500 is 1.3362474358081817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████▎                                             | 15997/40029 [07:30<11:16, 35.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 16000 is 1.3449081435203551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|███████████████████████████████▎                                            | 16499/40029 [07:43<11:00, 35.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 16500 is 1.3507089542150497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████████████▎                                           | 16998/40029 [07:55<10:43, 35.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 17000 is 1.3334044649600982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████▏                                          | 17500/40029 [08:06<10:26, 35.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 17500 is 1.339359054684639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████████████████████▏                                         | 17998/40029 [08:19<10:11, 36.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 18000 is 1.3213893389701843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████████████████████                                         | 18499/40029 [08:31<09:55, 36.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 18500 is 1.3174354234933854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████████████████████                                        | 19000/40029 [08:44<09:40, 36.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 19000 is 1.3296653043031692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|█████████████████████████████████████                                       | 19499/40029 [08:56<09:25, 36.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 19500 is 1.3003932650089265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████▉                                      | 19994/40029 [09:08<09:10, 36.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 20000 is 862549692122.3999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|██████████████████████████████████████▉                                     | 20496/40029 [09:21<08:54, 36.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 20500 is 1.3311471430063249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|███████████████████████████████████████▊                                    | 20999/40029 [09:33<08:39, 36.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 21000 is 1.2876358757019042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|████████████████████████████████████████▊                                   | 21499/40029 [09:45<08:24, 36.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 21500 is 1.2939173711538314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████████████████████▊                                  | 21998/40029 [09:57<08:09, 36.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 22000 is 1.3136649521589279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|██████████████████████████████████████████▋                                 | 22498/40029 [10:09<07:54, 36.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 22500 is 1.2916176323890687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|███████████████████████████████████████████▋                                | 22998/40029 [10:21<07:40, 37.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 23000 is 1.3515086461305619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|████████████████████████████████████████████▌                               | 23500/40029 [10:33<07:25, 37.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 23500 is 1.348629420876503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████▌                              | 23998/40029 [10:46<07:11, 37.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 24000 is 1.3046721646785735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████████████████████████████████████████████▌                             | 24500/40029 [10:58<06:57, 37.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 24500 is 1.3461731231212617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|███████████████████████████████████████████████▍                            | 25000/40029 [11:10<06:43, 37.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 25000 is 1.2963987344503403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████████████████████████████████▍                           | 25497/40029 [11:23<06:29, 37.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 25500 is 1.3142696627378463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████████▎                          | 25996/40029 [11:35<06:15, 37.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 26000 is 1.309981442451477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████████████████████████████████████████████████▎                         | 26500/40029 [11:47<06:01, 37.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 26500 is 1.322107995390892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|███████████████████████████████████████████████████▎                        | 26998/40029 [11:59<05:47, 37.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 27000 is 1.3110927568674087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████████████████████████████▏                       | 27492/40029 [12:11<05:33, 37.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 27500 is 1.3265038294792175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████▏                      | 27998/40029 [12:23<05:19, 37.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 28000 is 1.3030360441803932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████████████████████████████                      | 28499/40029 [12:35<05:05, 37.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 28500 is 1.2889029667377472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████████                     | 28997/40029 [12:47<04:51, 37.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 29000 is 1.3105775879621506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|████████████████████████████████████████████████████████                    | 29500/40029 [12:59<04:38, 37.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 29500 is 1.3301288551092147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████████▉                   | 30000/40029 [13:12<04:25, 37.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 30000 is 1.31101762509346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|█████████████████████████████████████████████████████████▉                  | 30496/40029 [13:25<04:11, 37.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 30500 is 1.3270451867580413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|██████████████████████████████████████████████████████████▊                 | 30998/40029 [13:37<03:58, 37.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 31000 is 1.3080371817946435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████████████████████████████████████████████████████████▊                | 31498/40029 [13:49<03:44, 37.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 31500 is 1.3279684480428695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████▊               | 32000/40029 [14:01<03:31, 38.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 32000 is 1.3232652513980865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|█████████████████████████████████████████████████████████████▋              | 32499/40029 [14:13<03:17, 38.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 32500 is 1.3300606914758681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|██████████████████████████████████████████████████████████████▋             | 32999/40029 [14:24<03:04, 38.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 33000 is 1.3412053018808365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████████████████████████████████████▌            | 33497/40029 [14:35<02:50, 38.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 33500 is 1.3315059522390364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████████████████████████████████████▌           | 33997/40029 [14:47<02:37, 38.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 34000 is 1.318062134563923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████████████████████████████████████▍          | 34498/40029 [14:59<02:24, 38.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 34500 is 1.3406775547862053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|██████████████████████████████████████████████████████████████████▍         | 34999/40029 [15:10<02:10, 38.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 35000 is 1.3167288051843644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|███████████████████████████████████████████████████████████████████▍        | 35498/40029 [15:20<01:57, 38.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 35500 is 1.3313065217137336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████▎       | 35998/40029 [15:31<01:44, 38.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 36000 is 1.3201530170440674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████████████████████████████████████████████████████████████████▎      | 36500/40029 [15:42<01:31, 38.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 36500 is 1.304189407289028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████████████████████████████████████▏     | 36996/40029 [15:54<01:18, 38.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 37000 is 1.3507744866609572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████████▏    | 37497/40029 [16:06<01:05, 38.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 37500 is 1.3231028648614884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|████████████████████████████████████████████████████████████████████████▏   | 38000/40029 [16:17<00:52, 38.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 38000 is 1.3232190842032432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████████████████████████████████████████   | 38498/40029 [16:28<00:39, 38.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 38500 is 1.3317740384936332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|██████████████████████████████████████████████████████████████████████████  | 38997/40029 [16:41<00:26, 38.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 39000 is 1.3394854108095169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|██████████████████████████████████████████████████████████████████████████▉ | 39498/40029 [16:54<00:13, 38.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 39500 is 1.3320784177780152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████▉| 39995/40029 [17:05<00:00, 38.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 40000 is 1.2931012964248658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 40029/40029 [17:06<00:00, 38.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss is 10774329124.190268\n",
      "per character loss is 88106041.93526067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                        | 0/40029 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 0 is 0.07323037755489349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                             | 496/40029 [00:12<16:32, 39.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 500 is 1.322719668507576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▉                                                                            | 999/40029 [00:25<16:31, 39.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 1000 is 1.336018288731575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▉                                                                          | 1500/40029 [00:39<17:03, 37.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 1500 is 1.3346922599077224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▊                                                                         | 1994/40029 [00:53<16:51, 37.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 2000 is 1.3278386645317077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▊                                                                        | 2496/40029 [01:06<16:34, 37.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 2500 is 1.3153756844997406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▊                                                                       | 2996/40029 [01:19<16:17, 37.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 3000 is 1.3139724818468095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████▋                                                                      | 3498/40029 [01:31<15:58, 38.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 3500 is 1.3136771708726882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▋                                                                     | 3997/40029 [01:44<15:42, 38.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 4000 is 1.3132910457849503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████▋                                                                    | 4499/40029 [01:59<15:42, 37.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 4500 is 1.3166076788902283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▌                                                                   | 4999/40029 [02:16<15:59, 36.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 5000 is 1.2994667117595673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████▌                                                                  | 5499/40029 [02:30<15:45, 36.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 5500 is 1.3198528794050217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████▌                                                                 | 5999/40029 [02:47<15:51, 35.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 6000 is 1.3030346041917802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▍                                                                | 6498/40029 [03:03<15:44, 35.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 6500 is 1.317380643606186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████▍                                                               | 6999/40029 [03:18<15:38, 35.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 7000 is 1.3217354596853257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████▍                                                              | 7500/40029 [03:33<15:26, 35.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 7500 is 1.3011065770387649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▍                                                             | 7997/40029 [03:49<15:19, 34.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 8000 is 1.3204736433029174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████▎                                                            | 8498/40029 [04:05<15:09, 34.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 8500 is 1.2921460454463958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████▎                                                           | 8997/40029 [04:20<14:59, 34.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 9000 is 1.2805765433311462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████▎                                                          | 9495/40029 [04:37<14:50, 34.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 9500 is 1.2920149862766266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████▏                                                         | 9998/40029 [04:54<14:43, 34.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 10000 is 1.3139101510047912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████▉                                                        | 10498/40029 [05:09<14:29, 33.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 10500 is 1.3153855578899383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████████████▉                                                       | 10999/40029 [05:24<14:16, 33.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 11000 is 1.2982669122219086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████▊                                                      | 11498/40029 [05:39<14:03, 33.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 11500 is 1.3524100861549377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████▊                                                     | 11998/40029 [05:52<13:43, 34.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 12000 is 1.3357810040712357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███████████████████████▋                                                    | 12498/40029 [06:05<13:24, 34.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 12500 is 1.2759814229011535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████▋                                                   | 12995/40029 [06:17<13:04, 34.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 13000 is 1.2886678912639618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████████████▋                                                  | 13497/40029 [06:29<12:45, 34.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 13500 is 1.3117145968675614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████▌                                                 | 14000/40029 [06:41<12:26, 34.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 14000 is 1.3120356194972993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████▌                                                | 14497/40029 [06:54<12:09, 35.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 14500 is 1.292922772526741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|████████████████████████████▍                                               | 14997/40029 [07:07<11:54, 35.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 15000 is 1.3378670189976691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|█████████████████████████████▍                                              | 15500/40029 [07:20<11:37, 35.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 15500 is 1.293037183880806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████▍                                             | 15999/40029 [07:33<11:20, 35.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 16000 is 1.3409236785769463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|███████████████████████████████▎                                            | 16500/40029 [07:46<11:05, 35.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 16500 is 1.342733005642891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████████████▎                                           | 16998/40029 [07:59<10:49, 35.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 17000 is 1.3077831901311874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████▏                                          | 17500/40029 [08:11<10:33, 35.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 17500 is 1.3247840168476104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████████████████████▏                                         | 17998/40029 [08:24<10:17, 35.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 18000 is 1.2873316057920456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████████████████████                                         | 18499/40029 [08:37<10:02, 35.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 18500 is 1.2871558610200882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████████████████████                                        | 18996/40029 [08:50<09:47, 35.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 19000 is 1.31131076836586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|█████████████████████████████████████                                       | 19499/40029 [09:03<09:32, 35.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 19500 is 1.271386549115181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████▉                                      | 19996/40029 [09:16<09:17, 35.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 20000 is 1.2969656730890273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|██████████████████████████████████████▉                                     | 20496/40029 [09:29<09:02, 36.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 20500 is 1.3062409747838974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|███████████████████████████████████████▊                                    | 20999/40029 [09:41<08:47, 36.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 21000 is 1.2710759226083757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|████████████████████████████████████████▊                                   | 21499/40029 [09:54<08:32, 36.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 21500 is 1.2755188210010528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████████████████████▊                                  | 21997/40029 [10:07<08:17, 36.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 22000 is 1.3058002396821975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|██████████████████████████████████████████▋                                 | 22500/40029 [10:21<08:04, 36.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 22500 is 1.2751298391819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|███████████████████████████████████████████▋                                | 22998/40029 [10:35<07:50, 36.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 23000 is 1.3358527551889419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|████████████████████████████████████████████▌                               | 23500/40029 [10:48<07:36, 36.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 23500 is 1.3511379029750823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████▌                              | 23998/40029 [11:02<07:22, 36.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 24000 is 1.2994908841848374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████████████████████████████████████████████▌                             | 24497/40029 [11:16<07:08, 36.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 24500 is 1.340928154706955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|███████████████████████████████████████████████▍                            | 24998/40029 [11:30<06:55, 36.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 25000 is 1.2760393018126488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████████████████████████████████▍                           | 25499/40029 [11:43<06:41, 36.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 25500 is 1.3042933319807053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████████▎                          | 25997/40029 [11:56<06:26, 36.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 26000 is 1.3043491402864456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████████████████████████████████████████████████▎                         | 26497/40029 [12:09<06:12, 36.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 26500 is 1.3102885032892226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|███████████████████████████████████████████████████▎                        | 27000/40029 [12:23<05:58, 36.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 27000 is 1.2947050795555115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████████████████████████████▏                       | 27492/40029 [12:37<05:45, 36.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 27500 is 1.3381466999053955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████▏                      | 27998/40029 [12:49<05:30, 36.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 28000 is 1.285001126766205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████████████████████████████                      | 28499/40029 [13:02<05:16, 36.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 28500 is 1.285588888645172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████████                     | 28999/40029 [13:14<05:02, 36.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 29000 is 1.2998806171417236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|████████████████████████████████████████████████████████                    | 29499/40029 [13:28<04:48, 36.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 29500 is 1.3161585545539856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████████▉                   | 30000/40029 [13:42<04:34, 36.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 30000 is 1.3027093218564987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|█████████████████████████████████████████████████████████▉                  | 30499/40029 [13:55<04:21, 36.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 30500 is 1.3243195759058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|██████████████████████████████████████████████████████████▊                 | 30999/40029 [14:09<04:07, 36.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 31000 is 1.2994250370264053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████████████████████████████████████████████████████████▊                | 31498/40029 [14:21<03:53, 36.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 31500 is 1.320370695233345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████▊               | 31999/40029 [14:33<03:39, 36.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 32000 is 1.3183319650888443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|█████████████████████████████████████████████████████████████▋              | 32497/40029 [14:47<03:25, 36.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 32500 is 1.3205598146915436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|██████████████████████████████████████████████████████████████▋             | 32998/40029 [15:04<03:12, 36.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 33000 is 1.3354478768110276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████████████████████████████████████▌            | 33494/40029 [15:19<02:59, 36.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 33500 is 1.3203753747940064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████████████████████████████████████▌           | 34000/40029 [15:33<02:45, 36.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 34000 is 1.321269943356514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████████████████████████████████████▍          | 34496/40029 [15:47<02:32, 36.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 34500 is 1.340229653775692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|██████████████████████████████████████████████████████████████████▍         | 34999/40029 [16:00<02:18, 36.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 35000 is 1.3143040757775306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|███████████████████████████████████████████████████████████████████▍        | 35500/40029 [16:15<02:04, 36.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 35500 is 1.3296346925497056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████▎       | 35998/40029 [16:27<01:50, 36.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 36000 is 1.312102358698845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████████████████████████████████████████████████████████████████▎      | 36500/40029 [16:42<01:36, 36.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 36500 is 1.2964845041036606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████████████████████████████████████▏     | 36996/40029 [16:58<01:23, 36.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 37000 is 1.3509341272115707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████████▏    | 37496/40029 [17:12<01:09, 36.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 37500 is 1.3090458801984788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|████████████████████████████████████████████████████████████████████████▏   | 38000/40029 [17:25<00:55, 36.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 38000 is 1.31966934800148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████████████████████████████████████████   | 38497/40029 [17:41<00:42, 36.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 38500 is 1.3273789944648742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|██████████████████████████████████████████████████████████████████████████  | 38997/40029 [17:55<00:28, 36.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 39000 is 1.329395548582077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|██████████████████████████████████████████████████████████████████████████▉ | 39498/40029 [18:09<00:14, 36.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 39500 is 1.3181236128807068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████▉| 39998/40029 [18:22<00:00, 36.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 40000 is 1.293402615070343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 40029/40029 [18:23<00:00, 36.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss is 1.3115061813634308\n",
      "per character loss is 0.0107247158761956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                        | 0/40029 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 0 is 0.07445354735851288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                             | 496/40029 [00:14<18:54, 34.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 500 is 1.3253869254589081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▉                                                                            | 999/40029 [00:27<17:56, 36.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 1000 is 7.031660099744679e+27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▉                                                                          | 1499/40029 [00:42<18:01, 35.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 1500 is 3.102496211911848e+28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▊                                                                         | 1998/40029 [00:55<17:30, 36.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 2000 is 2.9924375424423656e+28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▊                                                                        | 2498/40029 [01:08<17:08, 36.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 2500 is 2.4906394071801446e+28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▊                                                                       | 3000/40029 [01:22<17:04, 36.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 3000 is 2.682542572345201e+28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████▋                                                                      | 3498/40029 [01:36<16:42, 36.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 3500 is 2.797777244885182e+28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▋                                                                     | 3999/40029 [01:51<16:41, 35.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 4000 is 2.749917459574532e+28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████▋                                                                    | 4497/40029 [02:04<16:24, 36.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 4500 is 3.1734917318294936e+28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▌                                                                   | 4996/40029 [02:18<16:09, 36.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 5000 is 3.2242740493212113e+28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████▌                                                                  | 5499/40029 [02:30<15:47, 36.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 5500 is 2.7079758008488776e+28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████▌                                                                 | 5999/40029 [02:44<15:30, 36.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 6000 is 3.0557363989751824e+28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▌                                                                | 6499/40029 [02:57<15:17, 36.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 6500 is 2.6895555054838986e+28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████▍                                                               | 6999/40029 [03:12<15:07, 36.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 7000 is 2.700188587768574e+28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████▍                                                              | 7500/40029 [03:28<15:06, 35.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 7500 is 2.861430953748816e+28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▍                                                             | 7998/40029 [03:47<15:10, 35.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 8000 is 2.3890508590161722e+28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████▎                                                            | 8499/40029 [04:01<14:54, 35.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 8500 is 3.169336800576075e+28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████▎                                                           | 8998/40029 [04:15<14:39, 35.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 9000 is 2.8315808848041545e+28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████▎                                                          | 9496/40029 [04:31<14:31, 35.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 9500 is 2.3569867099035872e+28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████▏                                                         | 9997/40029 [04:43<14:11, 35.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 10000 is 2.941735195740924e+28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████▉                                                        | 10497/40029 [04:56<13:55, 35.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 10500 is 3.071389629081688e+28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████████████▉                                                       | 11000/40029 [05:18<14:00, 34.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 11000 is 3.288258043463433e+28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████▊                                                      | 11498/40029 [05:36<13:55, 34.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 11500 is 2.671812671686402e+28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████▊                                                     | 11998/40029 [05:50<13:39, 34.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 12000 is 2.436443180492941e+28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███████████████████████▋                                                    | 12497/40029 [06:04<13:22, 34.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 12500 is 2.8096312985835934e+28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████▋                                                   | 12995/40029 [06:16<13:03, 34.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 13000 is 2.4346866596364013e+28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████▉                                                   | 13162/40029 [06:20<12:56, 34.61it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-b84a0e0f07d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m#     print(x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m#     print(y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mepoch_length\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-db63537eec16>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(input_tensor, target_tensor)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;31m#     we want EVERYTHING to come and output a single value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\def\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-ad7ea9f8b618>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hidden)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mi2h\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mi2o\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\def\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\def\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\def\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[1;34m(input, dim, _stacklevel)\u001b[0m\n\u001b[0;32m    973\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m         \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'log_softmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 975\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    976\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# del rnn\n",
    "# rnn = RNN(abc.vocab_size, n_hidden, abc.vocab_size)\n",
    "\n",
    "epoch_loss = 0\n",
    "# loss every k iters\n",
    "# \n",
    "total_loss = 0\n",
    "total_length  = 0\n",
    "epoch_length = 0\n",
    "other_loss = 0\n",
    "\n",
    "from tqdm import tqdm\n",
    "num_epochs = 10\n",
    "for k in range(num_epochs ):\n",
    "    \n",
    "    for i,(x,y) in enumerate(tqdm(abc)):\n",
    "    #     print(x)\n",
    "    #     print(x)\n",
    "    #     print(y)\n",
    "        _, loss = train(x,y)\n",
    "        epoch_loss += loss\n",
    "        epoch_length += x.size()[0]\n",
    "        total_loss += loss\n",
    "        total_length += x.size()[0]\n",
    "        other_loss +=loss\n",
    "#         print(loss)\n",
    "    #     print(i)\n",
    "    #     abc = i\n",
    "        if i % 500 == 0:\n",
    "            print (\"loss for {} is {}\".format(i,other_loss/500))\n",
    "            other_loss = 0\n",
    "#         break\n",
    "\n",
    "    \n",
    "    print(\"epoch {} loss is {}\".format(k, epoch_loss/i))\n",
    "    print(\"per character loss is {}\".format(epoch_loss/epoch_length))\n",
    "    epoch_loss = 0\n",
    "    epoch_length = 0\n",
    "#     ideally: we would be able to compute the quintile losses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the entire model under the given filename\n",
    "def save_model(model,filename):\n",
    "    torch.save(model, filename)\n",
    "    \n",
    "    return\n",
    "\n",
    "# Saves the model parameters only (for maximum usability)\n",
    "\n",
    "def save_model_params(model, filename):\n",
    "\n",
    "    torch.save(model.state_dict(), filename)\n",
    "\n",
    "    return filename\n",
    "\n",
    "#  ideally, I could get per character loss, then I would also be able to get the total expected loss\n",
    "# so: we want to get total loss, then divide it by all the length of the number of examples we saw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_params(filename):\n",
    "    model = RNN(abc.vocab_size, n_hidden, abc.vocab_size)\n",
    "    model.load_state_dict(torch.load(filename))\n",
    "    return model #vs return model.eval()??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"reddit_draft.pt\"\n",
    "\n",
    "if True:\n",
    "\n",
    "    filename = save_model_params(rnn, \"reddit_draft.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    eval_model = load_model_from_params(filename)\n",
    "    eval_model.eval() # this is a mutating operation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# returns the loss for the entire line (requires normalization for comparison)\n",
    "def get_loss_on_line(rnn, line):\n",
    "    input_tensor =  abc.lineToTensor([None] + [x for x in line])\n",
    "    target_tensor = abc.lineToTensor([x for x in line] + [\"\\n\"])\n",
    "    criterion = nn.NLLLoss()    \n",
    "    hidden = rnn.initHidden()\n",
    "    loss = 0\n",
    "    rnn.zero_grad()\n",
    "    \n",
    "    \n",
    "#     print(input_tensor.size())\n",
    "#     print(target_tensor[0])\n",
    "#     print(target_tensor)\n",
    "    for i in range(input_tensor.size()[0]):\n",
    "        output, hidden = rnn(input_tensor[i], hidden)\n",
    "        \n",
    "        \n",
    "        # had to do this simply because of how the NLLL and CrossEntropy are defined\n",
    "        max_tensor = torch.argmax(target_tensor[i])\n",
    "        ind = (torch.argmax(target_tensor[i])).item()\n",
    "        true_target_tensor = torch.tensor([ind], dtype=torch.long)\n",
    "    \n",
    "#     Evaluate the loss on each character!\n",
    "        loss += criterion(output, true_target_tensor)\n",
    "    \n",
    "    return loss.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = eval_model)\n",
    "\n",
    "# so there's a couple possibilities: we can have jim and ask to predict as well as just get the loss of the example\n",
    "# out = train()\n",
    "# ()\n",
    "#lineToTensor\n",
    "\n",
    "# get it as tensors, then run it, then do loss addition\n",
    "\n",
    "STRING_TO_TEST =  \"David\"\n",
    "print(get_loss_on_line(eval_model, STRING_TO_TEST )/len(STRING_TO_TEST ))\n",
    "\n",
    "# we now want to implement sampling:\n",
    "#  is that useful though? \n",
    "# will it be good?\n",
    "# instead, we can also try and get text for the inputs \n",
    "#  then train on that, then run it on some numerical numbers\n",
    "\n",
    "# visualization would be super useful \n",
    "# for pretty printing, we can colour the terminal output\n",
    "# otherwise, we will need to somehow encode the colour so that it is output to the file\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  print(\"\\x1b[31m\\\"red\\\"\\x1b[0m\")\n",
    "\n",
    "# if no thresholding, then we should at least like somehow graphically display?\n",
    "# no,... this is a different concern. Don't put frontend and backend together! (or visualization and etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Fore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Fore.RED + \"yoo\")\n",
    "\n",
    "# print(Fore.BLUE + \"haha\")\n",
    "\n",
    "# if on average more than twice as high loss on this sample, then we should flag it for further review\n",
    "THRESHOLD =  1.8332151545300774 * 2\n",
    "\n",
    "\n",
    "# some more powerful model: uses LSTM as well as additional fields and operators!\n",
    "# ok, so now let us just iterate the text file\n",
    "with open(\"data\\\\test-cases.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        example_loss = get_loss_on_line(eval_model, line)/len(line )\n",
    "        if (example_loss > THRESHOLD):\n",
    "            print(Fore.RED + line)\n",
    "        else:\n",
    "            print(Fore.BLUE + line)\n",
    "        \n",
    "        print(\"loss\" + str(example_loss))\n",
    "    \n",
    "# perhaps we should train on google news corpus for a little while..\n",
    "# this \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ok\")\n",
    "\n",
    "sentences = reuters.raw().splitlines()\n",
    "# print(reuters.raw())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(sentences))\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# these are not exactly tokenized on sentences; but that is OK!\n",
    "sentences[:100]\n",
    "\n",
    "with open(\"reuters_news.txt\", \"w\") as file:\n",
    "    file.write(reuters.raw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need a smaller dataset for development\n",
    "# so, let's cut up the reuters into smaller (for example, load just the first K bytes of the file.)\n",
    "import time\n",
    "\n",
    "def make_proto_dataset(size):\n",
    "    with open(\"reuters_news_{}.txt\".format(size), \"w\") as file:\n",
    "        \n",
    "        \n",
    "        file.write('\\n'.join(reuters.raw().splitlines()[0:size]))\n",
    "    print(\"file created with {} lines\".format(size))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     the question now is how many neurons and the architecture to use\n",
    "# we can also look into enhancement with the tqdm inside the object?\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "make_proto_dataset(10000)\n",
    "elapsed = time.time() - start\n",
    "print(\"elapsed time is {}\".format(elapsed ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reuters dataset has umlauts and other non-standard characters, so we should try and account for that! \n",
    "# also: we should try and do a sort of full merge: merge between the train dataset and test dataset vocabs\n",
    "# other than that, we can just apply a regularizer to both sets, to get out the processed data\n",
    "# for now, let's just apply a regularization\n",
    "\n",
    "start = time.time()\n",
    "reuters_dataset = TextDataset( \"reuters_news_10000.txt\", True)\n",
    "elapsed = time.time() - start\n",
    "print(\"elapsed time is {}\".format(elapsed ))\n",
    "\n",
    "# jeez, so it takes more than 8 minutes to create the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(reuters_dataset))\n",
    "from tqdm import tqdm\n",
    "def general_train_function(dataset):\n",
    "# del rnn\n",
    "# rnn = RNN(abc.vocab_size, n_hidden, abc.vocab_size)\n",
    "\n",
    "    epoch_loss = 0\n",
    "    # loss every k iters\n",
    "    # \n",
    "    loss_per_k = 0\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_length  = 0\n",
    "    epoch_length = 0\n",
    "\n",
    "\n",
    "    num_epochs = 10\n",
    "    \n",
    "    for k in range(num_epochs ):\n",
    "\n",
    "        for i,(x,y) in enumerate(tqdm(dataset)):\n",
    "        #     print(x)\n",
    "        #     print(x)\n",
    "        #     print(y)\n",
    "            _, loss = train(x,y)\n",
    "            epoch_loss += loss\n",
    "            epoch_length += x.size()[0]\n",
    "            total_loss += loss\n",
    "            total_length += x.size()[0]\n",
    "            loss_per_k += loss\n",
    "        #     print(i)\n",
    "        #     abc = i\n",
    "        \n",
    "            # for the first 100 iters, print the loss of every line!\n",
    "#             if i < 100:\n",
    "#                 print (\"loss for {} is {}\".format(i,epoch_loss/(i+1)))\n",
    "                \n",
    "            \n",
    "            if i % 100 == 0 and i != 0:\n",
    "                print (\"loss for {} is {}\".format(i,loss_per_k/100))\n",
    "                loss_per_k = 0\n",
    "                \n",
    "\n",
    "        print(\"epoch {} loss is {}\".format(k, epoch_loss/i))\n",
    "        print(\"per character loss is {}\".format(epoch_loss/epoch_length))\n",
    "        epoch_loss = 0\n",
    "        epoch_length = 0\n",
    "#     ideally: we would be able to compute the quintile losses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# WE NEED THIS LINE TO RESET THE RNN!!\n",
    "rnn = RNN(reuters_dataset.vocab_size, 512, reuters_dataset.vocab_size)\n",
    "learning_rate = 0.0005 # If you set this too high, it might explode. If too low, it might not learn\n",
    "#  we had to set it a big lower to force convergence\n",
    "\n",
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(rnn.parameters(), lr = 0.0001)\n",
    "\n",
    "# returns the loss for a line\n",
    "\n",
    "def general_train(input_tensor, target_tensor):\n",
    "    \n",
    "        \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "#     print (input_tensor)\n",
    "    \n",
    "#     print(\"changed3\")\n",
    "#     print(input_tensor[1])\n",
    "    criterion = nn.NLLLoss()    \n",
    "    hidden = rnn.initHidden()\n",
    "    loss = 0\n",
    "    rnn.zero_grad()\n",
    "#     print(input_tensor.size())\n",
    "#     print(target_tensor[0])\n",
    "#     print(target_tensor)\n",
    "    for i in range(input_tensor.size()[0]):\n",
    "        output, hidden = rnn(input_tensor[i], hidden)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         find where the one is:\n",
    "# \n",
    "#         torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "        max_tensor = torch.argmax(target_tensor[i])\n",
    "#         print(max_tensor)\n",
    "        ind = (torch.argmax(target_tensor[i])).item()\n",
    "#         print(\"this the target\")\n",
    "#         print(target_tensor[i])\n",
    "#         print(ind)\n",
    "        true_target_tensor = torch.tensor([ind], dtype=torch.long)\n",
    "    \n",
    "#     Evaluate the loss on each character!\n",
    "        loss += criterion(output, true_target_tensor)\n",
    "        \n",
    "#         expects JUST a single target class:\n",
    "\n",
    "#     print (\"loss for i \" + str(loss.item()))    \n",
    "#         print()\n",
    "# should be do the loss on each thing, or each batch! no, we should accumulate it! \n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "#     for p in rnn.parameters():\n",
    "#         p.data.add_(-learning_rate, p.grad.data)\n",
    "\n",
    "    return output, loss.item()\n",
    "\n",
    "# why not run this just on all the tensors!! \n",
    "\n",
    "# then, we just call it with the dataset class, and then just iterate everything!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_train_function(reuters_dataset)\n",
    "# perhaps: examine the gradient instead!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# returns the loss for a line, evaluating on a BASIC rnn, and using the provided optimizer\n",
    "def prototype_general_train(input_tensor, target_tensor, basic_rnn, optimizer):\n",
    "    \n",
    "        \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    criterion = nn.NLLLoss()    \n",
    "    hidden = rnn.initHidden()\n",
    "    loss = 0\n",
    "    basic_rnn.zero_grad()\n",
    "    for i in range(input_tensor.size()[0]):\n",
    "        output, hidden = basic_rnn(input_tensor[i], hidden)\n",
    "        \n",
    "        max_tensor = torch.argmax(target_tensor[i])\n",
    "        ind = (torch.argmax(target_tensor[i])).item()\n",
    "        true_target_tensor = torch.tensor([ind], dtype=torch.long)\n",
    "        #     Evaluate the loss on each character!\n",
    "        loss += criterion(output, true_target_tensor)\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return output, loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "def",
   "language": "python",
   "name": "def"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
