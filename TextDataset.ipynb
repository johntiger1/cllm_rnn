{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.ascii_letters + string.digits\n",
    "string.printable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for the dataset:\n",
    "import torch\n",
    "# class for text-datasets\n",
    "# Jama, NEJM and lancet\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import unicodedata\n",
    "class TextDataset(Dataset):\n",
    "\n",
    "    SPECIAL_CHARS = [None, \"\\n\"]\n",
    "    def __len__(self):\n",
    "        return len(self.total_examples)\n",
    "        pass\n",
    " \n",
    "    # generates tensors for the vocab\n",
    "    # i.e. assigns a number to each character\n",
    "    # Q: possible to do one-pass?\n",
    "    def make_vocab(self):\n",
    "        \n",
    "        self.char2index = {}\n",
    "        self.index2char = {}\n",
    "        index = 0\n",
    "        with open(self.text_file) as file:\n",
    "            for line in file:\n",
    "                for char in line:\n",
    "                    if char not in self.char2index:\n",
    "                        self.char2index[char] = index\n",
    "                        self.index2char[index]  = char\n",
    "                        index+=1\n",
    "        \n",
    "        for char in self.SPECIAL_CHARS:\n",
    "#             print(\"this is the char\")\n",
    "            if char not in self.char2index:\n",
    "                self.char2index[char] = index\n",
    "                self.index2char[index] = char\n",
    "                index += 1\n",
    "        \n",
    "        print(self.char2index[None])\n",
    "        # potentially need to add 2 for the None and \\n characters\n",
    "        self.vocab_size = len(self.char2index)\n",
    "    \n",
    "    # this allows the model to handle all possible strings passed into it!!\n",
    "    def full_vocab(self):\n",
    "        self.char2index = {}\n",
    "        self.index2char = {}\n",
    "        index = 0\n",
    "        all_letters = string.printable \n",
    "        for char in all_letters:\n",
    "            if char not in self.char2index:\n",
    "                self.char2index[char] = index\n",
    "                self.index2char[index]  = char\n",
    "                index+=1\n",
    "                \n",
    "        for char in self.SPECIAL_CHARS:\n",
    "#             print(\"this is the char\")\n",
    "            if char not in self.char2index:\n",
    "                self.char2index[char] = index\n",
    "                self.index2char[index] = char\n",
    "                index += 1\n",
    "                \n",
    "        self.vocab_size = len(self.char2index)   \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def generate_tensor_for_char(self, char):\n",
    "        temp = torch.zeros(1, self.vocab_size)\n",
    "        temp[0][self.char2index[char]] = 1 \n",
    "        return temp\n",
    "\n",
    "#     def generate_char_from_tensor(self, char):\n",
    "#         temp = torch.zeros(self.vocab_size, 1)\n",
    "#         temp[self.char2index[char]][0] = 1 \n",
    "#         return temp\n",
    "    def lineToTensor(self,line):\n",
    "        tensor = torch.zeros(len(line), 1, self.vocab_size)\n",
    "#         print(line)\n",
    "        for li, letter in enumerate(line):\n",
    "            tensor[li][0][self.char2index[letter]] = 1\n",
    "        return tensor\n",
    "    \n",
    "    # wrap the lines!\n",
    "    def train_example_builder(self, line):\n",
    "        tensor = torch.zeros(len(line), 1, self.vocab_size)\n",
    "        for li, letter in enumerate(line):\n",
    "            tensor[li][0][self.char2index[letter]] = 1\n",
    "        return tensor\n",
    "      \n",
    "#     could do more of a common build api\n",
    "    def get_None_tensor(self):\n",
    "        tensor = torch.zeros(1, 1, self.vocab_size)\n",
    "        tensor[0][0][self.char2index[None]] = 1\n",
    "        return tensor\n",
    "    \n",
    "    def list_to_tensor(self, input_list):\n",
    "        tensor = torch.zeros(len(input_list), 1, self.vocab_size)\n",
    "        for elt in input_list:\n",
    "            tensor[li][0][self.char2index[letter]] = 1\n",
    "            \n",
    "#     def get_training_pair(self, line):\n",
    "        \n",
    "        \n",
    "    \n",
    "    def get_new_line_tensor(self):\n",
    "        tensor = torch.zeros(1, 1, self.vocab_size)\n",
    "        tensor[0][0][self.char2index[\"\\n\"]] = 1\n",
    "        return tensor\n",
    "\n",
    "        \n",
    "#         tensor[li][0][self.char2index[letter]] \n",
    "#         temp \n",
    "    def unicodeToAscii(self,s):\n",
    "        return ''.join(\n",
    "            c for c in unicodedata.normalize('NFD', s)\n",
    "            if unicodedata.category(c) != 'Mn'\n",
    "            and c in self.char2index\n",
    "        )\n",
    "\n",
    "    def __init__(self, text_file,  convert_to_ascii = True):\n",
    "        self.string = string\n",
    "        self.text_file = text_file\n",
    "\n",
    "        self.training_examples = []\n",
    "\n",
    "        total_inputs = []\n",
    "        total_outputs = []\n",
    "        \n",
    "#         make the vocab\n",
    "        self.full_vocab()\n",
    "        \n",
    "        with open(text_file) as file:\n",
    "            for raw_line in file:\n",
    "                \n",
    "                line = self.unicodeToAscii(raw_line) if convert_to_ascii else raw_line\n",
    "                # zero pad to start\n",
    "                \n",
    "                \n",
    "#                 think about how to make this a vector or tensor line! \n",
    "#                 print()\n",
    "                \n",
    "#                 inputs = self.get_None_tensor() + line_to_tensor(line)\n",
    "#                 inputs = [None] + [x for x in line]\n",
    "                inputs = self.lineToTensor([None] + [x for x in line])\n",
    "                \n",
    "                targets = self.lineToTensor([x for x in line] + [\"\\n\"])  # we need a 0 as well!\n",
    "\n",
    "                # append: will be a list of list (of lines)\n",
    "                # extend: will be a list of lines\n",
    "                total_inputs.append(inputs)\n",
    "                total_outputs.append(targets)\n",
    "\n",
    "        assert len(total_inputs) == len(total_outputs)\n",
    "        \n",
    "        # this is now a LIST of lists!\n",
    "        self.total_examples = list(zip(total_inputs, total_outputs))\n",
    "        \n",
    "        #                 for char in line:\n",
    "        # how many chars before the target? or all chars before the target?\n",
    "        # so we simply pair up x with [x+1] i think\n",
    "        # ok, and then we iterate them in the loader?\n",
    "        #                     inputs = [x for x in ]\n",
    "        #                     targets = []\n",
    "\n",
    "        # we should also have some big list of entries \n",
    "\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    # ok, now let us just try adding the transforms\n",
    "    # actually the transforms should take responsibility for all of the vocab stuff\n",
    "    \n",
    "    # number of items in the dataset. This involves a rather large computation!\n",
    "    # we can either do a feed forward cllm in the style of bengio, or we can just \n",
    "    # do the RNN approach (as specified by Sean Robertson in his tutorial)\n",
    "\n",
    "    # the indices should represent examples inside the list\n",
    "    # one strange thing is the following: we need to precompute al the indices earlier, imo, and then simply return the list\n",
    "    # at that element! (perhaps with some transforms!)\n",
    "    def __getitem__(self, index):\n",
    "        return self.total_examples[index]\n",
    "\n",
    "        # build a list, return elements from that list? we need to internally keep track of some index\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# ok, so it works now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "abc = TextDataset(os.path.join(\"data\", \"names\", \"English.txt\"), False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(abc.char2index[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.generate_tensor_for_char(\"a\")\n",
    "# abc.index2char[2]\n",
    "abc.lineToTensor(\"abcd\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for (a,b) in abc:\n",
    "    pass\n",
    "#     this should give two lines/tests\n",
    "#     print(a,b)\n",
    "#     print()\n",
    "    \n",
    "#     realistically, we should also have it as tensors/vectors\n",
    "# finally, we should also have some way where we run the rnn forward and \n",
    "#  iteratoring over the set, does not consume the elements! It is not a genertor! Rather, we simply index into the elements we would like\n",
    "for(a,b) in abc:\n",
    "    pass\n",
    "#     print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_x = [None] + [\"e\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ok, so now let's just do the stuff\n",
    "# the RNN actually makes one-character over predictions! \n",
    "# rnn_forward is a utility function that does a lot of stuff\n",
    "len(char_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok, so now we can start building the network that will process these!!\n",
    "# simply: iterate the dataset, and run train on it, do the log likelihood and etc.\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "    \n",
    "n_hidden = 128\n",
    "\n",
    "\n",
    "rnn = RNN(abc.vocab_size, n_hidden, abc.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.lineToTensor(\"we\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# WE NEED THIS LINE TO RESET THE RNN!!\n",
    "rnn = RNN(abc.vocab_size, n_hidden, abc.vocab_size)\n",
    "learning_rate = 0.0005 # If you set this too high, it might explode. If too low, it might not learn\n",
    "#  we had to set it a big lower to force convergence\n",
    "\n",
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(rnn.parameters(), lr = 0.01)\n",
    "\n",
    "# returns the loss for a line\n",
    "\n",
    "def train(input_tensor, target_tensor):\n",
    "    \n",
    "        \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "#     print (input_tensor)\n",
    "    \n",
    "#     print(\"changed3\")\n",
    "#     print(input_tensor[1])\n",
    "    criterion = nn.NLLLoss()    \n",
    "    hidden = rnn.initHidden()\n",
    "    loss = 0\n",
    "    rnn.zero_grad()\n",
    "#     print(input_tensor.size())\n",
    "#     print(target_tensor[0])\n",
    "#     print(target_tensor)\n",
    "    for i in range(input_tensor.size()[0]):\n",
    "        output, hidden = rnn(input_tensor[i], hidden)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         find where the one is:\n",
    "# \n",
    "#         torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "        max_tensor = torch.argmax(target_tensor[i])\n",
    "#         print(max_tensor)\n",
    "        ind = (torch.argmax(target_tensor[i])).item()\n",
    "#         print(\"this the target\")\n",
    "#         print(target_tensor[i])\n",
    "#         print(ind)\n",
    "        true_target_tensor = torch.tensor([ind], dtype=torch.long)\n",
    "    \n",
    "#     Evaluate the loss on each character!\n",
    "        loss += criterion(output, true_target_tensor)\n",
    "        \n",
    "#         expects JUST a single target class:\n",
    "\n",
    "#     print (\"loss for i \" + str(loss.item()))    \n",
    "#         print()\n",
    "# should be do the loss on each thing, or each batch! no, we should accumulate it! \n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "#     for p in rnn.parameters():\n",
    "#         p.data.add_(-learning_rate, p.grad.data)\n",
    "\n",
    "    return output, loss.item()\n",
    "\n",
    "# why not run this just on all the tensors!! \n",
    "\n",
    "# then, we just call it with the dataset class, and then just iterate everything!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.index2char[0]\n",
    "abc.index2char[1]\n",
    "\n",
    "abc.char2index[\"A\"]\n",
    "\n",
    "# ok some weird stuff here...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (x,y) in abc:\n",
    "#     print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3668/3668 [00:13<00:00, 262.72it/s]\n",
      "  1%|          | 29/3668 [00:00<00:12, 285.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss is 38.76116996569564\n",
      "per character loss is 4.615893555814826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3668/3668 [00:14<00:00, 261.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss is 38.76116996569564\n",
      "per character loss is 4.615893555814826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# del rnn\n",
    "rnn = RNN(abc.vocab_size, n_hidden, abc.vocab_size)\n",
    "\n",
    "epoch_loss = 0\n",
    "# loss every k iters\n",
    "# \n",
    "total_loss = 0\n",
    "total_length  = 0\n",
    "epoch_length = 0\n",
    "\n",
    "\n",
    "num_epochs = 2\n",
    "for k in range(num_epochs ):\n",
    "    \n",
    "    for i,(x,y) in enumerate(tqdm(abc)):\n",
    "    #     print(x)\n",
    "    #     print(x)\n",
    "    #     print(y)\n",
    "        _, loss = train(x,y)\n",
    "        epoch_loss += loss\n",
    "        epoch_length += x.size()[0]\n",
    "        total_loss += loss\n",
    "        total_length += x.size()[0]\n",
    "\n",
    "    #     print(i)\n",
    "    #     abc = i\n",
    "#         if i % 100 == 0:\n",
    "#             print (\"loss for {} is {}\".format(i,other_loss/100))\n",
    "#             other_loss = 0\n",
    "    \n",
    "    print(\"epoch {} loss is {}\".format(k, epoch_loss/i))\n",
    "    print(\"per character loss is {}\".format(epoch_loss/epoch_length))\n",
    "    epoch_loss = 0\n",
    "    epoch_length = 0\n",
    "#     ideally: we would be able to compute the quintile losses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the entire model under the given filename\n",
    "def save_model(model,filename):\n",
    "    torch.save(model, filename)\n",
    "    \n",
    "    return\n",
    "\n",
    "# Saves the model parameters only (for maximum usability)\n",
    "\n",
    "def save_model_params(model, filename):\n",
    "\n",
    "    torch.save(model.state_dict(), filename)\n",
    "\n",
    "    return filename\n",
    "\n",
    "#  ideally, I could get per character loss, then I would also be able to get the total expected loss\n",
    "# so: we want to get total loss, then divide it by all the length of the number of examples we saw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_params(filename):\n",
    "    model = RNN(abc.vocab_size, n_hidden, abc.vocab_size)\n",
    "    model.load_state_dict(torch.load(filename))\n",
    "    return model #vs return model.eval()??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"draft_TEST.pt\"\n",
    "\n",
    "if True:\n",
    "\n",
    "    filename = save_model_params(rnn, \"draft_TEST.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (i2h): Linear(in_features=229, out_features=128, bias=True)\n",
       "  (i2o): Linear(in_features=229, out_features=101, bias=True)\n",
       "  (softmax): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model = load_model_from_params(filename)\n",
    "eval_model.eval() # this is a mutating operation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# returns the loss for the entire line (requires normalization for comparison)\n",
    "def get_loss_on_line(rnn, line):\n",
    "    input_tensor =  abc.lineToTensor([None] + [x for x in line])\n",
    "    target_tensor = abc.lineToTensor([x for x in line] + [\"\\n\"])\n",
    "    criterion = nn.NLLLoss()    \n",
    "    hidden = rnn.initHidden()\n",
    "    loss = 0\n",
    "    rnn.zero_grad()\n",
    "    \n",
    "    \n",
    "#     print(input_tensor.size())\n",
    "#     print(target_tensor[0])\n",
    "#     print(target_tensor)\n",
    "    for i in range(input_tensor.size()[0]):\n",
    "        output, hidden = rnn(input_tensor[i], hidden)\n",
    "        \n",
    "        \n",
    "        # had to do this simply because of how the NLLL and CrossEntropy are defined\n",
    "        max_tensor = torch.argmax(target_tensor[i])\n",
    "        ind = (torch.argmax(target_tensor[i])).item()\n",
    "        true_target_tensor = torch.tensor([ind], dtype=torch.long)\n",
    "    \n",
    "#     Evaluate the loss on each character!\n",
    "        loss += criterion(output, true_target_tensor)\n",
    "    \n",
    "    return loss.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.568442153930664\n"
     ]
    }
   ],
   "source": [
    "# out = eval_model)\n",
    "\n",
    "# so there's a couple possibilities: we can have jim and ask to predict as well as just get the loss of the example\n",
    "# out = train()\n",
    "# ()\n",
    "#lineToTensor\n",
    "\n",
    "# get it as tensors, then run it, then do loss addition\n",
    "\n",
    "STRING_TO_TEST =  \"David\"\n",
    "print(get_loss_on_line(eval_model, STRING_TO_TEST )/len(STRING_TO_TEST ))\n",
    "\n",
    "# we now want to implement sampling:\n",
    "#  is that useful though? \n",
    "# will it be good?\n",
    "# instead, we can also try and get text for the inputs \n",
    "#  then train on that, then run it on some numerical numbers\n",
    "\n",
    "# visualization would be super useful \n",
    "# for pretty printing, we can colour the terminal output\n",
    "# otherwise, we will need to somehow encode the colour so that it is output to the file\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  print(\"\\x1b[31m\\\"red\\\"\\x1b[0m\")\n",
    "\n",
    "# if no thresholding, then we should at least like somehow graphically display?\n",
    "# no,... this is a different concern. Don't put frontend and backend together! (or visualization and etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Fore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mBilly\n",
      "\n",
      "loss2.187842686971029\n",
      "\u001b[34mJoe\n",
      "\n",
      "loss2.927530288696289\n",
      "\u001b[34mBob\n",
      "\n",
      "loss3.550493001937866\n",
      "\u001b[34mThornton\n",
      "\n",
      "loss1.9199905395507812\n",
      "\u001b[34mElliot\n",
      "\n",
      "loss2.500835418701172\n",
      "\u001b[34mRandom\n",
      "\n",
      "loss2.389070783342634\n",
      "\u001b[34mderivative\n",
      "\n",
      "loss3.6175897771661933\n",
      "\u001b[31m';3[39\n",
      "\n",
      "loss8.677899496895927\n",
      "\u001b[31mj0hn_person1\n",
      "\n",
      "loss5.2926177978515625\n",
      "\u001b[34mEnglish\n",
      "\n",
      "loss2.915396213531494\n",
      "\u001b[31mwkijkq\n",
      "\n",
      "loss6.433131626674107\n",
      "\u001b[34mWord\n",
      "\n",
      "loss1.381985855102539\n",
      "\u001b[31mAdditional_names\n",
      "\n",
      "loss4.289423325482537\n",
      "\u001b[31mQuixotic\n",
      "\n",
      "loss4.087853749593099\n",
      "\u001b[31m24uirfejkfk\n",
      "\n",
      "loss6.100430170694987\n",
      "\u001b[34mJavier\n",
      "\n",
      "loss2.5835887363978793\n",
      "\u001b[34mJason\n",
      "\n",
      "loss2.2196717262268066\n",
      "\u001b[31mJiao\n",
      "\n",
      "loss4.139523696899414\n",
      "\u001b[34mChen\n",
      "\n",
      "loss2.830333137512207\n",
      "\u001b[34mAkshay\n",
      "\n",
      "loss2.998241424560547\n",
      "\u001b[34mMbaay\n",
      "\n",
      "loss3.496740976969401\n",
      "\u001b[34mGovind\n",
      "loss3.070594151814779\n"
     ]
    }
   ],
   "source": [
    "# print(Fore.RED + \"yoo\")\n",
    "\n",
    "# print(Fore.BLUE + \"haha\")\n",
    "\n",
    "# if on average more than twice as high loss on this sample, then we should flag it for further review\n",
    "THRESHOLD =  1.8332151545300774 * 2\n",
    "\n",
    "\n",
    "# some more powerful model: uses LSTM as well as additional fields and operators!\n",
    "# ok, so now let us just iterate the text file\n",
    "with open(os.path.join(\"data\",\"test-cases.txt\"), \"r\") as file:\n",
    "    for line in file:\n",
    "        example_loss = get_loss_on_line(eval_model, line)/len(line )\n",
    "        if (example_loss > THRESHOLD):\n",
    "            print(Fore.RED + line)\n",
    "        else:\n",
    "            print(Fore.BLUE + line)\n",
    "        \n",
    "        print(\"loss\" + str(example_loss))\n",
    "    \n",
    "# perhaps we should train on google news corpus for a little while..\n",
    "# this \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('reuters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anaconda3  ec2_final\t    nltk_data\t\t    sandbox.ipynb\n",
      "cllm_rnn   environment.yml  reuters_news_10000.txt  TextDataset.ipynb\n"
     ]
    }
   ],
   "source": [
    "! ls /home/ubuntu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")\n",
    "\n",
    "# sentences = reuters.raw().splitlines()\n",
    "# print(reuters.raw())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    print(type(sentences))\n",
    "    print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# these are not exactly tokenized on sentences; but that is OK!\n",
    "# sentences[:100]\n",
    "if False:\n",
    "    with open(\"reuters_news.txt\", \"w\") as file:\n",
    "        file.write(reuters.raw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need a smaller dataset for development\n",
    "# so, let's cut up the reuters into smaller (for example, load just the first K bytes of the file.)\n",
    "import time\n",
    "\n",
    "def make_proto_dataset(size):\n",
    "    with open(\"reuters_news_{}.txt\".format(size), \"w\") as file:\n",
    "        \n",
    "        \n",
    "        file.write('\\n'.join(reuters.raw().splitlines()[0:size]))\n",
    "    print(\"file created with {} lines\".format(size))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     the question now is how many neurons and the architecture to use\n",
    "# we can also look into enhancement with the tqdm inside the object?\n",
    "\n",
    "if False:\n",
    "    start = time.time()\n",
    "\n",
    "\n",
    "    make_proto_dataset(10000)\n",
    "    elapsed = time.time() - start\n",
    "    print(\"elapsed time is {}\".format(elapsed ))\n",
    "\n",
    "# jeez, so it takes more than 8 minutes to create the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time is 6.738259315490723\n"
     ]
    }
   ],
   "source": [
    "# reuters dataset has umlauts and other non-standard characters, so we should try and account for that! \n",
    "# also: we should try and do a sort of full merge: merge between the train dataset and test dataset vocabs\n",
    "# other than that, we can just apply a regularizer to both sets, to get out the processed data\n",
    "# for now, let's just apply a regularization\n",
    "import time\n",
    "start = time.time()\n",
    "reuters_dataset = TextDataset( \"reuters_news_10000.txt\", True)\n",
    "elapsed = time.time() - start\n",
    "print(\"elapsed time is {}\".format(elapsed ))\n",
    "\n",
    "# jeez, so it takes more than 8 minutes to create the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(reuters_dataset))\n",
    "from tqdm import tqdm\n",
    "def general_train_function(dataset):\n",
    "# del rnn\n",
    "# rnn = RNN(abc.vocab_size, n_hidden, abc.vocab_size)\n",
    "\n",
    "    epoch_loss = 0\n",
    "    # loss every k iters\n",
    "    # \n",
    "    loss_per_k = 0\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_length  = 0\n",
    "    epoch_length = 0\n",
    "\n",
    "\n",
    "    num_epochs = 1\n",
    "    \n",
    "    for k in range(num_epochs ):\n",
    "\n",
    "        for i,(x,y) in enumerate(tqdm(dataset)):\n",
    "        #     print(x)\n",
    "        #     print(x)\n",
    "        #     print(y)\n",
    "            _, loss = train(x,y)\n",
    "            epoch_loss += loss\n",
    "            epoch_length += x.size()[0]\n",
    "            total_loss += loss\n",
    "            total_length += x.size()[0]\n",
    "            loss_per_k += loss\n",
    "        #     print(i)\n",
    "        #     abc = i\n",
    "        \n",
    "            # for the first 100 iters, print the loss of every line!\n",
    "#             if i < 100:\n",
    "#                 print (\"loss for {} is {}\".format(i,epoch_loss/(i+1)))\n",
    "                \n",
    "            \n",
    "            if i % 100 == 0 and i != 0:\n",
    "                print (\"loss for {} is {}\".format(i,loss_per_k/100))\n",
    "                loss_per_k = 0\n",
    "                \n",
    "\n",
    "        print(\"epoch {} loss is {}\".format(k, epoch_loss/i))\n",
    "        print(\"per character loss is {}\".format(epoch_loss/epoch_length))\n",
    "        epoch_loss = 0\n",
    "        epoch_length = 0\n",
    "#     ideally: we would be able to compute the quintile losses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# WE NEED THIS LINE TO RESET THE RNN!!\n",
    "rnn = RNN(reuters_dataset.vocab_size, 512, reuters_dataset.vocab_size)\n",
    "rnn = reuters_model\n",
    "learning_rate = 0.0005 # If you set this too high, it might explode. If too low, it might not learn\n",
    "#  we had to set it a big lower to force convergence\n",
    "\n",
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(rnn.parameters(), lr = 0.0001)\n",
    "\n",
    "# returns the loss for a line\n",
    "\n",
    "def general_train(input_tensor, target_tensor):\n",
    "    \n",
    "        \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "#     print (input_tensor)\n",
    "    \n",
    "#     print(\"changed3\")\n",
    "#     print(input_tensor[1])\n",
    "    criterion = nn.NLLLoss()    \n",
    "    hidden = rnn.initHidden()\n",
    "    loss = 0\n",
    "    rnn.zero_grad()\n",
    "#     print(input_tensor.size())\n",
    "#     print(target_tensor[0])\n",
    "#     print(target_tensor)\n",
    "    for i in range(input_tensor.size()[0]):\n",
    "        output, hidden = rnn(input_tensor[i], hidden)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         find where the one is:\n",
    "# \n",
    "#         torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "        max_tensor = torch.argmax(target_tensor[i])\n",
    "#         print(max_tensor)\n",
    "        ind = (torch.argmax(target_tensor[i])).item()\n",
    "#         print(\"this the target\")\n",
    "#         print(target_tensor[i])\n",
    "#         print(ind)\n",
    "        true_target_tensor = torch.tensor([ind], dtype=torch.long)\n",
    "    \n",
    "#     Evaluate the loss on each character!\n",
    "        loss += criterion(output, true_target_tensor)\n",
    "        \n",
    "#         expects JUST a single target class:\n",
    "\n",
    "#     print (\"loss for i \" + str(loss.item()))    \n",
    "#         print()\n",
    "# should be do the loss on each thing, or each batch! no, we should accumulate it! \n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "#     for p in rnn.parameters():\n",
    "#         p.data.add_(-learning_rate, p.grad.data)\n",
    "\n",
    "    return output, loss.item()\n",
    "\n",
    "# why not run this just on all the tensors!! \n",
    "\n",
    "# then, we just call it with the dataset class, and then just iterate everything!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 103/10000 [00:03<04:44, 34.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 100 is 251.97255268096924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 204/10000 [00:06<05:10, 31.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 200 is 234.6040403652191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 306/10000 [00:09<05:40, 28.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 300 is 234.4470827102661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 404/10000 [00:13<05:16, 30.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 400 is 212.36662675857545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 505/10000 [00:16<04:24, 35.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 500 is 186.90268845558165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 604/10000 [00:19<05:26, 28.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 600 is 181.76997879981994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 706/10000 [00:22<04:22, 35.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 700 is 177.357438955307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 803/10000 [00:25<05:03, 30.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 800 is 166.35841693878174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 905/10000 [00:28<04:33, 33.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 900 is 188.44637283325196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1003/10000 [00:31<04:46, 31.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 1000 is 177.94423122406005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1104/10000 [00:34<04:21, 34.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 1100 is 173.52205041885375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1209/10000 [00:37<03:49, 38.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 1200 is 167.32943879127504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1306/10000 [00:41<04:57, 29.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 1300 is 180.05056740760804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1405/10000 [00:44<04:41, 30.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 1400 is 174.26244561195372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 1509/10000 [00:47<03:55, 36.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 1500 is 163.73068364143373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1611/10000 [00:50<03:15, 42.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 1600 is 151.5397739124298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1705/10000 [00:52<03:47, 36.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 1700 is 122.43813943862915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1808/10000 [00:55<03:31, 38.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 1800 is 156.80732619285584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1905/10000 [00:58<04:41, 28.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 1900 is 165.22236526489257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2010/10000 [01:00<02:43, 48.90it/s]"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    general_train_function(reuters_dataset)\n",
    "# perhaps: examine the gradient instead!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# returns the loss for a line, evaluating on a BASIC rnn, and using the provided optimizer\n",
    "def prototype_general_train(input_tensor, target_tensor, basic_rnn, optimizer):\n",
    "    \n",
    "        \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    criterion = nn.NLLLoss()    \n",
    "    hidden = rnn.initHidden()\n",
    "    loss = 0\n",
    "    basic_rnn.zero_grad()\n",
    "    for i in range(input_tensor.size()[0]):\n",
    "        output, hidden = basic_rnn(input_tensor[i], hidden)\n",
    "        \n",
    "        max_tensor = torch.argmax(target_tensor[i])\n",
    "        ind = (torch.argmax(target_tensor[i])).item()\n",
    "        true_target_tensor = torch.tensor([ind], dtype=torch.long)\n",
    "        #     Evaluate the loss on each character!\n",
    "        loss += criterion(output, true_target_tensor)\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return output, loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    save_model_params(rnn, \"reuters_model_new.pt\")\n",
    "\n",
    "# an rnn class could save some config info like the below!\n",
    "def load_model_from_params_reuters(filename):\n",
    "    print(\"running\")\n",
    "#     print(torch.load(filename))\n",
    "    \n",
    "#     print(reuters_dataset.vocab_size)\n",
    "    model = RNN(reuters_dataset.vocab_size, 512, reuters_dataset.vocab_size)\n",
    "#     model = RNN(abc.vocab_size, n_hidden, abc.vocab_size)\n",
    "    model.load_state_dict(torch.load(filename))\n",
    "    return model\n",
    "\n",
    "# reuters_model = load_model_from_params_reuters(\"reuters_model.pt\")\n",
    "reuters_model = load_model_from_params_reuters(\"reuters_model_new.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (i2h): Linear(in_features=613, out_features=512, bias=True)\n",
      "  (i2o): Linear(in_features=613, out_features=101, bias=True)\n",
      "  (softmax): LogSoftmax()\n",
      ")\n",
      "RNN(\n",
      "  (i2h): Linear(in_features=613, out_features=512, bias=True)\n",
      "  (i2o): Linear(in_features=613, out_features=101, bias=True)\n",
      "  (softmax): LogSoftmax()\n",
      ")\n",
      "<function load_model_from_params_reuters at 0x7f15c1f990d0>\n"
     ]
    }
   ],
   "source": [
    "print(rnn)\n",
    "print(reuters_model)\n",
    "print(load_model_from_params_reuters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anyway, now let us try running it line by line on a sample abstract dataset\n",
    "import json\n",
    "import os\n",
    "with open(os.path.join(\"dataXplorer\", \"result.json\")) as file:\n",
    "    data  = json.load(file)\n",
    "\n",
    "\n",
    "for key in data:\n",
    "#     print(key)\n",
    "#     print(data[key])\n",
    "    pass\n",
    "    \n",
    "sample_phrase = \"Hello. You are cool.\"\n",
    "for key in data:\n",
    "    sample_phrase = data[key] \n",
    "    break\n",
    "    \n",
    "    \n",
    "# now we just need to cut up the stuff\n",
    "# we can try a tokenizer (for example, nltk tokenizer) \n",
    "# or perhaps we can try moses tokenizer\n",
    "# recall we learnt lots about tokenization at some point: stat tokenizer?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_list = sent_tokenize(sample_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import reuters\n",
    "# nltk.download('reuters')\n",
    "# reuters.raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' The most common differential diagnosis of β-thalassemia (β-thal) trait is iron deficiency anemia.',\n",
       " 'Several red blood cell equations were introduced during different studies for differential diagnosis between β-thal trait and iron deficiency anemia.',\n",
       " 'Due to genetic variations in different regions, these equations cannot be useful in all population.',\n",
       " 'The aim of this study was to determine a native equation with high accuracy for differential diagnosis of β-thal trait and iron deficiency anemia for the Sistan and Baluchestan population by logistic regression analysis.',\n",
       " 'We selected 77 iron deficiency anemia and 100 β-thal trait cases.',\n",
       " 'We used binary logistic regression analysis and determined best equations for probability prediction of β-thal trait against iron deficiency anemia in our population.',\n",
       " 'We compared diagnostic values and receiver operative characteristic (ROC) curve related to this equation and another 10 published equations in discriminating β-thal trait and iron deficiency anemia.',\n",
       " 'The binary logistic regression analysis determined the best equation for best probability prediction of β-thal trait against iron deficiency anemia with area under curve (AUC) 0.998.',\n",
       " 'Based on ROC curves and AUC, Green & King, England & Frazer, and then Sirdah indices, respectively, had the most accuracy after our equation.',\n",
       " 'We suggest that to get the best equation and cut-off in each region, one needs to evaluate specific information of each region, specifically in areas where populations are homogeneous, to provide a specific formula for differentiating between β-thal trait and iron deficiency anemia.']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok so this will do what we want then!!\n",
    "\n",
    "# now, it is just a matter of making the dataset then\n",
    "# test sentences:\n",
    "count = 0\n",
    "training_examples = []\n",
    "with open(\"testing_samples.txt\", \"w\") as file:\n",
    "    for key in data:\n",
    "        lines = sent_tokenize(data[key])\n",
    "        for line in lines:\n",
    "            training_examples.append(line)\n",
    "            file.write(\"\\n\")\n",
    "            file.write(line)\n",
    "            count+=1\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1019\n"
     ]
    }
   ],
   "source": [
    "# print(len())\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.57561072524713\n",
      " The most common differential diagnosis of β-thalassemia (β-thal) trait is iron deficiency anemia.\n",
      "4.621365335963716\n",
      "Several red blood cell equations were introduced during different studies for differential diagnosis between β-thal trait and iron deficiency anemia.\n",
      "4.668588041055082\n",
      "Due to genetic variations in different regions, these equations cannot be useful in all population.\n",
      "4.618717817826704\n",
      "The aim of this study was to determine a native equation with high accuracy for differential diagnosis of β-thal trait and iron deficiency anemia for the Sistan and Baluchestan population by logistic regression analysis.\n",
      "4.6145883413461535\n",
      "We selected 77 iron deficiency anemia and 100 β-thal trait cases.\n",
      "4.619775978915663\n",
      "We used binary logistic regression analysis and determined best equations for probability prediction of β-thal trait against iron deficiency anemia in our population.\n",
      "4.624330771089804\n",
      "We compared diagnostic values and receiver operative characteristic (ROC) curve related to this equation and another 10 published equations in discriminating β-thal trait and iron deficiency anemia.\n",
      "4.617566789899554\n",
      "The binary logistic regression analysis determined the best equation for best probability prediction of β-thal trait against iron deficiency anemia with area under curve (AUC) 0.998.\n",
      "4.646327241938165\n",
      "Based on ROC curves and AUC, Green & King, England & Frazer, and then Sirdah indices, respectively, had the most accuracy after our equation.\n",
      "4.6160099312610425\n",
      "We suggest that to get the best equation and cut-off in each region, one needs to evaluate specific information of each region, specifically in areas where populations are homogeneous, to provide a specific formula for differentiating between β-thal trait and iron deficiency anemia.\n",
      "4.655984629755435\n",
      " Reporting of surgical complications is common, but few provide information about the severity and estimate risk factors of complications.\n",
      "4.763862378669508\n",
      "If have, but lack of specificity.\n",
      "4.636764090401786\n",
      "We retrospectively analyzed data on 2795 gastric cancer patients underwent surgical procedure at the Affiliated Hospital of Qingdao University between June 2007 and June 2012, established multivariate logistic regression model to predictive risk factors related to the postoperative complications according to the Clavien-Dindo classification system.\n",
      "4.643603974105047\n",
      "Twenty-four out of 86 variables were identified statistically significant in univariate logistic regression analysis, 11 significant variables entered multivariate analysis were employed to produce the risk model.\n",
      "4.640185397095475\n",
      "Liver cirrhosis, diabetes mellitus, Child classification, invasion of neighboring organs, combined resection, introperative transfusion, Billroth II anastomosis of reconstruction, malnutrition, surgical volume of surgeons, operating time and age were independent risk factors for postoperative complications after gastrectomy.\n",
      "4.608159658071157\n",
      "Based on logistic regression equation, p=Exp∑BiXi / (1+Exp∑BiXi), multivariate logistic regression predictive model that calculated the risk of postoperative morbidity was developed, p = 1/(1 + e((4.810-1.287X1-0.504X2-0.500X3-0.474X4-0.405X5-0.318X6-0.316X7-0.305X8-0.278X9-0.255X10-0.138X11))).\n",
      "4.650600760323661\n",
      "The accuracy, sensitivity and specificity of the model to predict the postoperative complications were 86.7%, 76.2% and 88.6%, respectively.\n",
      "4.632130015980113\n",
      "This risk model based on Clavien-Dindo grading severity of complications system and logistic regression analysis can predict severe morbidity specific to an individual patient's risk factors, estimate patients' risks and benefits of gastric surgery as an accurate decision-making tool and may serve as a template for the development of risk models for other surgical groups.\n",
      "4.638318562057783\n",
      " While many studies have investigated neck strain in helicopter aircrew, no one study has used a comprehensive approach involving multivariate analysis of questionnaire data in combination with physiological results related to the musculature of the cervical spine.\n",
      "4.641386405049755\n",
      "There were 40 aircrew members who provided questionnaire results detailing lifetime prevalence of neck pain, flight history, physical fitness results, and physiological variables.\n",
      "4.636797093633396\n",
      "Isometric testing data for flexion (Flx), extension (Ext), and right (RFlx) and left (LFlx) lateral flexion of the cervical spine that included maximal voluntary contraction (MVC) force and submaximal exercise at 70% MCV until time-to-fatigue (TTF) was also collected.\n",
      "4.639509137167314\n",
      "Muscles responsible for the work performed were monitored with electromyography (EMG) and near-infrared spectroscopy (NIRS) and the associated ratings of perceived exertion (RPE) were collected simultaneously.\n",
      "4.655877064850371\n",
      "Results were compiled and analyzed by logistic regression to identify the variables that were predictive of neck pain.\n",
      "4.656690095600329\n",
      "While many variables were included in the logistic regression, the final regression equation required two, easy to measure variables.\n",
      "4.638022093646295\n",
      "The longest single night vision goggle (NVG) mission (NVGmax; h) combined with the height of the aircrew member in meters (m) provided an accurate logistic regression equation for approximately one-half of our sample (N = 19).\n",
      "4.684510080437911\n",
      "Cross-validation of the remaining subjects (N = 21) confirmed this accuracy.\n",
      "4.651213727678571\n",
      "Our regression equation is simple and can be used by global operational units to provide a cursory assessment without the need for acquiring specialized equipment or training.\n",
      "4.632433899836753\n",
      " Motivated by an investigation of the effect of surface water temperature on the presence of Vibrio cholerae in water samples collected from different fixed surface water monitoring sites in Haiti in different months, we investigated methods to adjust for unmeasured confounding due to either of the two crossed factors site and month.\n",
      "4.639921519677964\n",
      "In the process, we extended previous methods that adjust for unmeasured confounding due to one nesting factor (such as site, which nests the water samples from different months) to the case of two crossed factors.\n",
      "4.650664180158133\n",
      "First, we developed a conditional pseudolikelihood estimator that eliminates fixed effects for the levels of each of the crossed factors from the estimating equation.\n",
      "4.641864670225349\n",
      "Using the theory of U-Statistics for independent but non-identically distributed vectors, we show that our estimator is consistent and asymptotically normal, but that its variance depends on the nuisance parameters and thus cannot be easily estimated.\n",
      "4.64454053795856\n",
      "Consequently, we apply our estimator in conjunction with a permutation test, and we investigate use of the pigeonhole bootstrap and the jackknife for constructing confidence intervals.\n",
      "4.65302373321963\n",
      "We also incorporate our estimator into a diagnostic test for a logistic mixed model with crossed random effects and no unmeasured confounding.\n",
      "4.678377398322611\n",
      "For comparison, we investigate between-within models extended to two crossed factors.\n",
      "4.648658859897667\n",
      "These generalized linear mixed models include covariate means for each level of each factor in order to adjust for the unmeasured confounding.\n",
      "4.678533453690378\n",
      "We conduct simulation studies, and we apply the methods to the Haitian data.\n",
      "4.6122692108154295\n",
      "Copyright © 2016 John Wiley & Sons, Ltd.\n",
      "4.63037829928928\n",
      " When analyzing longitudinal data, it is essential to account both for the correlation inherent from the repeated measures of the responses as well as the correlation realized on account of the feedback created between the responses at a particular time and the predictors at other times.\n",
      "4.658795273094847\n",
      "As such one can analyze these data using generalized estimating equation with the independent working correlation.\n",
      "4.636904832793445\n",
      "However, because it is essential to include all the appropriate moment conditions as you solve for the regression coefficients, we explore an alternative approach using a generalized method of moments for estimating the coefficients in such data.\n",
      "4.650452538359937\n",
      "We develop an approach that makes use of all the valid moment conditions necessary with each time-dependent and time-independent covariate.\n",
      "4.654793330601284\n",
      "This approach does not assume that feedback is always present over time, or if present occur at the same degree.\n",
      "4.668865781841856\n",
      "Further, we make use of continuously updating generalized method of moments in obtaining estimates.\n",
      "4.632780997983871\n",
      "We fit the generalized method of moments logistic regression model with time-dependent covariates using SAS PROC IML and also in R. We used p-values adjusted for multiple correlated tests to determine the appropriate moment conditions for determining the regression coefficients.\n",
      "4.70936554553462\n",
      "We examined two datasets for illustrative purposes.\n",
      "4.693263462611607\n",
      "We looked at re-hospitalization taken from a Medicare database.\n",
      "4.659482568726504\n",
      "We also revisited data regarding the relationship between the body mass index and future morbidity among children in the Philippines.\n",
      "4.671970762055496\n",
      "We conducted a simulated study to compare the performances of extended classifications.\n",
      "4.660135323660715\n",
      " Low specificity of PSA for early diagnosis of prostate cancer (PC) is the cause of search for new tests.\n",
      "4.645758897244574\n",
      "The aim of our study was to develop the logistic regression model and estimate the value of the regression equation as a diagnostic tool for prostate cancer detection.\n",
      "4.642782731489702\n",
      "A total of 518 male patients aged 47-83 years (mean 65.5 +/- 6.5 years) who had undergone TRUS-guided 12-core systematic transrectal prostate biopsy were included in the study.\n",
      "4.726325058355564\n",
      "PC detection rate in our study was 43.8%.\n",
      "4.641615988991477\n",
      "The logistic regression model with PC detection as a response and age, prostate volume, PSA, induration on DRE and hypoechoic lesion on TRUS as effects was designed.\n",
      "4.685452313490317\n",
      "With regression equation PC probability for any patient was calculated.\n",
      "4.70068359375\n",
      "The regression equation was tested as a PC diagnostic tool.\n",
      "4.641771559747274\n",
      "As the combination of model effects (chi-square 87.9; p < 0.0001; R2 = 0.124) any of the effects independently may predict prostate cancer detection.\n",
      "4.639176739386793\n",
      "The obtained regression equation is: P(Pca) = 1/{1 + 2.718(-[-4.029 + (0.068 x AGE) + (0.022 x PSA) + (-0013 x PROSTATE VOLUME) + (0.375 x DRE) + (0.254 x TRUS)])} Accuracy (area under ROC-curve) of our regression equation as a PC detection diagnostic tool was 73%.\n",
      "4.64200395407136\n",
      "Probability cutoff of 0.26 leads to sensitivity of 90% and specificity of 30% and eliminates 12% of unnecessary biopsies in patients with benign prostate diseases (chi-square 10.91; p < 0.0001).\n",
      "4.669711608886718\n",
      "Thus, the obtained logistic regression equation may be used as a PC diagnostic tool in the suspects.\n",
      "4.68031875401327\n",
      "Multicenter trial may improve regression equation diagnostic performance.\n",
      "4.648780585816188\n",
      " The authors derive a general equation to compute multiple cut-offs on a total test score in order to classify individuals into more than two ordinal categories.\n",
      "4.64771728515625\n",
      "The equation is derived from the multinomial logistic regression (MLR) model, which is an extension of the binary logistic regression (BLR) model to accommodate polytomous outcome variables.\n",
      "4.641184105063385\n",
      "From this analytical procedure, cut-off scores are established at the test score (the predictor variable) at which an individual is as likely to be in category j as in category j+1 of an ordinal outcome variable.\n",
      "4.653535936699539\n",
      "The application of the complete procedure is illustrated by an example with data from an actual study on eating disorders.\n",
      "4.646775787951899\n",
      "In this example, two cut-off scores on the Eating Attitudes Test (EAT-26) scores are obtained in order to classify individuals into three ordinal categories: asymptomatic, symptomatic and eating disorder.\n",
      "4.656019867443647\n",
      "Diagnoses were made from the responses to a self-report (Q-EDD) that operationalises DSM-IV criteria for eating disorders.\n",
      "4.6789933268229165\n",
      "Alternatives to the MLR model to set multiple cut-off scores are discussed.\n",
      "4.66701945852726\n",
      " A possible means of decreasing prostate cancer mortality is through improved early detection.\n",
      "4.678106198365661\n",
      "We attempted to create an equation to predict the likelihood of having prostate cancer.\n",
      "4.66455078125\n",
      "Between January 2005 and May 2008, patients who received prostate biopsies were retrospective evaluated.\n",
      "4.633265738983636\n",
      "The relationship between the possibility of prostate cancer and the following variables were evaluated: age; serum prostate specific antigen (PSA) level, prostate volume, numbers of prostatic biopsies, digital rectal examination (DRE) findings, and the presence of hypoechoic nodule under transrectal ultrasonography.\n",
      "4.646849067650031\n",
      "A multivariate regression model was created to predict the possibility of having prostate cancer, and a receiver-operating characteristic (ROC) curve was drawn based on the predictive scoring equation.\n",
      "4.585955914499696\n",
      "Using a predictive equation, P=1/(1-e(-x)), where X=-4.88,+1.11 (if DRE positive),+0.75 (if hypoechoic nodule of prostate present),+1.27 (when 7<PSA≤10),+2.02 (when 10<PSA≤24),+2.28 (when 24<PSA≤50),+3.93 (when 50<PSA),+1.23 (when 65<age≤75),+1.66 (when 75<age), followed by ROC curve analysis, we showed that the sensitivity was 88.5% and specificity was 79.1% in predicting the possibility of prostate cancer.\n",
      "4.65356209047379\n",
      "Clinicians can tailor each patient's follow-up according to the nomogram based on this equation to increase the efficacy of evaluating for prostate cancer.\n",
      "4.650871725643382\n",
      " To explore the method and performance of using multiple indices to diagnose sepsis and to predict the prognosis of severe ill patients.\n",
      "4.634034223211177\n",
      "Critically ill patients at first admission to intensive care unit (ICU) of Changzheng Hospital, Second Military Medical University, from January 2014 to September 2015 were enrolled if the following conditions were satisfied: (1) patients were 18-75 years old; (2) the length of ICU stay was more than 24 hours; (3) All records of the patients were available.\n",
      "4.6767416561351105\n",
      "Data of the patients was collected by searching the electronic medical record system.\n",
      "4.647254861811156\n",
      "Logistic regression model was formulated to create the new combined predictive indicator and the receiver operating characteristic (ROC) curve for the new predictive indicator was built.\n",
      "4.664975754758145\n",
      "The area under the ROC curve (AUC) for both the new indicator and original ones were compared.\n",
      "4.672778042879972\n",
      "The optimal cut-off point was obtained where the Youden index reached the maximum value.\n",
      "4.661433742357337\n",
      "Diagnostic parameters such as sensitivity, specificity and predictive accuracy were also calculated for comparison.\n",
      "4.662376791743909\n",
      "Finally, individual values were substituted into the equation to test the performance in predicting clinical outcomes.\n",
      "4.658519592285156\n",
      "A total of 362 patients (218 males and 144 females) were enrolled in our study and 66 patients died.\n",
      "4.6160227457682295\n",
      "The average age was (48.3±19.3) years old.\n",
      "4.638813283183787\n",
      "(1) For the predictive model only containing categorical covariants [including procalcitonin (PCT), lipopolysaccharide (LPS), infection, white blood cells count (WBC) and fever], increased PCT, increased WBC and fever were demonstrated to be independent risk factors for sepsis in the logistic equation.\n",
      "4.6458924989442565\n",
      "The AUC for the new combined predictive indicator was higher than that of any other indictor, including PCT, LPS, infection, WBC and fever (0.930 vs. 0.661, 0.503, 0.570, 0.837, 0.800).\n",
      "4.68374516413762\n",
      "The optimal cut-off value for the new combined predictive indicator was 0.518.\n",
      "4.651957194010417\n",
      "Using the new indicator to diagnose sepsis, the sensitivity, specificity and diagnostic accuracy rate were 78.00%, 93.36% and 87.47%, respectively.\n",
      "4.660089007878708\n",
      "One patient was randomly selected, and the clinical data was substituted into the probability equation for prediction.\n",
      "4.65408509529677\n",
      "The calculated value was 0.015, which was less than the cut-off value (0.518), indicating that the prognosis was non-sepsis at an accuracy of 87.47%.\n",
      "4.637604486374628\n",
      "(2) For the predictive model only containing continuous covariants, the logistic model which combined acute physiology and chronic health evaluation II (APACHE II) score and sequential organ failure assessment (SOFA) score to predict in-hospital death events, both APACHE II score and SOFA score were independent risk factors for death.\n",
      "4.66043317810563\n",
      "The AUC for the new predictive indicator was higher than that of APACHE II score and SOFA score (0.834 vs. 0.812, 0.813).\n",
      "4.639323066262638\n",
      "The optimal cut-off value for the new combined predictive indicator in predicting in-hospital death events was 0.236, and the corresponding sensitivity, specificity and diagnostic accuracy for the combined predictive indicator were 73.12%, 76.51% and 75.70%, respectively.\n",
      "4.65543212890625\n",
      "One patient was randomly selected, and the APACHE II score and SOFA score was substituted into the probability equation for prediction.\n",
      "4.652001179439921\n",
      "The calculated value was 0.570, which was higher than the cut-off value (0.236), indicating that the death prognosis at an accuracy of 75.70%.\n",
      "4.653439527366594\n",
      "The combined predictive indicator, which is formulated by logistic regression models, is superior to any single indicator in predicting sepsis or in-hospital death events.\n",
      "4.65146718860346\n",
      " To investigate the clinical features, characteristic of cochlear and vestibular dysfunction in Meniere's disease (MD) by using the multiple factor Logistic regression analysis.\n",
      "4.647722127051327\n",
      "The clinical data of 36 patients with the diagnosis of Meniere's disease according to 2006 Guiyang standard and 30 patients with peripheral vestibular disorders were investigated.\n",
      "4.641218665692446\n",
      "All subjects received audiologic and vestibular assessments, including pure tone audiometry, Metz's recruitment test, electrocochleography (ECochG), auditory brainstem response (ABR), glycerol test, vestibular caloric test, head shaking nystagmus (HSN) and fukuda stepping test.\n",
      "4.645677619806215\n",
      "The clinical features and audiovestibular tests in Meniere's disease were investigated by chi square test, and then analyzed by using the multiple factor Logistic regression mode.\n",
      "4.640337753295898\n",
      "(1) The fluctuating sensorineural hearing loss, the number of active symptoms, Tullio phenomenon,--SP/AP ratio, the Metz's recruitment test and the glycerol test demonstrated as the main characteristics in the discrimination between the MD group and non-MD group, the difference was statistically significant (P < 0.05).\n",
      "4.637058375071894\n",
      "(2) The Logistic regression predictive equation for Meniere's disease was: Logit(p) = 9.443 + 3.110 X1 + 5.015 X2 + 2.506 X3 + 3.963 X4, in which the concomitant variables were curve of electrocochleography (EcochG) (X1), glycerol test (X2), the number of active symptoms (X3), the fluctuating sensorineural hearing loss (X4).\n",
      "4.72556872245593\n",
      "The area under the ROC curve was 0.993.\n",
      "4.709663878095911\n",
      "The percentage of correct prediction was 95.5%.\n",
      "4.645531508501838\n",
      "The clinical features of Meniere's disease are distinguished, combined with audiovestibular tests, which can be differentiated from other peripheral vestibular disorders.\n",
      "4.665504521908967\n",
      "The multiple factor Logistic regression predictive equation for Meniere's disease is an auxiliary diagnosis method.\n",
      "4.651683498073268\n",
      " While patients with acute uncomplicated appendicitis may be treated conservatively, those who suffer from complicated appendicitis require surgery.\n",
      "4.645421645220588\n",
      "We describe a logistic regression equation to calculate the likelihood of acute uncomplicated appendicitis and complicated appendicitis in patients presenting to the emergency department with suspected acute appendicitis.\n",
      "4.670992896670387\n",
      "A cohort of 895 patients who underwent appendicectomy were analysed retrospectively.\n",
      "4.655809674944196\n",
      "Depending on the final histology, patients were divided into three groups; normal appendix, acute uncomplicated appendicitis and complicated appendicitis.\n",
      "4.648566441820157\n",
      "Normal appendix was considered the reference category, while acute uncomplicated appendicitis and complicated appendicitis were the nominal categories.\n",
      "4.643899035097948\n",
      "Multivariate and univariate regression models were undertaken to detect independent variables with significant odds ratio that can predict acute uncomplicated appendicitis and complicated appendicitis.\n",
      "4.6618544390412415\n",
      "Subsequently, a logistic regression equation was generated to produce the likelihood acute uncomplicated appendicitis and complicated appendicitis.\n",
      "4.650160310018128\n",
      "Pathological diagnosis of normal appendix, acute uncomplicated appendicitis and complicated appendicitis was identified in 188 (21%), 525 (59%) and 182 patients (20%), respectively.\n",
      "4.5975341796875\n",
      "The odds ratio from a univariate analysis to predict complicated appendicitis for age, female gender, log<sub>2</sub> white cell count, log<sub>2</sub> C-reactive protein and log<sub>2</sub> bilirubin were 1.02 (95% confidence interval, CI, 1.01, 1.04), 2.37 (95% CI 1.51, 3.70), 9.74 (95% CI 5.41, 17.5), 1.57 (95% CI 1.40, 1.74), 2.08 (95% CI 1.56, 2.76), respectively.\n",
      "4.644668506093002\n",
      "For the same variable, similar odds ratios were demonstrated in a multivariate analysis to predict complicated appendicitis and univariate and multivariate analysis to predict acute uncomplicated appendicitis.\n",
      "4.65121429135101\n",
      "The likelihood of acute uncomplicated appendicitis and complicated appendicitis can be calculated by using the reported predictive equations integrated into a web application at www.appendistat.com.\n",
      "4.651784910377881\n",
      "This will enable clinicians to determine the probability of appendicitis and the need for urgent surgery in case of complicated appendicitis.\n",
      "4.633014502474421\n",
      "This work would have not been completed without the help of: Clarissa Y. M. Carvallho, Consultant Anaesthetist at Guy's and St Thomas's Hospital; Bried O'Brien, the Head of Urgent Care Transformation at University College London Hospital; and Guang's Wu, Web Application Developer.\n",
      "4.664461729956455\n",
      "Their contribution to building the web application allowed this work to materialise into clinical use to benefit patients.\n",
      "4.64712845651727\n",
      " This study analysed the influence of clinical factors on early postoperative seizures in patients with meningiomas and constructed a logistic regression equation for assessing risk factors.\n",
      "4.688342571258545\n",
      "Clinical data from 222 patients with meningiomas were collected.\n",
      "4.640662208597928\n",
      "The odds ratios (ORs) for independent  variables were determined: the ORs for preoperative seizure history and movement disorder were > 1, whereas the OR for prophylactic therapy was < 1.\n",
      "4.654731487405711\n",
      "A logistic regression analysis was then performed to select potential risk factors for early postoperative seizures.\n",
      "4.649854434433804\n",
      "Five variables (preoperative  seizure history, movement disorder, tumour location, primary location of initial tumour and prophylactic therapy) were introduced into the regression model.\n",
      "4.655694666043134\n",
      "A logistic regression equation was then constructed that had a positive predictive value of 66.65% and a negative predictive value of  84.95%.\n",
      "4.641220032935049\n",
      "This suggested that the five variables introduced in the equation were closely associated with early postoperative seizures, with preoperative seizure history and movement disorder as potential risk factors and prophylactic therapy as a protective factor.\n",
      "4.66495432752244\n",
      " This research aimed to propose a logistic regression model for Japanese blunt trauma victims.\n",
      "4.636748411945093\n",
      "We tested whether the logistic regression model previously created from data registered in the Japan Trauma Data Bank between 2005 and 2008 is still valid for the data from the same data bank between 2009 and 2013.\n",
      "4.647655345775463\n",
      "Additionally, we analyzed whether the model would be highly accurate even when its coefficients were rounded off to two decimal places.\n",
      "4.673870408391378\n",
      "The model was proved to be highly accurate (94.56%) in the recent data (2009-2013).\n",
      "4.662160396575928\n",
      "We also showed that the model remains valid without respiratory rate data and the simplified model would maintain high accuracy.\n",
      "4.573809243188116\n",
      "We propose the equation of survival prediction of blunt trauma victims in Japan to be Ps = 1/(1+e<sup>-b</sup>), where b = -0.76 + 1.03 × Revised Trauma Score - 0.07 × Injury Severity Score - 0.04 × age.\n",
      "4.654416340153392\n",
      " To investigate a method for quantitative differential diagnosis of damp-heat and cold-damp impeding syndrome of rheumatoid arthritis (RA) in Chinese medicine (CM).\n",
      "4.689917185949901\n",
      "Laboratory parameters were collected from 306 patients with RA.\n",
      "4.636939976402517\n",
      "The clinical symptoms and laboratory parameters were compared between patients with these two syndromes (158 with RA of damp-heat impeding syndrome, and 148 with RA of cold-damp impeding syndrome), and a regression equation was established to facilitate discrimination of the two RA syndromes.\n",
      "4.636804995329483\n",
      "There were significant differences in disease activity score in 28 joints [DAS28 (4)], erythrocyte sedimentation rate (ESR), white blood cell count (WBC), C-reactive protein (CRP), platelet count (PLT), albumin (ALB) and globulin (GLB) between the two syndrome of RA (P<0.05).\n",
      "4.640278888993474\n",
      "Logistic regression analysis showed that the parameters ESR, WBC, CRP, joint pyrexia, joint cold, thirst, sweating, aversion to wind and cold, and cold extremities were statistically useful to discriminate damp-heat from cold-damp impeding syndrome.\n",
      "4.583514920514615\n",
      "The regression equation was as follows: P=1/{1+exp[-(3.0-0.021X                            (1)-0.196X                            (2)-0.163X                            (3)-1.559X                            (4)+1.504X                            (5)-0.927X                            (6)-1.039X                            (7)+1.070X                            (8)+1.330X                            (9))]}.\n",
      "4.62303466796875\n",
      "The independent variables X                            (1)-X                            (9) were ESR, WBC, CRP, hot joint, cold joint, thirst, sweating, aversion to wind and cold, and cold limbs.\n",
      "4.661787995194967\n",
      "A P value > 0.5 signified cold-damp impeding syndrome, and a P value < 0.5 signified damp-heat impeding syndrome.\n",
      "4.811034824537194\n",
      "The accuracy was 90.2%.\n",
      "4.666748910580042\n",
      "The regression equation may be useful for discriminating damp-heat from cold-damp impeding syndrome of RA.\n",
      "4.650753599224669\n",
      " Stunting is the core measure of child health inequalities as it reveals multiple dimensions of child health and development status.\n",
      "4.640091913916199\n",
      "The main focus of this study is to show the procedure of selecting the most appropriate logistic regression model for stunting by developing and comparing several plausible models, which ultimately helps to identify the predictors of childhood stunting in Bangladesh.\n",
      "4.667753447086439\n",
      "This study utilizes child anthropometric data collected in the 2014 Bangladesh Demographic and Health Survey.\n",
      "4.620882102911421\n",
      "Valid height-for-age anthropometric indices were available for a total of 6,931 children aged 0-59 months, of which about 36% were stunted.\n",
      "4.639134216308594\n",
      "Ordinary logistic, survey logistic, marginal logistic, and random intercept logistic regression models were developed assuming independence, sampling design, cluster effect, and hierarchy of the data.\n",
      "4.649450956885494\n",
      "Based on a number of model selection criteria, random intercept logistic model is found the most appropriate for the studied children.\n",
      "4.658370843454569\n",
      "A number of child, mother, household, regional, and community-level variables were included in the model specification.\n",
      "4.621540069580078\n",
      "The factors that increased the odds of stunting are children older than 11 months, short birth interval, recent morbidity of children, lower maternal education, young maternity, lower maternal body mass index, poor household wealth, urban residential place, and living in Sylhet division.\n",
      "4.645426783068427\n",
      "Findings of this study recommend to utilize an appropriate logistic model considering the issues relevant to the data, particularly sampling design and clustering for determining the risk factors of childhood stunting in Bangladesh.\n",
      "4.659863479738313\n",
      " The goal of this study was to establish a biomathematical model to accurately predict the probability of aneurysm rupture.\n",
      "4.657622848731884\n",
      "Biomathematical models incorporate various physical and dynamic phenomena that provide insight into why certain aneurysms grow or rupture.\n",
      "4.65771285886687\n",
      "Prior studies have demonstrated that regression models may determine which parameters of an aneurysm contribute to rupture.\n",
      "4.651067526943712\n",
      "In this study, the authors derived a modified binary logistic regression model and then validated it in a distinct cohort of patients to assess the model's stability.\n",
      "4.725176789039789\n",
      "Patients were examined with CT angiography.\n",
      "4.65287971496582\n",
      "Three-dimensional reconstructions were generated and aneurysm height, width, and neck size were obtained in 2 orthogonal planes.\n",
      "4.640241206918724\n",
      "Forward stepwise binary logistic regression was performed and then applied to a prospective cohort of 49 aneurysms in 37 patients (not included in the original derivation of the equation) to determine the log-odds of rupture for this aneurysm.\n",
      "4.671476557013694\n",
      "A total of 279 aneurysms (156 ruptured and 123 unruptured) were observed in 217 patients.\n",
      "4.651204003228082\n",
      "Four of 6 linear dimensions and the aspect ratio were significantly larger (each with p < 0.01) in ruptured aneurysms than unruptured aneurysms.\n",
      "4.673287468987542\n",
      "Calculated volume and aneurysm location were correlated with rupture risk.\n",
      "4.656736642722316\n",
      "Binary logistic regression applied to an independent prospective cohort demonstrated the model's stability, showing 83% sensitivity and 80% accuracy.\n",
      "4.659722043756853\n",
      "This binary logistic regression model of aneurysm rupture identified the status of an aneurysm with good accuracy.\n",
      "4.647355168502523\n",
      "The use of this technique and its validation suggests that biomorphometric data and their relationships may be valuable in determining the status of an aneurysm.\n",
      "4.633054226805261\n",
      " To analyze the relationship between TCM's characteristics and treatment of cardiovascular diseases on the basis of the modem medical research literatures about treatment of cardiovascular diseases and establish a mathematic model in order to give reference for clinical study and clinical prescription for treatment of cardiovascular diseases with TCMs.\n",
      "4.633969514266305\n",
      "Articles on treatment of cardiovascular diseases with TCMs published at home in the past 20 years were collected and screened to summarize the number of TCMs with different function, property, flavor, channel tropism and the number of them with the therapeutically effect on cardiovascular diseases.\n",
      "4.682609833866717\n",
      "And a mathematic model was established on the multivariate discriminatory analysis.\n",
      "4.651307349111519\n",
      "Medicines for activating blood circulation and removing blood stasis (21.21%), those restoring deficiency (17.65%), those attributive to heart channel (21.82%) and those attributive to spleen channel (16.\n",
      "4.658460828993055\n",
      "11%) were relatively active in study for treatment of cardiovascular diseases and showed great difference (P < 0.05).\n",
      "4.634872056411255\n",
      "According to findings of the logistic regression screen, TCMs attribute to heart, spleen, gallbladder, pericardium channel and those restoring deficiency were important impact factors with therapeutically effect on cardiovascular diseases (regression coefficient > 0 and P < 0.05).\n",
      "4.650497010300279\n",
      "The coincidence was 91.6% between mathematical computing and original classification, indicating the coincidence with relevant theories of the traditional Chinese medical science.\n",
      "4.646262075386796\n",
      "A more objective Logistic regression equation with a higher accuracy rate of retrospective inspection is established to detect the effect of TCMs with different characteristics on cardiovascular diseases.\n",
      "4.649433357484879\n",
      "It is suggested that more experiments and clinical comparative studies on treatment of cardiovascular diseases with TMCs shall be included in pharmacopeia.\n",
      "4.6923020582932695\n",
      " Hemorrhagic shock is a common cause of death in emergency rooms.\n",
      "4.656870924581693\n",
      "Since the symptoms of hemorrhagic shock occur after shock has considerably progressed, it is difficult to diagnose shock early.\n",
      "4.6618703206380205\n",
      "The purpose of this study was to improve early diagnosis of hemorrhagic shock using a survival prediction model in rats.\n",
      "4.649589304543712\n",
      "We measured ECG, blood pressure, respiration and temperature in 45 Sprague-Dawley rats, and then obtained a logistic regression equation predicting survival rates.\n",
      "4.734659685407366\n",
      "Area under the ROC curves was 0.99.\n",
      "4.671005073635057\n",
      "The Hosmer-Lemeshow goodness-of-fit chi-square was 0.86 (degree of freedom=8, p=0.999).\n",
      "4.6634674072265625\n",
      "Applying the determined optimal boundary value of 0.25, the accuracy of survival prediction was 94.7%.\n",
      "4.642111489939135\n",
      " To develop and validate a general method (called regression risk analysis) to estimate adjusted risk measures from logistic and other nonlinear multiple regression models.\n",
      "4.686456298828125\n",
      "We show how to estimate standard errors for these estimates.\n",
      "4.650812243738918\n",
      "These measures could supplant various approximations (e.g., adjusted odds ratio [AOR]) that may diverge, especially when outcomes are common.\n",
      "4.636297280896348\n",
      "Regression risk analysis estimates were compared with internal standards as well as with Mantel-Haenszel estimates, Poisson and log-binomial regressions, and a widely used (but flawed) equation to calculate adjusted risk ratios (ARR) from AOR.\n",
      "4.721772485849809\n",
      "Data sets produced using Monte Carlo simulations.\n",
      "4.635884976168291\n",
      "Regression risk analysis accurately estimates ARR and differences directly from multiple regression models, even when confounders are continuous, distributions are skewed, outcomes are common, and effect size is large.\n",
      "4.664844621930803\n",
      "It is statistically sound and intuitive, and has properties favoring it over other methods in many cases.\n",
      "4.6377859542618936\n",
      "Regression risk analysis should be the new standard for presenting findings from multiple regression analysis of dichotomous outcomes for cross-sectional, cohort, and population-based case-control studies, particularly when outcomes are common or effect size is large.\n",
      "4.663127018855168\n",
      " Logistic regression is among the most widely used statistical methods for linear discriminant analysis.\n",
      "4.677233078900506\n",
      "In many applications, we only observe possibly mislabeled responses.\n",
      "4.683432163336338\n",
      "Fitting a conventional logistic regression can then lead to biased estimation.\n",
      "4.6558818359375\n",
      "One common resolution is to fit a mislabel logistic regression model, which takes into consideration of mislabeled responses.\n",
      "4.675548796958112\n",
      "Another common method is to adopt a robust M-estimation by down-weighting suspected instances.\n",
      "4.618092054731391\n",
      "In this work, we propose a new robust mislabel logistic regression based on γ-divergence.\n",
      "4.660408661744305\n",
      "Our proposal possesses two advantageous features: (1) It does not need to model the mislabel probabilities.\n",
      "4.624744543868505\n",
      "(2) The minimum γ-divergence estimation leads to a weighted estimating equation without the need to include any bias correction term, that is, it is automatically bias-corrected.\n",
      "4.621828055676119\n",
      "These features make the proposed γ-logistic regression more robust in model fitting and more intuitive for model interpretation through a simple weighting scheme.\n",
      "4.6786939403678796\n",
      "Our method is also easy to implement, and two types of algorithms are included.\n",
      "4.617502420890231\n",
      "Simulation studies and the Pima data application are presented to demonstrate the performance of γ-logistic regression.\n",
      "4.644547060311559\n",
      " To develop and validate an empirical equation to screen for dysglycaemia [impaired fasting glucose (IFG), impaired glucose tolerance (IGT) and undiagnosed diabetes].\n",
      "4.6507895192792335\n",
      "A predictive equation was developed using multiple logistic regression analysis and data collected from 1032 Egyptian subjects with no history of diabetes.\n",
      "4.632959750735706\n",
      "The equation incorporated age, sex, body mass index (BMI), post-prandial time (self-reported number of hours since last food or drink other than water), systolic blood pressure, high-density lipoprotein (HDL) cholesterol and random capillary plasma glucose as independent covariates for prediction of dysglycaemia based on fasting plasma glucose (FPG)>or=6.1 mmol/l and/or plasma glucose 2 h after a 75-g oral glucose load (2-h PG)>or=7.8 mmol/l.\n",
      "4.70286609280494\n",
      "The equation was validated using a cross-validation procedure.\n",
      "4.667227696890783\n",
      "Its performance was also compared with static plasma glucose cut-points for dysglycaemia screening.\n",
      "4.633821493120336\n",
      "The predictive equation was calculated with the following logistic regression parameters: P=1+1/(1+e-X)=where X=-8.3390+0.0214 (age in years)+0.6764 (if female)+0.0335 (BMI in kg/m2)+0.0934 (post-prandial time in hours)+0.0141 (systolic blood pressure in mmHg)-0.0110 (HDL in mmol/l)+0.0243 (random capillary plasma glucose in mmol/l).\n",
      "4.676971080691316\n",
      "The cut-point for the prediction of dysglycaemia was defined as a probability>or=0.38.\n",
      "4.680588100267493\n",
      "The equation's sensitivity was 55%, specificity 90% and positive predictive value (PPV) 65%.\n",
      "4.669740717461768\n",
      "When applied to a new sample, the equation's sensitivity was 53%, specificity 89% and PPV 63%.\n",
      "4.638559025826214\n",
      "This multivariate logistic equation improves on currently recommended methods of screening for dysglycaemia and can be easily implemented in a clinical setting using readily available clinical and non-fasting laboratory data and an inexpensive hand-held programmable calculator.\n",
      "4.659150906694614\n",
      " A set of 69 concentration-response curves from 5 acute ecotoxicity assays was fitted with a 2-parameter logistic equation.\n",
      "4.660378774007161\n",
      "High correlation between values of regression parameters suggested similar slopes of the curves.\n",
      "4.65647512242414\n",
      "This enabled derivation of the empirical single-parameter logistic equation with the sole median effective concentration (EC50) parameter.\n",
      "4.644799107142857\n",
      "Such an equation might be useful in the evaluation of lower-quality (preliminary) experimental data and for the reduction of the number of test organisms and of testing costs.\n",
      "4.633568828820475\n",
      " The standard methods for regression analyses of clustered riverine larval habitat data of <i>Simulium damnosum s.l.</i> a major black-fly vector of Onchoceriasis, postulate models relating observational ecological-sampled parameter estimators to prolific habitats without accounting for residual intra-cluster error correlation effects.\n",
      "4.635803767613003\n",
      "Generally, this correlation comes from two sources: (1) the design of the random effects and their assumed covariance from the multiple levels within the regression model; and, (2) the correlation structure of the residuals.\n",
      "4.636738725142045\n",
      "Unfortunately, inconspicuous errors in residual intra-cluster correlation estimates can overstate precision in forecasted <i>S.damnosum s.l.</i> riverine larval habitat explanatory attributes regardless how they are treated (e.g., independent, autoregressive, Toeplitz, etc).\n",
      "4.682406303210136\n",
      "In this research, the geographical locations for multiple riverine-based <i>S.\n",
      "4.644301049503279\n",
      "damnosum s.l.</i> larval ecosystem habitats sampled from 2 pre-established epidemiological sites in Togo were identified and recorded from July 2009 to June 2010.\n",
      "4.714730954637714\n",
      "Initially the data was aggregated into proc genmod.\n",
      "4.669259907286844\n",
      "An agglomerative hierarchical residual cluster-based analysis was then performed.\n",
      "4.655902927204714\n",
      "The sampled clustered study site data was then analyzed for statistical correlations using Monthly Biting Rates (MBR).\n",
      "4.658756880326704\n",
      "Euclidean distance measurements and terrain-related geomorphological statistics were then generated in ArcGIS.\n",
      "4.649536859421503\n",
      "A digital overlay was then performed also in ArcGIS using the georeferenced ground coordinates of high and low density clusters stratified by Annual Biting Rates (ABR).\n",
      "4.655996548927437\n",
      "This data was overlain onto multitemporal sub-meter pixel resolution satellite data (i.e., QuickBird 0.61m wavbands ).\n",
      "4.690374319893973\n",
      "Orthogonal spatial filter eigenvectors were then generated in SAS/GIS.\n",
      "4.6398951107040975\n",
      "Univariate and non-linear regression-based models (i.e., Logistic, Poisson and Negative Binomial) were also employed to determine probability distributions and to identify statistically significant parameter estimators from the sampled data.\n",
      "4.640195838004484\n",
      "Thereafter, Durbin-Watson test statistics were used to test the null hypothesis that the regression residuals were not autocorrelated against the alternative that the residuals followed an autoregressive process in AUTOREG.\n",
      "4.655936948714718\n",
      "Bayesian uncertainty matrices were also constructed employing normal priors for each of the sampled estimators in PROC MCMC.\n",
      "4.6567190847089215\n",
      "The residuals revealed both spatially structured and unstructured error effects in the high and low ABR-stratified clusters.\n",
      "4.636152866908482\n",
      "The analyses also revealed that the estimators, levels of turbidity and presence of rocks were statistically significant for the high-ABR-stratified clusters, while the estimators distance between habitats and floating vegetation were important for the low-ABR-stratified cluster.\n",
      "4.628288810483871\n",
      "Varying and constant coefficient regression models, ABR- stratified GIS-generated clusters, sub-meter resolution satellite imagery, a robust residual intra-cluster diagnostic test, MBR-based histograms, eigendecomposition spatial filter algorithms and Bayesian matrices can enable accurate autoregressive estimation of latent uncertainity affects and other residual error probabilities (i.e., heteroskedasticity) for testing correlations between georeferenced <i>S.\n",
      "4.707820100604363\n",
      "damnosum s.l.</i> riverine larval habitat estimators.\n",
      "4.640716858930811\n",
      "The asymptotic distribution of the resulting residual adjusted intra-cluster predictor error autocovariate coefficients can thereafter be established while estimates of the asymptotic variance can lead to the construction of approximate confidence intervals for accurately targeting productive <i>S.\n",
      "4.680148518880208\n",
      "damnosum s.l</i> habitats based on spatiotemporal field-sampled count data.\n",
      "4.657487300404331\n",
      " Several model types have already been developed to describe the boundary between growth and no growth conditions.\n",
      "4.638460128438512\n",
      "In this article two types were thoroughly studied and compared, namely (i) the ordinary (linear) logistic regression model, i.e., with a polynomial on the right-hand side of the model equation (type I) and (ii) the (nonlinear) logistic regression model derived from a square root-type kinetic model (type II).\n",
      "4.671260390170785\n",
      "The examination was carried out on the basis of the data described in Vermeulen et al.\n",
      "4.650558948516846\n",
      "[Vermeulen, A., Gysemans, K.P.M., Bernaerts, K., Geeraerd, A.H., Van Impe, J.F., Debevere, J., Devlieghere, F., 2006-this issue.\n",
      "4.645337785993304\n",
      "Influence of pH, water activity and acetic acid concentration on Listeria monocytogenes at 7 degrees C: data collection for the development of a growth/no growth model.\n",
      "4.720381625863009\n",
      "International Journal of Food Microbiology.\n",
      "6.08184814453125\n",
      ".].\n",
      "4.636405311817685\n",
      "These data sets consist of growth/no growth data for Listeria monocytogenes as a function of water activity (0.960-0.990), pH (5.0-6.0) and acetic acid percentage (0-0.8% (w/w)), both for a monoculture and a mixed strain culture.\n",
      "4.662741470336914\n",
      "Numerous replicates, namely twenty, were performed at closely spaced conditions.\n",
      "4.653407118055555\n",
      "In this way detailed information was obtained about the position of the interface and the transition zone between growth and no growth.\n",
      "4.628880782093075\n",
      "The main questions investigated were (i) which model type performs best on the monoculture and the mixed strain data, (ii) are there differences between the growth/no growth interfaces of monocultures and mixed strain cultures, (iii) which parameter estimation approach works best for the type II models, and (iv) how sensitive is the performance of these models to the values of their nonlinear-appearing parameters.\n",
      "4.649074500715229\n",
      "The results showed that both type I and II models performed well on the monoculture data with respect to goodness-of-fit and predictive power.\n",
      "4.680462980923587\n",
      "The type I models were, however, more sensitive to anomalous data points.\n",
      "4.700012742427358\n",
      "The situation was different for the mixed strain culture.\n",
      "4.648097810291109\n",
      "In that case, the type II models could not describe the curvature in the growth/no growth interface which was reversed to the typical curvatures found for monocultures.\n",
      "4.6330899665692105\n",
      "This unusual curvature may originate from the fact that (i) an interface of a mixed strain culture can result from the superposition of the interfaces of the individual strains, or that (ii) only a narrow range of the growth/no growth interface was studied (the local trend can be different from the trend over a wider range).\n",
      "4.634819319158075\n",
      "It was also observed that the best type II models were obtained with the flexible nonlinear logistic regression, although reasonably good models were obtained with the less flexible linear logistic regression with the nonlinear-appearing parameters fixed at experimentally determined values.\n",
      "4.64190673828125\n",
      "Finally, it was found that for some of the nonlinear-appearing parameters, deviations from their experimentally determined values did not influence the model fit.\n",
      "4.663881937662761\n",
      "This was probably caused by the fact that only a limited part of the growth/no growth interface was studied.\n",
      "4.6417897373338874\n",
      " The authors have previously developed a logistic regression equation to predict the odds that a human T-cell lymphotropic virus type 1 (HTLV-1)-infected individual of specified genotype, age, and provirus load has HTLV-1-associated myelopathy/tropical spastic paraparesis (HAM/TSP) in southern Japan.\n",
      "4.6619283176908555\n",
      "This study evaluated whether this equation is useful predictor for monitoring asymptomatic HTLV-1-seropositive carriers (HCs) in the same population.\n",
      "4.638777836326979\n",
      "The authors genotyped 181 HCs for each HAM/TSP-associated gene (tumor necrosis factor [TNF]-alpha-863A/C, stromal cell-derived factor 1 (SDF-1) +801G/A, human leukocyte antigen [HLA]-A*02, HLA-Cw*08, HTLV-1 tax subgroup) and measured HTLV-1 provirus load in peripheral blood mononuclear cells using real-time polymerase chain reaction (PCR).\n",
      "4.6511383056640625\n",
      "Finally, the odds of HAM/TSP for each subject were calculated by using the equation and compared the results with clinical symptoms and laboratory findings.\n",
      "4.628951811454665\n",
      "Although no clear difference was seen between the odds of HAM/TSP and either sex, family history of HAM/TSP or adult T-cell lenkemia (ATL), history of blood transfusion, it was found that brisk patellar deep tendon reflexes, which suggest latent central nervous system compromise, and flower cell-like abnormal lymphocytes, which is the morphological characteristic of ATL cells, were associated with a higher odds of HAM/TSP.\n",
      "4.6600119850852275\n",
      "The best-fit logistic regression equation may be useful for detecting subclinical abnormalities in HCs in southern Japan.\n",
      "4.640363353167394\n",
      " The latest methods in estimating the probability (absolute risk) of osteoporotic fractures include several logistic regression models, based on qualitative risk factors plus bone mineral density (BMD), and the probability estimate of fracture in the future.\n",
      "4.641860890276555\n",
      "The Slovak logistic regression model, in contrast to other models, is created from quantitative variables of the proximal femur (in International System of Units) and estimates the probability of fracture by fall.\n",
      "4.642963036070479\n",
      "The first objective of this study was to order selected independent variables according to the intensity of their influence (statistical significance) upon the occurrence of values of the dependent variable: femur strength index (FSI).\n",
      "4.640541076660156\n",
      "The second objective was to determine, using logistic regression, whether the odds of FSI acquiring a pathological value (femoral neck fracture by fall) increased or declined if the value of the variables (T-score total hip, BMI, alpha angle, theta angle and HAL) were raised by one unit.\n",
      "4.6324726010379855\n",
      "Bone densitometer measurements using dual energy X-ray absorptiometry (DXA), (Prodigy, Primo, GE, USA) of the left proximal femur were obtained from 3 216 East Slovak women with primary or secondary osteoporosis or osteopenia, aged 20-89 years (mean age 58.9; 95% CI: -58.42; 59.38).\n",
      "4.598684150481892\n",
      "The following variables were measured: FSI, T-score total hip BMD, body mass index (BMI), as were the geometrical variables of proximal femur alpha angle (α angle), theta angle (θ angle), and hip axis length (HAL).\n",
      "4.651009443867413\n",
      "Logistic regression was used to measure the influence of the independent variables (T-score total hip, alpha angle, theta angle, HAL, BMI) upon the dependent variable (FSI).\n",
      "4.6401424084679554\n",
      "The order of independent variables according to the intensity of their influence (greatest to least) upon the occurrence of values of the dependent FSI variable was found to be: BMI, theta angle, T-score total hip, alpha angle, and HAL.\n",
      "4.646767044067383\n",
      "An increase of one unit of an independent variable was shown, with statistical significance, to either raise or decrease the odds of the dependent FSI variable.\n",
      "4.589315783339764\n",
      "Specific findings were as follows: an increase by 1° of the α angle escalated the probability of FSI acquiring a pathological value by 1111 times; an increase by 1° of the θ angle was found to boost these odds 1231 times; an increase by 1 mm of the HAL was found to increase these odds by 1043 times; an increase by 1.0 kg/m(2) of the BMI raised the odds 1302 times; an increase by +1 standard deviation of the value of the T-score total hip subsequently decreased these odds 198 times.\n",
      "4.640332238148835\n",
      "The equation of the Slovak regression model makes it possible in praxis to determine the probability or absolute risk of femoral neck fracture by fall at those densitometrical workplaces without a program for measuring the FSI variable.\n",
      "4.637251653591124\n",
      " This study was performed to develop an algorithm using polymorphisms of CYP2D6, p-gp, OPRM1, COMT and psychological variables to predict tramadol response in Chinese patients recovering from upper limb fracture internal fixation surgery.\n",
      "4.666926558299731\n",
      "A total of 250 Han Chinese patients recovering from fracture in the upper limb were enrolled.\n",
      "4.648144721984863\n",
      "CYP2D6*10, p-gp G2677T, p-gp C3435T, OPRM1 A118G and COMT Val158Met were detected by the ligase detection reaction (LDR) method.\n",
      "4.654834139878583\n",
      "The algorithm was developed with binary logistic regression in cohort 1 (200 patients) and assessed with Wilcoxon signed-rank test in cohort 2 (50 patients).\n",
      "4.533749768333713\n",
      "According to cohort 1, the predictive equation was calculated with the following logistic regression parameters: Logit (1) = 2.304-4.841 × (anxiety I) - 23.709 × (anxiety II) + 2.823 × (p-gp 3435CT) + 5.737 × (p-gp 3435 TT) - 1.586 × (CYP2D6*10 CT) - 4.542 × (CYP2D6*10 TT).\n",
      "4.618152016087582\n",
      "The cutoff point for the prediction was defined as a probability value ≥0.5.\n",
      "4.7272993723551435\n",
      "The equation's positive predictive value is 90%.\n",
      "4.682519766000601\n",
      "When applied to a new sample, the equation's positive predictive value is 86%.\n",
      "4.61664529448574\n",
      "The Nagelkerke R² of the model is 0.819, the results of the Hosmer and Leme test show a value of 0.981.\n",
      "4.647146267361111\n",
      "The nonparametric correlations between predicted and observed response showed significant correlation (coefficient = 0.879; p < 0.001).\n",
      "4.663939255934495\n",
      "The algorithm we have developed might predict tramadol response in Chinese upper limb fracture patients.\n",
      "4.659313772607037\n",
      " Biochemical measures for assessment of insulin resistance are not cost-effective in resource-constrained developing countries.\n",
      "4.637570529513889\n",
      "Using classification and regression tree (CART) and multivariate logistic regression, we aimed to develop simple predictive decision models based on routine clinical and biochemical parameters to predict insulin resistance in apparently healthy Asian Indian adolescents.\n",
      "4.745619522897821\n",
      "Community based cross-sectional study.\n",
      "4.671192124310662\n",
      "Data of apparently healthy 793 adolescents (aged 14-19 years) were used for analysis.\n",
      "4.684939575195313\n",
      "WHO's multistage cluster sampling design was used for data collection.\n",
      "4.660481460221851\n",
      "Homeostasis Model of Assessment value > 75th centile was used as cut-off for defining the main outcome variable insulin resistance.\n",
      "4.658081513598449\n",
      "CART was used to develop the decision tree models and multivariate logistic regression used to develop the clinical prediction score.\n",
      "4.658138275146484\n",
      "Three classification trees and an equation for prediction score were developed and internally validated.\n",
      "4.668893469385354\n",
      "The three decision trees were termed as CART I, CART II and CART III, respectively.\n",
      "4.648222127537818\n",
      "CART I based on anthropometric parameters alone has sensitivity 88.2%, specificity 50.1% and area under receiver operating characteristic curve (aROC) 77.8%.\n",
      "4.657930203569614\n",
      "CART II based on anthropometric and routine biochemical parameters has sensitivity 94.5%, specificity 38.3% and aROC 73.6%.\n",
      "4.650319051399506\n",
      "CART III based on all anthropometric, biochemical and clinical parameters together has sensitivity 70.7%, specificity 79.2% and aROC 77.4%.\n",
      "4.653592377706291\n",
      "Prediction score for insulin resistance = 1 x (waist circumference) + 1.1 x (percentage body fat) + 1.6 x (triceps skin-fold thickness) - 1.9 x (gender).\n",
      "4.648638407389323\n",
      "A score cut-off of > 0 (using values marked for each) was a marker of insulin resistance in the study population (sensitivity 82.4%, specificity 56.7%, and aROC 73.4%).\n",
      "4.644868818741271\n",
      "These simple and cost-effective classification rules may be used to predict insulin resistance and implement population based preventive interventions in Asian Indian adolescents.\n",
      "4.645157511200385\n",
      " Fever occurring in a neutropenic patient remains a common life-threatening complication of cancer chemotherapy, and febrile neutropenia (FN) is recognized as a dose-limiting factor (DLF) in cancer chemotherapy.\n",
      "4.657196529327877\n",
      "The aim of this study is to evaluate the significant covariate associated with the risk of FN occurrence in Japanese patients.\n",
      "4.663091257077839\n",
      "A stepwise logistic regression was conducted using data from Japanese cancer patients treated with docetaxel.\n",
      "4.665244445800782\n",
      "Based on those results, an equation was established which predicts the probability of FN occurrence.\n",
      "4.630767637310606\n",
      "From the result of a stepwise multivariate logistic regression analysis, performance status factor (PS*), which is set to 1 if performance status factor is 2 or 3, and to 0 otherwise and area under the plasma concentration versus time curve (AUC) were selected as covariates significantly associated (p < 0.05) with FN occurrence.\n",
      "4.650733460771277\n",
      "The obtained equation to predict the probability (P) of docetaxel-induced FN occurrence is P = 1/[1 + exp{-(1.29 x AUC + 1.41 x PS* -3.52)}].\n",
      "4.643527100988701\n",
      "A receiver operating characteristic (ROC) curve analysis revealed that the best cut-off value of FN probability to differentiate between the presence and absence of FN was 0.61.\n",
      "4.6557065217391305\n",
      "An equation was developed to predict the probability of FN occurrence for Japanese patients treated with docetaxel.\n",
      "4.653262589328973\n",
      "It was found that FN may not occur when the probability of FN occurrence calculated by the predictive equation is less than 0.61.\n",
      "4.649564302884615\n",
      "Therefore, the predictive equation for FN occurrence may be used for selecting the appropriate dose to avoid the occurrence of FN.\n",
      "4.6413128098330825\n",
      " Multivariate analysis was used to select the risk factors in non-insulin dependent diabetes mellitus (NIDDM) patients with oral candidosis, and to establish the forecasting equation, aimed to detect the risk of oral candidosis among NIDDM patients.\n",
      "4.71709296043883\n",
      "140 NIDDM patients were included in this study.\n",
      "4.642017711292613\n",
      "11 clinical parameters including gender, age, course smoking, fasting blood glucose, oral hygiene status, systemic manifestation, oral mucous membrane status, and denture were recorded respectively.\n",
      "4.689527484732614\n",
      "Oral rinse technique was used to detect the salivary candidal carriage.\n",
      "4.694736286745233\n",
      "The isolates were identified using CHROM agar Candida test.\n",
      "4.673746282404119\n",
      "The Logistic multivariate regression analysis was carried our for risk factors analysis.\n",
      "4.659734191894532\n",
      "Candida was found in 69 out of 140 NIDDM cases, and Candida albicans was the major species isolated.\n",
      "4.653456069483902\n",
      "The poor glycemic control, poor oral hygiene, and dry mouth were the risk factors of oral candidosis in NIDDM patients, and the forecasting equation was established.\n",
      "4.68618657038762\n",
      "Using substitution method, the veracity of the forecasting equation was 82.1%.\n",
      "4.664492986898507\n",
      "Poor glycemic control, poor oral hygiene and dry mouth were risk factors of oral candidosis among NIDDM patients.\n",
      "4.650437672932942\n",
      "The probability obtained from the forecasting equation may offer references for predicting and preventing the oral candidosis in NIDDM patients.\n",
      "4.665996053944463\n",
      " Predicting the presence of enteric viruses in surface waters is a complex modeling problem.\n",
      "4.634164220999673\n",
      "Multiple water quality parameters that indicate the presence of human fecal material, the load of fecal material, and the amount of time fecal material has been in the environment are needed.\n",
      "4.6339636514353195\n",
      "This paper presents the results of a multiyear study of raw-water quality at the inlet of a potable-water plant that related 17 physical, chemical, and biological indices to the presence of enteric viruses as indicated by cytopathic changes in cell cultures.\n",
      "4.643848646009291\n",
      "It was found that several simple, multivariate logistic regression models that could reliably identify observations of the presence or absence of total culturable virus could be fitted.\n",
      "4.630153004716083\n",
      "The best models developed combined a fecal age indicator (the atypical coliform [AC]/total coliform [TC] ratio), the detectable presence of a human-associated sterol (epicoprostanol) to indicate the fecal source, and one of several fecal load indicators (the levels of Giardia species cysts, coliform bacteria, and coprostanol).\n",
      "4.633211066923946\n",
      "The best fit to the data was found when the AC/TC ratio, the presence of epicoprostanol, and the density of fecal coliform bacteria were input into a simple, multivariate logistic regression equation, resulting in 84.5% and 78.6% accuracies for the identification of the presence and absence of total culturable virus, respectively.\n",
      "4.644645182291667\n",
      "The AC/TC ratio was the most influential input variable in all of the models generated, but producing the best prediction required additional input related to the fecal source and the fecal load.\n",
      "4.642776794433594\n",
      "The potential for replacing microbial indicators of fecal load with levels of coprostanol was proposed and evaluated by multivariate logistic regression modeling for the presence and absence of virus.\n",
      "4.622990968848477\n",
      " The objective of this study was to develop a probabilistic model to predict the end of lag time (λ) during the growth of Bacillus cereus vegetative cells as a function of temperature, pH, and salt concentration using logistic regression.\n",
      "4.619166298518105\n",
      "The developed λ model was subsequently combined with a logistic differential equation to simulate bacterial numbers over time.\n",
      "4.5922229397681456\n",
      "To develop a novel model for λ, we determined whether bacterial growth had begun, i.e., whether λ had ended, at each time point during the growth kinetics.\n",
      "4.540992736816406\n",
      "The growth of B. cereus was evaluated by optical density (OD) measurements in culture media for various pHs (5.5 ∼ 7.0) and salt concentrations (0.5 ∼ 2.0%) at static temperatures (10 ∼ 20°C).\n",
      "4.620909208409927\n",
      "The probability of the end of λ was modeled using dichotomous judgments obtained at each OD measurement point concerning whether a significant increase had been observed.\n",
      "4.6174175555889425\n",
      "The probability of the end of λ was described as a function of time, temperature, pH, and salt concentration and showed a high goodness of fit.\n",
      "4.614474826388889\n",
      "The λ model was validated with independent data sets of B. cereus growth in culture media and foods, indicating acceptable performance.\n",
      "4.618065019087358\n",
      "Furthermore, the λ model, in combination with a logistic differential equation, enabled a simulation of the population of B. cereus in various foods over time at static and/or fluctuating temperatures with high accuracy.\n",
      "4.6219633186005975\n",
      "Thus, this newly developed modeling procedure enables the description of λ using observable environmental parameters without any conceptual assumptions and the simulation of bacterial numbers over time with the use of a logistic differential equation.\n",
      "4.652117774600074\n",
      " To find out HepB vaccine timely delivery factors influencing in newborns within 24 hours, provide a basic evidences for increasing the coverage of timely HepB vaccine.\n",
      "4.637923803084936\n",
      "We established multinomial Logistic regression equation to analysis the factors with the investigation landform, delivery rate at hospital, occupation and education of child caretakers, ethnic,whether the child caretakers know children need vaccination and if the child caretakers bring children for vaccination.\n",
      "4.664818832554768\n",
      "234 children received timely birth dose HepB among 852 children, timely coverage rate was 27.46%.\n",
      "4.640283857073102\n",
      "Compare with 6.71% of children delivery at home, timely coverage of children delivery at township clinic and county clinic hospitals are 46.86% and 54.05% respectively.\n",
      "4.633256487918467\n",
      "Multinomial logistic regression analysis showed that delivery hospitals (X1), education of child caretakers (X2) were the main influencing factors to the timely birth dose HepB vaccination, the investigation landform, occupation of child caretakers, ethnic, whether the child caretakers know children need vaccination and if the child caretakers bring children for vaccination on their own have relevancy with the timely to the timely birth dose HepB vaccination.\n",
      "4.651449552146337\n",
      "The strategies such as increasing the rate of delivery at hospitals and putting more funding into publicity will facilitate increasing the coverage of timely birth dose HepB vaccination.\n",
      "4.644332952374454\n",
      " We employ a general bias preventive approach developed by Firth (Biometrika 1993; 80:27-38) to reduce the bias of an estimator of the log-odds ratio parameter in a matched case-control study by solving a modified score equation.\n",
      "4.669707888648624\n",
      "We also propose a method to calculate the standard error of the resultant estimator.\n",
      "4.655120161242951\n",
      "A closed-form expression for the estimator of the log-odds ratio parameter is derived in the case of a dichotomous exposure variable.\n",
      "4.676503995569741\n",
      "Finite sample properties of the estimator are investigated via a simulation study.\n",
      "4.665719258416559\n",
      "Finally, we apply the method to analyze a matched case-control data from a low birthweight study.\n",
      "4.6681494140625\n",
      " This paper considers inference methods for case-control logistic regression in longitudinal setups.\n",
      "4.659263744688871\n",
      "The motivation is provided by an analysis of plains bison spatial location as a function of habitat heterogeneity.\n",
      "4.640694205216535\n",
      "The sampling is done according to a longitudinal matched case-control design in which, at certain time points, exactly one case, the actual location of an animal, is matched to a number of controls, the alternative locations that could have been reached.\n",
      "4.644453796029788\n",
      "We develop inference methods for the conditional logistic regression model in this setup, which can be formulated within a generalized estimating equation (GEE) framework.\n",
      "4.6410491772870115\n",
      "This permits the use of statistical techniques developed for GEE-based inference, such as robust variance estimators and model selection criteria adapted for non-independent data.\n",
      "4.660027219538103\n",
      "The performance of the methods is investigated in a simulation study and illustrated with the bison data analysis.\n",
      "4.656022545245054\n",
      " Structural equation modelling (SEM) has been increasingly used in medical statistics for solving a system of related regression equations.\n",
      "4.645527488306949\n",
      "However, a great obstacle for its wider use has been its difficulty in handling categorical variables within the framework of generalised linear models.\n",
      "4.63433837890625\n",
      "A large data set with a known structure among two related outcomes and three independent variables was generated to investigate the use of Yule's transformation of odds ratio (OR) into Q-metric by (OR-1)/(OR+1) to approximate Pearson's correlation coefficients between binary variables whose covariance structure can be further analysed by SEM.\n",
      "4.662575822535569\n",
      "Percent of correctly classified events and non-events was compared with the classification obtained by logistic regression.\n",
      "4.641961581465127\n",
      "The performance of SEM based on Q-metric was also checked on a small (N = 100) random sample of the data generated and on a real data set.\n",
      "4.699717203776042\n",
      "SEM successfully recovered the generated model structure.\n",
      "4.64831622753268\n",
      "SEM of real data suggested a significant influence of a latent confounding variable which would have not been detectable by standard logistic regression.\n",
      "4.676352212595385\n",
      "SEM classification performance was broadly similar to that of the logistic regression.\n",
      "4.646544656635802\n",
      "The analysis of binary data can be greatly enhanced by Yule's transformation of odds ratios into estimated correlation matrix that can be further analysed by SEM.\n",
      "4.647583420212205\n",
      "The interpretation of results is aided by expressing them as odds ratios which are the most frequently used measure of effect in medical statistics.\n",
      "4.661701784295551\n",
      " In the process of risk stratification, a logistic calculation of mortality risk in percentage is easier to interpret.\n",
      "4.665345423429915\n",
      "Unfortunately, there is no reliable logistic model available for postoperative intensive care patients.\n",
      "4.6527410848251245\n",
      "The aim of this study was to present the first logistic model for postoperative mortality risk stratification in cardiac surgical intensive care units.\n",
      "4.658231820633162\n",
      "This logistic version is based on our previously presented and established additive model (CASUS) that proved a very high reliability.\n",
      "4.647719742415787\n",
      "In this prospective study, data from all adult patients admitted to our ICU after cardiac surgery over a period of three years (2007-2009) were collected.\n",
      "4.66280185475069\n",
      "The Log-CASUS was developed by weighting the 10 variables of the additive CASUS and adding the number of postoperative day to the model.\n",
      "4.691286001632463\n",
      "Risk of mortality is predicted with a logistic regression equation.\n",
      "4.64289217373348\n",
      "Statistical performance of the two scores was assessed using calibration (observed/expected mortality ratio), discrimination (area under the receiver operating characteristic curve), and overall correct classification analyses.\n",
      "4.735730622944079\n",
      "The outcome measure was ICU mortality.\n",
      "4.660275734077065\n",
      "A total of 4054 adult cardiac surgical patients was admitted to the ICU after cardiac surgery during the study period.\n",
      "4.759453296661377\n",
      "The ICU mortality rate was 5.8%.\n",
      "4.661951846168154\n",
      "The discriminatory power was very high for both additive (0.865-0.966) and logistic (0.874-0.963) models.\n",
      "4.646160958827227\n",
      "The logistic model calibrated well from the first until the 13th postoperative day (0.997-1.002), but the additive model over- or underestimated mortality risk (0.626-1.193).\n",
      "4.714639469068878\n",
      "The logistic model shows statistical superiority.\n",
      "4.673617304587851\n",
      "Because of the precise weighing the individual risk factors, it offers a reliable risk prediction.\n",
      "4.655290159460616\n",
      "It is easier to interpret and to facilitate the integration of mortality risk stratification into the daily management more than the additive one.\n",
      "4.694871520996093\n",
      " Composite endpoints are commonplace in biomedical research.\n",
      "4.655727751358696\n",
      "The complex nature of many health conditions and medical interventions demand that composite endpoints be employed.\n",
      "4.683212052530317\n",
      "Different approaches exist for the analysis of composite endpoints.\n",
      "4.649718033640008\n",
      "A Monte Carlo simulation study was employed to assess the statistical properties of various regression methods for analyzing binary composite endpoints.\n",
      "4.665489715279885\n",
      "We also applied these methods to data from the BETTER trial which employed a binary composite endpoint.\n",
      "4.653799874441964\n",
      "We demonstrated that type 1 error rates are poor for the Negative Binomial regression model and the logistic generalized linear mixed model (GLMM).\n",
      "4.639846122216599\n",
      "Bias was minimal and power was highest in the binomial logistic regression model, the linear regression model, the Poisson (corrected for over-dispersion) regression model and the common effect logistic generalized estimating equation (GEE) model.\n",
      "4.649457858718988\n",
      "Convergence was poor in the distinct effect GEE models, the logistic GLMM and some of the zero-one inflated beta regression models.\n",
      "4.640839227355353\n",
      "Considering the BETTER trial data, the distinct effect GEE model struggled with convergence and the collapsed composite method estimated an effect, which was greatly attenuated compared to other models.\n",
      "4.676878662109375\n",
      "All remaining models suggested an intervention effect of similar magnitude.\n",
      "4.634745341413331\n",
      "In our simulation study, the binomial logistic regression model (corrected for possible over/under-dispersion), the linear regression model, the Poisson regression model (corrected for over-dispersion) and the common effect logistic GEE model appeared to be unbiased, with good type 1 error rates, power and convergence properties.\n",
      "4.650834677875906\n",
      " In dementia screening tests, item selection for shortening an existing screening test can be achieved using multiple logistic regression.\n",
      "4.6340078580177435\n",
      "However, maximum likelihood estimates for such logistic regression models often experience serious bias or even non-existence because of separation and multicollinearity problems resulting from a large number of highly correlated items.\n",
      "4.64886720153107\n",
      "Firth (1993, Biometrika, 80(1), 27-38) proposed a penalized likelihood estimator for generalized linear models and it was shown to reduce bias and the non-existence problems.\n",
      "4.657661769701087\n",
      "The ridge regression has been used in logistic regression to stabilize the estimates in cases of multicollinearity.\n",
      "4.704778817983774\n",
      "However, neither solves the problems for each other.\n",
      "4.654184486126078\n",
      "In this paper, we propose a double penalized maximum likelihood estimator combining Firth's penalized likelihood equation with a ridge parameter.\n",
      "4.648508150283605\n",
      "We present a simulation study evaluating the empirical performance of the double penalized likelihood estimator in small to moderate sample sizes.\n",
      "4.665345389887972\n",
      "We demonstrate the proposed approach using a current screening data from a community-based dementia study.\n",
      "4.643574923755013\n",
      " Development of policies and procedures to contend with the risks presented by elopement, aggression, and suicidal behaviors are long-standing challenges for mental health administrators.\n",
      "4.65422679759838\n",
      "Guidance in making such judgments can be obtained through the use of a multivariate statistical technique known as logistic regression.\n",
      "4.644711417947861\n",
      "This procedure can be used to develop a predictive equation that is mathematically formulated to use the best combination of predictors, rather than considering just one factor at a time.\n",
      "4.6615857036173844\n",
      "This paper presents an overview of logistic regression and its utility in mental health administrative decision making.\n",
      "4.6546117389012895\n",
      "A case example of its application is presented using data on elopements from Missouri's long-term state psychiatric hospitals.\n",
      "4.636963300256921\n",
      "Ultimately, the use of statistical prediction analyses tempered with differential qualitative weighting of classification errors can augment decision-making processes in a manner that provides guidance and flexibility while wrestling with the complex problem of risk assessment and decision making.\n",
      "4.653609238661729\n",
      " In clinical research, suitable visualization techniques of data after statistical analysis are crucial for the researches' and physicians' understanding.\n",
      "4.661857449278539\n",
      "Common statistical techniques to analyze data in clinical research are logistic regression models.\n",
      "4.636840330070281\n",
      "Among these, the application of binary logistic regression analysis (LRA) has greatly increased during past years, due to its diagnostic accuracy and because scientists often want to analyze in a dichotomous way whether some event will occur or not.\n",
      "4.634878599877451\n",
      "Such an analysis lacks a suitable, understandable, and widely used graphical display, instead providing an understandable logit function based on a linear model for the natural logarithm of the odds in favor of the occurrence of the dependent variable, Y.\n",
      "4.643288323818109\n",
      "By simple exponential transformation, such a logit equation can be transformed into a logistic function, resulting in predicted probabilities for the presence of the dependent variable, P(Y-1/X).\n",
      "4.673482919668222\n",
      "This model can be used to generate a simple graphical display for binary LRA.\n",
      "4.642850730451233\n",
      "For the case of a single predictor or explanatory (independent) variable, X, a plot can be generated with X represented by the abscissa (i.e., horizontal axis) and P(Y-1/X) represented by the ordinate (i.e., vertical axis).\n",
      "4.646382410386029\n",
      "For the case of multiple predictor models, I propose here a relief 3D surface graphic in order to plot up to four independent variables (two continuous and two discrete).\n",
      "4.6417058199772\n",
      "By using this technique, any researcher or physician would be able to transform a lesser understandable logit function into a figure easier to grasp, thus leading to a better knowledge and interpretation of data in clinical research.\n",
      "4.647891870281041\n",
      "For this, a sophisticated statistical package is not necessary, because the graphical display may be generated by using any 2D or 3D surface plotter.\n",
      "4.683191811166158\n",
      " Logistic regression is most often used to produce a cardiac operative risk model.\n",
      "4.709059281782671\n",
      "But the logistic equation requires a computer to solve.\n",
      "4.658749876903887\n",
      "Thus, simple additive models have been derived from logistic models by adding the odds ratios or modified coefficients.\n",
      "4.658357956830193\n",
      "However, this simplification has no statistical justification, and the additive scores do not equal the original logistic probabilities.\n",
      "4.647027180989583\n",
      "The EuroSCORE risk model is a very successful and widely used cardiac surgery risk model and it comes in both an additive and a full logistic version.\n",
      "4.657739537362834\n",
      "We applied the EuroSCORE model to the 28,337 cardiac surgeries in the Providence Health System Cardiovascular Study Group database.\n",
      "4.705331771100154\n",
      "The discrimination of the models was assessed by the c index.\n",
      "4.661258443196615\n",
      "The comparison of the mortality predictions of the logistic and the additive model are mostly descriptive and graphical.\n",
      "4.648096377132861\n",
      "Theoretical considerations would predict that the additive model greatly underestimates the risk for the higher risk patients, and clinical data confirm this fact.\n",
      "4.6541775581531954\n",
      "For the 23,463 (83%) cases with complete data, the predicted mortality was 8.3% by the logistic model and 5.4% by the additive model.\n",
      "4.671293608996333\n",
      "The discrimination (c index) of the additive (0.794) and logistic (0.791) models was equally good.\n",
      "4.650893683182566\n",
      "A modified additive score is proposed (the mean of the logistic predicted mortality for each original additive score) which could be provided as a look-up table along with the scoring sheet.\n",
      "4.650365936622191\n",
      "The additive EuroSCORE gives excellent discrimination, as good as the logistic risk model, but it greatly underestimates the risk of high-risk patients, compared to the logistic.\n",
      "4.686428363506611\n",
      "The logistic equation should be used to predicate the mortality when possible.\n",
      "4.679056440080915\n",
      "If this is not feasible, a modified additive score could be employed at the bedside.\n",
      "4.667494626389336\n",
      "But the logistic should always be used for comparison of providers and for research publications.\n",
      "4.645049676662538\n",
      " To identify potential prognostic factors for pulmonary thromboembolism (PTE), establishing a mathematical model to predict the risk for fatal PTE and nonfatal PTE.\n",
      "4.647559591809159\n",
      "The reports on 4,813 consecutive autopsies performed from 1979 to 1998 in a Brazilian tertiary referral medical school were reviewed for a retrospective study.\n",
      "4.633490360144413\n",
      "From the medical records and autopsy reports of the 512 patients found with macroscopically and/or microscopically documented PTE, data on demographics, underlying diseases, and probable PTE site of origin were gathered and studied by multiple logistic regression.\n",
      "4.647901546320266\n",
      "Thereafter, the \"jackknife\" method, a statistical cross-validation technique that uses the original study patients to validate a clinical prediction rule, was performed.\n",
      "4.6953992341694075\n",
      "The autopsy rate was 50.2%, and PTE prevalence was 10.6%.\n",
      "4.693809772359914\n",
      "In 212 cases, PTE was the main cause of death (fatal PTE).\n",
      "4.6223254733615455\n",
      "The independent variables selected by the regression significance criteria that were more likely to be associated with fatal PTE were age (odds ratio [OR], 1.02; 95% confidence interval [CI], 1.00 to 1.03), trauma (OR, 8.5; 95% CI, 2.20 to 32.81), right-sided cardiac thrombi (OR, 1.96; 95% CI, 1.02 to 3.77), pelvic vein thrombi (OR, 3.46; 95% CI, 1.19 to 10.05); those most likely to be associated with nonfatal PTE were systemic arterial hypertension (OR, 0.51; 95% CI, 0.33 to 0.80), pneumonia (OR, 0.46; 95% CI, 0.30 to 0.71), and sepsis (OR, 0.16; 95% CI, 0.06 to 0.40).\n",
      "4.633273934170962\n",
      "The results obtained from the application of the equation in the 512 cases studied using logistic regression analysis suggest the range in which logit p > 0.336 favors the occurrence of fatal PTE, logit p < - 1.142 favors nonfatal PTE, and logit P with intermediate values is not conclusive.\n",
      "4.6532133078273334\n",
      "The cross-validation prediction misclassification rate was 25.6%, meaning that the prediction equation correctly classified the majority of the cases (74.4%).\n",
      "4.636406122251999\n",
      "Although the usefulness of this method in everyday medical practice needs to be confirmed by a prospective study, for the time being our results suggest that concerning prevention, diagnosis, and treatment of PTE, strict attention should be given to those patients presenting the variables that are significant in the logistic regression model.\n",
      "4.666618828300957\n",
      " To investigate the outcome predictive factors of ruptured lumbar disc herniation after conservative treatment.\n",
      "4.638417602056571\n",
      "From June 2009 to June 2016, 147 patients with ruptured lumbar intervertebral disc herniation were treated with conservative treatment in the orthopedics department of Suzhou Traditional Chinese Medicine Hospital for clinical efficacy and MRI follow-up.\n",
      "4.633111769153226\n",
      "Multivariate Logistic regression analysis(Stepwise regression method)was used to analyze the relationship between the 11 categorical variables and absorptivity of protrusions: sex(X1), age(X2), course of disease(X3) , the rate of protrusion(X4), the Komori type(X5), the MSU type(X6), the Iwabuchi type(X7), the Pfirrmann grade(X8), the Modic change on adjacent vertebrae(X9), spinal canal morphology(X10), the Schizas types of cauda equina sedimentation sign(X11).\n",
      "4.661095883665967\n",
      "A total of 64 cases of prominent reabsorption among all cases followed-up (absorption rate>=30%), accounting for 43.5%.\n",
      "4.642699270537405\n",
      "The reabsorption of protrusions is more likely to occur in patients with a duration of less than 1 year(<i>P=</i>0.006), MSU type 3 (<i>P=</i>0.001), Iwabuchi type 1 or 5 (<i>P=</i>0.000), the Schizas type of cauda equina sedimentation sign A or B(<i>P=</i>0.004).\n",
      "4.665487289428711\n",
      "Regression equation Y=-10.363+1.916X3+1.446X4-1.445X5+2.070X6+4.679X7+1.125X9+1.023X10+2.223X11.\n",
      "4.6536017767816995\n",
      "Such factors as age, gender, Pfirrmann classification and spinal canal morphology had no significant effect on reabsorption of protrusions.\n",
      "4.674625058717366\n",
      "Ruptured lumbar disc herniation can be reabsorbed after nonoperative treatment.\n",
      "4.639155619853252\n",
      "And the reabsorption of protrusions is more likely to occur in patients with a duration of less than 1 year, MSU type 3, Iwabuchi type 1 or 5, the Schizas type of cauda equina sedimentation sign A or B, which can be used as the key reference factors for predicting the outcome of the projections.\n",
      "4.646037746120143\n",
      " The standard model for the dynamics of a fragmented density-dependent population is built from several local logistic models coupled by migrations.\n",
      "4.651175247995477\n",
      "First introduced in the 1970s and used in innumerable articles, this standard model applied to a two-patch situation has never been completely analysed.\n",
      "4.64361572265625\n",
      "Here, we complete this analysis and we delineate the conditions under which fragmentation associated to dispersal is either beneficial or detrimental to total population abundance.\n",
      "4.709110260009766\n",
      "Therefore, this is a contribution to the SLOSS question.\n",
      "4.654201840394295\n",
      "Importantly, we also show that, depending on the underlying mechanism, there is no unique way to generalize the logistic model to a patchy situation.\n",
      "4.677496068617877\n",
      "In many cases, the standard model is not the correct generalization.\n",
      "4.681339488309972\n",
      "We analyse several alternative models and compare their predictions.\n",
      "4.642387977013221\n",
      "Finally, we emphasize the shortcomings of the logistic model when written in the r-K parameterization and we explain why Verhulst's original polynomial expression is to be preferred.\n",
      "4.680497741699218\n",
      " The Hill equation is often used in dose-response or exposure-response modeling.\n",
      "4.673631249404535\n",
      "Aliases for the Hill model include the Emax model, and the Michaelis-Menten model.\n",
      "4.634766045932112\n",
      "There is confusion about the appropriate parameterization, how to interpret the parameters, what the meaning is of the various parameterizations found in the literature, and which parameterization best approximates the statistical inferences produced when fitting the Hill equation to data.\n",
      "4.629990734501348\n",
      "In this paper, we present several equivalent versions of the Hill model; show that they are equivalent in terms of yielding the same prediction for a given dose, and are equivalent to the four-parameter logistic model in this same sense; and deduce which parameterization is optimal in the sense of having the least statistical curvature and preferable multicollinearity.\n",
      "4.642568359375\n",
      " To apply logistic regression analysis for several clinical and sonographic data for the construction of a predictive model that could be helpful in the preoperative differentiation of adnexal masses.\n",
      "4.669265898147432\n",
      "Two hundred and eight women with tumors thought to be of adnexal origin were examined preoperatively.\n",
      "4.635193541809753\n",
      "Initial analysis included age and menopausal status, ultrasound derived morphological features of adnexal masses (unilateral/bilateral tumors, papillae, septae, tumor size and volume) as well as color Doppler criteria such as PI, RI, Peak Systolic Velocity, PSV assessment.\n",
      "4.660605294363839\n",
      "In all examinations we used B&K 2002 ADI (Denmark) and Kretz Voluson V730 (Austria) scanners with transvaginal probes 5-9 MHz.\n",
      "4.6540126922024285\n",
      "Stepwise logistic regression analysis was used to construct a predictive model that would allow probability of malignancy calculation for individual patient.\n",
      "4.703992428986923\n",
      "There were 159 benign and 49 malignant masses.\n",
      "4.727313892261402\n",
      "Seven cancers were in FIGO stage one.\n",
      "4.656539440155029\n",
      "Statistical analysis revealed that only 5 of initially tested 14 variables had significant influence on the regression equation.\n",
      "4.643366642770051\n",
      "These were: age, bilateral mass, presence of septa > 3 mm, papillary projections > 3 mm in the tumor wall and subjective color scale assessment according to Timmerman et al.\n",
      "5.220442635672433\n",
      "(1999).\n",
      "4.6546760619156\n",
      "Sensitivity and specificity at the 50% probability level of malignancy in the studied tumor were 77.5% and 96.8%, respectively.\n",
      "4.6664798281608375\n",
      "When 25% cut-off probability level was used, sensitivity increased to 87.7% and specificity dropped to 89.9%.\n",
      "4.665590447894598\n",
      "Prospective testing in a new group of 30 patients (5 ovarian cancers) gave sensitivity of 80% and specificity of 100%.\n",
      "4.665320763221154\n",
      "The use of logistic regression analysis can help in modeling clinical and sonographic data.\n",
      "4.645243683753655\n",
      "Our model had better predictive value than individual tests and allowed to calculate true probability figure of ovarian malignancy for any given patient with adnexal mass.\n",
      "4.654643788057215\n",
      " Comparison of patient-reported outcomes may be invalidated by the occurrence of item bias, also known as differential item functioning.\n",
      "4.6357451238992695\n",
      "We show two ways of using structural equation modeling (SEM) to detect item bias: (1) multigroup SEM, which enables the detection of both uniform and nonuniform bias, and (2) multidimensional SEM, which enables the investigation of item bias with respect to several variables simultaneously.\n",
      "4.636263316761363\n",
      "Gender- and age-related bias in the items of the Hospital Anxiety and Depression Scale (HADS; Zigmond and Snaith in Acta Psychiatr Scand 67:361-370, 1983) from a sample of 1068 patients was investigated using the multigroup SEM approach and the multidimensional SEM approach.\n",
      "4.648745888157895\n",
      "Results were compared to the results of the ordinal logistic regression, item response theory, and contingency tables methods reported by Cameron et al.\n",
      "4.733690970284599\n",
      "(Qual Life Res 23:2883-2888, 2014).\n",
      "4.644629992739692\n",
      "Both SEM approaches identified two items with gender-related bias and two items with age-related bias in the Anxiety subscale, and four items with age-related bias in the Depression subscale.\n",
      "4.644628064385776\n",
      "Results from the SEM approaches generally agreed with the results of Cameron et al., although the SEM approaches identified more items as biased.\n",
      "4.667752295425258\n",
      "SEM provides a flexible tool for the investigation of item bias in health-related questionnaires.\n",
      "4.630245374596638\n",
      "Multidimensional SEM has practical and statistical advantages over multigroup SEM, and over other item bias detection methods, as it enables item bias detection with respect to multiple variables, of various measurement levels, and with more statistical power, ultimately providing more valid comparisons of patients' well-being in both research and clinical practice.\n",
      "4.654960469996675\n",
      " Many clinical guidelines recommend apolipoprotein B (apoB) measurement, particularly in subjects with metabolic syndrome or type 2 diabetes.\n",
      "4.680240796959919\n",
      "Recently, we developed a new equation to estimate serum apoB (apoBE).\n",
      "4.6450508214250394\n",
      "We validated the clinical relevance of apoBE and compared the performance of the equation with conventional lipid measurements and direct measurement of apoB.\n",
      "4.644202822730655\n",
      "Study subjects were recruited from patients who visited the Health Screening Center at Kangbuk Samsung Hospital between January and December 2009 for routine medical examinations (n=78125).\n",
      "4.644693014505026\n",
      "For analysis of coronary calcium score, we recruited study subjects from the same institution between January 2007 and December 2010 (n=16493).\n",
      "4.641066764164897\n",
      "apoBE was significantly correlated with serum high-sensitivity C-reactive level {r=0.18 [95% confidence interval (CI), 0.18-0.19]} in partial correlation analysis adjusted for age, sex, and body mass index.\n",
      "4.62083788209607\n",
      "apoBE was associated with a Framingham risk score indicating more than moderate risk (10-year risk ≥10%), the presence of microalbuminuria, and the presence of coronary artery calcium in multivariate logistic regression analysis.\n",
      "4.6328147847384695\n",
      "These associations were comparable to those of directly-measured serum apoB [odds ratio per 1 SD 3.02 (2.75-3.27) vs. 2.70 (2.42-3.02) for a Framingham risk score indicating more than moderate risk, 1.31 (1.21-1.41) vs. 1.35 (1.25-1.45) for the presence of microalbuminuria, and 1.33 (1.26-1.41) vs. 1.31 (1.23-1.38) for the presence of coronary calcium score respectively].\n",
      "4.665310728783701\n",
      "These findings were also consistently observed in subgroup analysis for subjects with type 2 diabetes.\n",
      "4.655284721310399\n",
      "The associations between cardiovascular surrogate markers and apoBE were comparable to those of directly-measured apoB.\n",
      "4.640479163785951\n",
      " To develop a predictive equation to screen for vertical root fractures (VRFs) by numerically evaluating the shapes of radiolucent areas on the periapical radiographs of endodontically treated maxillary incisors and premolars.\n",
      "4.659510458669355\n",
      "41 pre-operative periapical radiographs of maxillary incisors and premolars with radiolucent areas at root apices were used.\n",
      "4.675679726175742\n",
      "Out of 41 teeth, 18 had a fractured root (VRF group) and 23 had a non-fractured root (non-VRF group).\n",
      "4.647047254774305\n",
      "The periapical radiolucent area of each tooth was traced out by six examiners on a personal computer and two indices, \"Complexity\" and \"Radial SD\", were measured.\n",
      "4.6420423290397546\n",
      "For each index, the difference between the VRF and non-VRF groups and the interexaminer differences were analysed with two-way ANOVA at 5% significance level.\n",
      "4.650764855155109\n",
      "Multiple logistic regression analysis was used to develop a predictive equation and the probability of VRF in all samples was calculated.\n",
      "4.67231814066569\n",
      "A receiver operating characteristic (ROC) curve was constructed to select the optimal cut-point.\n",
      "4.688127854291131\n",
      "Each sample was predicted as \"VRF\" or \"non-VRF\" with this cut-point.\n",
      "4.657998833774535\n",
      "For both \"Complexity\" and \"Radial SD\", the VRF group showed significantly greater values than the non-VRF group (P<0.05).\n",
      "4.654002415314886\n",
      "With a cut-point derived from the ROC curve, sensitivity, specificity and efficiency of VRF were 0.68, 0.80 and 0.75, respectively.\n",
      "4.67852783203125\n",
      "VRF teeth have more complicated radiolucent areas compared with non-VRF teeth.\n",
      "4.65330379710478\n",
      "By evaluating the shapes of radiolucent areas, a logistic regression equation to screen for VRF was calculated and this equation could contribute to the diagnosis of VRF.\n",
      "4.642349825560592\n",
      " A logistic regression equation for the vacuous pulse and the replete pulse was determined based on data obtained using a clip-type pulsimeter equipped with a Hall device that sensed the change in the magnetic field due to the minute movement of a radial artery.\n",
      "4.634540089887314\n",
      "To evaluate the efficacy of the two different pulses from the deficiency and the excess syndrome groups, we performed a clinical trial, and we used a statistical regression analysis to process the clinical data from the 180 participants who were enrolled in this study.\n",
      "4.638779511322847\n",
      "The ratio of the systolic peak's amplitude to its time in the pulse's waveform was found to be a major efficacy parameter for differentiating between the vacuous pulse and the replete pulse using an empirical equation that was deduced from the data using a statistical logistic regression method.\n",
      "4.649542369981752\n",
      "This logistic regression equation can be applied to develop a novel algorithm for pulse measurements based on Oriental medical diagnoses.\n",
      "4.651303439670139\n",
      " Methods for direct measurement of glomerular filtration rate (GFR) are expensive and inconsistently applied across transplant centers.\n",
      "4.649942016601562\n",
      "The Modified Diet in Renal Disease (MDRD) equation is commonly used for GFR estimation, but is inaccurate for GFRs >60 ml/min per 1.73 m(2).\n",
      "4.652274498572717\n",
      "The Chronic Kidney Disease Epidemiology Collaboration (CKDEPI) and Wright equations have shown improved predictive capabilities in some patient populations.\n",
      "4.64583837890625\n",
      "We compared these equations to determine which one correlates best with direct GFR measurement in lung transplant candidates.\n",
      "4.6798876026008704\n",
      "We conducted a retrospective cohort analysis of 274 lung transplant recipients.\n",
      "4.685299295774648\n",
      "Pre-operative GFR was measured directly using a radionuclide GFR assay.\n",
      "4.657919253943102\n",
      "Results from the MDRD, CKDEPI, Wright, and Cockroft-Gault equations were compared with direct measurement.\n",
      "4.643163452148437\n",
      "Findings were validated using logistic regression models and receiver operating characteristic (ROC) analyses in looking at GFR as a predictor of mortality and renal function outcomes post-transplant.\n",
      "4.636439431477063\n",
      "Assessed against the radionuclide GFR measurement, CKDEPI provided the most consistent results, with low values for bias (0.78), relative standard error (0.03) and mean absolute percentage error (15.02).\n",
      "4.675212116984578\n",
      "Greater deviation from radionuclide GFR was observed for all other equations.\n",
      "4.665245691935222\n",
      "Pearson's correlation between radionuclide and calculated GFR was significant for all equations.\n",
      "4.642797076512897\n",
      "Regression and ROC analyses revealed equivalent utility of the radionuclide assay and GFR equations for predicting post-transplant acute kidney injury and chronic kidney disease (p < 0.05).\n",
      "4.640876726915607\n",
      "In patients being evaluated for lung transplantation, CKDEPI correlates closely with direct radionuclide GFR measurement and equivalently predicts post-operative renal outcomes.\n",
      "4.648409446574146\n",
      "Transplant centers could consider replacing or supplementing direct GFR measurement with less expensive, more convenient estimation by using the CKDEPI equation.\n",
      "4.644627538220636\n",
      " To develop an equation model of in-hospital mortality for mechanically ventilated patients in adult intensive care using administrative data for the purpose of retrospective performance comparison among intensive care units (ICUs).\n",
      "4.642790033576194\n",
      "Two models were developed using the split-half method, in which one test dataset and two validation datasets were used to develop and validate the prediction model, respectively.\n",
      "4.632314453125\n",
      "Nine candidate variables (demographics: age; gender; clinical factors hospital admission course; primary diagnosis; reason for ICU entry; Charlson score; number of organ failures; procedures and therapies administered at any time during ICU admission: renal replacement therapy; pressors/vasoconstrictors) were used for developing the equation model.\n",
      "4.663601989746094\n",
      "In acute-care teaching hospitals in Japan: 282 ICUs in 2008, 310 ICUs in 2009, and 364 ICUs in 2010.\n",
      "4.654770572628595\n",
      "Mechanically ventilated adult patients discharged from an ICU from July 1 to December 31 in 2008, 2009, and 2010.\n",
      "4.648661574272261\n",
      "The test dataset consisted of 5,807 patients in 2008, and the validation datasets consisted of 10,610 patients in 2009 and 7,576 patients in 2010.\n",
      "4.6453416907269025\n",
      "Two models were developed: Model 1 (using independent variables of demographics and clinical factors), Model 2 (using procedures and therapies administered at any time during ICU admission in addition to the variables in Model 1).\n",
      "4.642569206621005\n",
      "Using the test dataset, 8 variables (except for gender) were included in multiple logistic regression analysis with in-hospital mortality as the dependent variable, and the mortality prediction equation was constructed.\n",
      "4.679736667209202\n",
      "Coefficients from the equation were then tested in the validation model.\n",
      "4.6150599116772675\n",
      "Hosmer-Lemeshow χ(2) are values for the test dataset in Model 1 and Model 2, and were 11.9 (P = 0.15) and 15.6 (P = 0.05), respectively; C-statistics for the test dataset in Model 1and Model 2 were 0.70 and 0.78, respectively.\n",
      "4.654194839128101\n",
      "In-hospital mortality prediction for the validation datasets showed low and moderate accuracy in Model 1 and Model 2, respectively.\n",
      "4.642026672363281\n",
      "Model 2 may potentially serve as an alternative model for predicting mortality in mechanically ventilated patients, who have so far required physiological data for the accurate prediction of outcomes.\n",
      "4.648001006155303\n",
      "Model 2 may facilitate the comparative evaluation of in-hospital mortality in multicenter analyses based on administrative data for mechanically ventilated patients.\n",
      "4.64619239600929\n",
      " This research aimed to estimate the effect of perceived social factors in the community stress and problems on the residents' psychopathology such as depression and suicidal behaviors.\n",
      "4.666115785256411\n",
      "Subjects of this study were the informants (N=1618) in a psychological autopsy (PA) study with a case-control design.\n",
      "4.634045665800883\n",
      "We interviewed two informants (a family member and a close friend) for 392 suicides and 416 living controls, which came from 16 rural counties randomly selected from three provinces of China.\n",
      "4.676509433322483\n",
      "Community stress and problems were measured by the WHO SUPRE-MISS scale.\n",
      "4.671772596571181\n",
      "Depression was measured by CES-D scale, and suicidal behavior was assessed by NCS-R scale.\n",
      "4.641509876501091\n",
      "Multivariable liner and logistic regression models and the Structural Equation Modeling (SEM) were applied to probe the correlation of the depression and the suicidal behaviors with some major demographic variables as covariates.\n",
      "4.647405675939612\n",
      "It was found that community stress and problems were directly associated with rural Chinese residents' depression (Path coefficient=0.127, P<0.001).\n",
      "4.640925581737231\n",
      "There was no direct correlation between community stress and problem and suicidal behaviors, but community stress and problem can affect suicidal behaviors indirectly through depression.\n",
      "4.675915443733947\n",
      "The path coefficient between depression and suicidal behaviors was 0.975.\n",
      "4.646553574094347\n",
      "The current study predicts a new research viewpoint, that is, the depression is the intermediate between community stress and problem and suicidal behaviors.\n",
      "4.653726497166593\n",
      "It might be an effective route to prevent depression directly and suicidal behaviors indirectly by reducing the community stress and problems.\n",
      "4.643123750908431\n",
      " The aim of this study was to evaluate the effect of variables such as personality traits, driving behavior and mental illness on road traffic accidents among the drivers with accidents and those without road crash.\n",
      "4.692354232545883\n",
      "In this cohort study, 800 bus and truck drivers were recruited.\n",
      "4.6652743252840905\n",
      "Participants were selected among drivers who referred to Imam Sajjad Hospital (Tehran, Iran) during 2013-2015.\n",
      "4.647354912512081\n",
      "The Manchester driving behavior questionnaire (MDBQ), big five personality test (NEO personality inventory) and semi-structured interview (schizophrenia and affective disorders scale) were used.\n",
      "4.6660009765625\n",
      "After two years, we surveyed all accidents due to human factors that involved the recruited drivers.\n",
      "4.6521498491974915\n",
      "The data were analyzed using the SPSS software by performing the descriptive statistics, t-test, and multiple logistic regression analysis methods.\n",
      "4.680778734611742\n",
      "P values less than 0.05 were considered statistically significant.\n",
      "4.643628555689102\n",
      "In terms of controlling the effective and demographic variables, the findings revealed significant differences between the two groups of drivers that were and were not involved in road accidents.\n",
      "4.646852102338897\n",
      "In addition, it was found that depression and anxiety could increase the odds ratio (OR) of road accidents by 2.4- and 2.7-folds, respectively (P=0.04, P=0.004).\n",
      "4.642792062661083\n",
      "It is noteworthy to mention that neuroticism alone can increase the odds of road accidents by 1.1-fold (P=0.009), but other personality factors did not have a significant effect on the equation.\n",
      "4.668146306818182\n",
      "The results revealed that some mental disorders affect the incidence of road collisions.\n",
      "4.647722048875762\n",
      "Considering the importance and sensitivity of driving behavior, it is necessary to evaluate multiple psychological factors influencing drivers before and after receiving or renewing their driver's license.\n",
      "4.649044083960263\n",
      " The aim of this study was to extract the factors possibly associated with sertraline treatment response and elucidate their interactions and extent of influence.\n",
      "4.616894208952146\n",
      "Demographic state, stress state, personality, and eight genetic polymorphisms at baseline and clinical symptoms at baseline and 8 weeks were analyzed and examined by logistic regression and a structural equation model in sertraline treatment study of 96 Japanese patients with major depressive disorder.\n",
      "4.620136320777822\n",
      "Non-responders were associated with higher scores of harm avoidance in Temperament and Character Inventory, higher scores (≥24) of 17-item Hamilton Rating Scale for Depression at baseline, recurrence, and 12/12 genotype of the serotonin transporter variable number of tandem repeat polymorphism in intron 2 (5HTTSTin2).\n",
      "4.646284253669507\n",
      "When we calculated the response index using four factors extracted, the mean response index value of non-responders was significantly higher than that of responders.\n",
      "4.622074731334842\n",
      "The symptoms at baseline, personality, recurrence, and polymorphism of 5HTTSTin2 showed significantly direct and positive influences on the symptoms at 8 weeks in our final structural equation model with a good model fit.\n",
      "4.644637722439236\n",
      "Considering the combination of four factors extracted may be useful for predicting a worse response to sertraline treatment and selecting different treatment other than sertraline.\n",
      "4.64969755912739\n",
      " To determine the underlying substrate utilization mechanism in the logistic equation for batch microbial growth by revealing the relationship between the logistic and Monod kinetics.\n",
      "4.680453044612233\n",
      "Also, to determine the logistic rate constant in terms of Monod kinetic constants.\n",
      "4.6488595736228815\n",
      "The logistic equation used to describe batch microbial growth was related to the Monod kinetics and found to be first-order in terms of the substrate and biomass concentrations.\n",
      "4.688557298877571\n",
      "The logistic equation constant was also related to the Monod kinetic constants.\n",
      "4.663331821986607\n",
      "Similarly, the substrate utilization kinetic equations were derived by using the logistic growth equation and related to the Monod kinetics.\n",
      "4.650892130533854\n",
      "It is revaled that the logistic growth equation is a special form of the Monod growth kinetics when substrate limitation is first-order with respect to the substrate concentration.\n",
      "4.648022289007482\n",
      "The logistic rate constant (k) is directly proportional to the maximum specific growth rate constant (mu(m)) and initial substrate concentration (S(0)) and also inversely related to the saturation constant (K(s)).\n",
      "4.647467251481681\n",
      "The semi-empirical logistic equation can be used instead of Monod kinetics at low substrate concentrations to describe batch microbial growth using the relationship between the logistic rate constant and the Monod kinetic constants.\n",
      "4.6457978197808805\n",
      " Ten permanent plots of Larix olgensis plantation were established in 1972 and 1974 at Jiangshanjiao and Mengjiagang forest farms in Heilongjiang Province, respectively.\n",
      "4.671826171875\n",
      "The plots including 8 thinning plots and 2 control plots were measured annually.\n",
      "4.658467610677083\n",
      "The effects of thinning on the probability of plot mortality and individual tree mortality were analyzed.\n",
      "4.662958585298979\n",
      "Based on the binary logistic regression, two-step models of the probability of mortality were developed.\n",
      "4.648586778755647\n",
      "The approach consisted of estimating the probability of mortality after thinning on a sample plot (1) and the mortality of individual tree within mortality plots (2).\n",
      "4.667349767203283\n",
      "The generalized estimating equations (GEE) method was adopted to estimate the parameters of models.\n",
      "4.649204294305099\n",
      "An optimal cutpoint was determined for each model by plotting the sensitivity curve and the specificity curve and choosing the cutpoint at which the specificity and sensitivity curves cross.\n",
      "4.650768255418347\n",
      "The results showed that four models (models 1-4) were developed based on the data of plots which was divided into 4 groups by thinning times, respectively.\n",
      "4.658878737229568\n",
      "The significant explicatory variables of model 1 were site index, the logarithm of stand age, thinning age and thinning intensity.\n",
      "4.700113932291667\n",
      "Principal component analysis was used to develop models 2-4.\n",
      "4.648563232421875\n",
      "The primal variables of the principal components were stand age, tree numbers per hectare, mean square diameter at breast height and thinning factors.\n",
      "4.6759095709007905\n",
      "This showed that thinning significantly affected the probability of plot mortality.\n",
      "4.669627199890793\n",
      "The effect of thinning was not significant for the pro-bability of individual tree mortality.\n",
      "4.643346854967949\n",
      "The significant variables of the individual tree mortality model were planting density, age, the inverse of diameter at breast height and the basal area of all trees larger than the subject tree.\n",
      "4.614599032664862\n",
      "Hosmer and Lemeshow goodness of fit tests were not significant for the mortality models of plots and individual trees (P＞0.05).\n",
      "4.638821235069861\n",
      "The areas under the receiver operating characteristic curve (AUC) of the models were all greater than 0.91, the accuracies were all above 80%, suggesting the fitting results of the models performed very well.\n",
      "4.6633737546588305\n",
      " While risk factors for depression are increasingly known, there is no widely utilised depression risk index.\n",
      "4.640415668487549\n",
      "Our objective was to develop a method for a flexible, modular, Risk Index for Depression using structural equation models of key determinants identified from previous published research that blended machine-learning with traditional statistical techniques.\n",
      "4.590836007254464\n",
      "Demographic, clinical and laboratory variables from the National Health and Nutrition Examination Study (2009-2010, N = 5546) were utilised.\n",
      "4.701267787388393\n",
      "Data were split 50:50 into training:validation datasets.\n",
      "4.5877314753093\n",
      "Generalised structural equation models, using logistic regression, were developed with a binary outcome depression measure (Patient Health Questionnaire-9 score ⩾ 10) and previously identified determinants of depression: demographics, lifestyle-environs, diet, biomarkers and somatic symptoms.\n",
      "4.646424093364198\n",
      "Indicative goodness-of-fit statistics and Areas Under the Receiver Operator Characteristic Curves were calculated and probit regression checked model consistency.\n",
      "4.6779620830829325\n",
      "The generalised structural equation model was built from a systematic process.\n",
      "4.623760705706717\n",
      "Relative importance of the depression determinants were diet (odds ratio: 4.09; 95% confidence interval: [2.01, 8.35]), lifestyle-environs (odds ratio: 2.15; 95% CI: [1.57, 2.94]), somatic symptoms (odds ratio: 2.10; 95% CI: [1.58, 2.80]), demographics (odds ratio:1.46; 95% CI: [0.72, 2.95]) and biomarkers (odds ratio:1.39; 95% CI: [1.00, 1.93]).\n",
      "4.649171560402684\n",
      "The relationships between demographics and lifestyle-environs and depression indicated a potential indirect path via somatic symptoms and biomarkers.\n",
      "4.718221491033381\n",
      "The path from diet was direct to depression.\n",
      "4.423920988305214\n",
      "The Areas under the Receiver Operator Characteristic Curves were good (logistic:training = 0.850, validation = 0.813; probit:training = 0.849, validation = 0.809).\n",
      "4.640041611759538\n",
      "The novel Risk Index for Depression modular methodology developed has the flexibility to add/remove direct/indirect risk determinants paths to depression using a structural equation model on datasets that take account of a wide range of known risks.\n",
      "4.638541726505055\n",
      "Risk Index for Depression shows promise for future clinical use by providing indications of main determinant(s) associated with a patient's predisposition to depression and has the ability to be translated for the development of risk indices for other affective disorders.\n",
      "4.6425176397100225\n",
      " We developed a mathematical \"prostate cancer (PCa) conditions simulating\" predictive model (PCP-SMART), from which we derived a novel PCa predictor (prostate cancer risk determinator [PCRD] index) and a PCa risk equation.\n",
      "4.666841735839844\n",
      "We used these to estimate the probability of finding PCa on prostate biopsy, on an individual basis.\n",
      "4.658368644067797\n",
      "A total of 371 men who had undergone transrectal ultrasound-guided prostate biopsy were enrolled in the present study.\n",
      "4.614939655440737\n",
      "Given that PCa risk relates to the total prostate-specific antigen (tPSA) level, age, prostate volume, free PSA (fPSA), fPSA/tPSA ratio, and PSA density and that tPSA ≥ 50 ng/mL has a 98.5% positive predictive value for a PCa diagnosis, we hypothesized that correlating 2 variables composed of 3 ratios (1, tPSA/age; 2, tPSA/prostate volume; and 3, fPSA/tPSA; 1 variable including the patient's tPSA and the other, a tPSA value of 50 ng/mL) could operate as a PCa conditions imitating/simulating model.\n",
      "4.657788292836335\n",
      "Linear regression analysis was used to derive the coefficient of determination (R<sup>2</sup>), termed the PCRD index.\n",
      "4.590934753417969\n",
      "To estimate the PCRD index's predictive validity, we used the χ<sup>2</sup> test, multiple logistic regression analysis with PCa risk equation formation, calculation of test performance characteristics, and area under the receiver operating characteristic curve analysis using SPSS, version 22 (P < .05).\n",
      "4.669379376350565\n",
      "The biopsy findings were positive for PCa in 167 patients (45.1%) and negative in 164 (44.2%).\n",
      "4.591793441772461\n",
      "The PCRD index was positively signed in 89.82% positive PCa cases and negative in 91.46% negative PCa cases (χ<sup>2</sup> test; P < .001; relative risk, 8.98).\n",
      "4.650443856574629\n",
      "The sensitivity was 89.8%, specificity was 91.5%, positive predictive value was 91.5%, negative predictive value was 89.8%, positive likelihood ratio was 10.5, negative likelihood ratio was 0.11, and accuracy was 90.6%.\n",
      "4.644717390366022\n",
      "Multiple logistic regression revealed the PCRD index as an independent PCa predictor, and the formulated risk equation was 91% accurate in predicting the probability of finding PCa.\n",
      "4.620938982282366\n",
      "On the receiver operating characteristic analysis, the PCRD index (area under the curve, 0.926) significantly (P < .001) outperformed other, established PCa predictors.\n",
      "4.640208472275153\n",
      "The PCRD index effectively predicted the prostate biopsy outcome, correctly identifying 9 of 10 men who were eventually diagnosed with PCa and correctly ruling out PCa for 9 of 10 men who did not have PCa.\n",
      "4.643206757623792\n",
      "Its predictive power significantly outperformed established PCa predictors, and the formulated risk equation accurately calculated the probability of finding cancer on biopsy, on an individual patient basis.\n",
      "4.674257339969758\n",
      " Unconditioned logistic regression is a highly useful risk prediction method in epidemiology.\n",
      "4.643907600274965\n",
      "This article reviews the different solutions provided by different authors concerning the interface between the calculation of the sample size and the use of logistics regression.\n",
      "4.638754835406553\n",
      "Based on the knowledge of the information initially provided, a review is made of the customized regression and predictive constriction phenomenon, the design of an ordinal exposition with a binary output, the event of interest per variable concept, the indicator variables, the classic Freeman equation, etc.\n",
      "4.696268389301915\n",
      "Some skeptical ideas regarding this subject are also included.\n",
      "4.649176865994574\n",
      " Periodontal disease is associated with diabetes, heart disease, and chronic kidney disease (CKD), relationships postulated to be due in part to vascular inflammation.\n",
      "4.650925239507299\n",
      "A bidirectional relationship between CKD and periodontal disease is plausible, though this relationship has not been previously reported.\n",
      "4.622706943088108\n",
      "In this study, we assessed the potential for connections between CKD and periodontal disease, and mediators of these relationships using structural equation models of data from 11,211 adults ≥ 18 years of age who participated in the Third National Health and Nutrition Examination Survey.\n",
      "4.654419836336679\n",
      "Multivariable logistic regression models were used to test the hypothesis that periodontal disease was independently associated with CKD.\n",
      "4.630018214723763\n",
      "Given the potential that the periodontal disease and CKD relationship may be bidirectional, a two-step analytic approach was used that involved tests for mediation and structural equation models to examine more complex direct and indirect effects of periodontal disease on CKD, and vice versa.\n",
      "4.6401351054859585\n",
      "In two separate models, periodontal disease (adjusted odds ratio of 1.62), edentulism (adjusted odds ratio of 1.83), and the periodontal disease score were associated with CKD when simultaneously adjusting for 14 other factors.\n",
      "4.670301835615557\n",
      "Altogether, three of four structural equation models support the hypothesized relationship.\n",
      "4.645647736633716\n",
      "Thus, our analyses support a bidirectional relationship between CKD and periodontal disease, mediated by hypertension and the duration of diabetes.\n",
      "4.64137217762706\n",
      " The time required before a mass of cancer cells considered to have originated from a single malignantly transformed cancer 'stem' cell reaches a certain number has not been studied.\n",
      "4.638969854496452\n",
      "Applications might include determination of the time the cell mass reaches a size that can be detected by X-rays or physical examination or modeling growth rates in vitro in order to compare with other models or established data.\n",
      "4.6472176771897535\n",
      "We employed a simple logarithmic equation and a common logistic equation incorporating 'feedback' for unknown variables of cell birth, growth, division, and death that can be used to model cell proliferation.\n",
      "4.680651448567708\n",
      "It can be used in association with free or commercial statistical software.\n",
      "4.654277115417042\n",
      "Results with these two equations, varying the proliferation rate, nominally reduced by generational cell loss, are presented in two tables.\n",
      "4.639542061941964\n",
      "The resulting equation, instructions, examples, and necessary mathematical software are available in the online appendix, where several parameters of interest can be modified by the reader www.uic.edu/nursing/publicationsupplements/tobillion_Anderson_Rubenstein_Guinan_Patel1.pdf.\n",
      "4.65404005174513\n",
      "Reducing the proliferation rate by whatever alterations employed, markedly increases the time to reach 10(9) cells originating from an initial progenitor.\n",
      "4.650465772331105\n",
      "In thinking about multistep oncogenesis, it is useful to consider the profound effect that variations in the effective proliferation rate may have during cancer development.\n",
      "4.6559509661212655\n",
      "This can be approached with the proposed equation, which is easy to use and available to further peer fine-tuning to be used in future modeling of cell growth.\n",
      "4.661063816236413\n",
      " The transition density of a stochastic, logistic population growth model with multiplicative intrinsic noise is analytically intractable.\n",
      "4.645384974449685\n",
      "Inferring model parameter values by fitting such stochastic differential equation (SDE) models to data therefore requires relatively slow numerical simulation.\n",
      "4.643830217633929\n",
      "Where such simulation is prohibitively slow, an alternative is to use model approximations which do have an analytically tractable transition density, enabling fast inference.\n",
      "4.656116704831178\n",
      "We introduce two such approximations, with either multiplicative or additive intrinsic noise, each derived from the linear noise approximation (LNA) of a logistic growth SDE.\n",
      "4.645412160389459\n",
      "After Bayesian inference we find that our fast LNA models, using Kalman filter recursion for computation of marginal likelihoods, give similar posterior distributions to slow, arbitrarily exact models.\n",
      "4.6489914519877376\n",
      "We also demonstrate that simulations from our LNA models better describe the characteristics of the stochastic logistic growth models than a related approach.\n",
      "4.633254620207458\n",
      "Finally, we demonstrate that our LNA model with additive intrinsic noise and measurement error best describes an example set of longitudinal observations of microbial population size taken from a typical, genome-wide screening experiment.\n",
      "4.658622233072917\n",
      " Chronic kidney disease accounts for much of the increased mortality, especially in the elder population.\n",
      "4.67061966456724\n",
      "The prevalence of this disease is expected to increase significantly as the society ages.\n",
      "4.656602762513241\n",
      "Our aim was to evaluate the kidney function and risk factors of reduced renal function among elderly Chinese patients.\n",
      "4.662870279947916\n",
      "This study retrospectively collected clinical data from a total of 1062 inpatients aged 65 years or over.\n",
      "4.653949821082345\n",
      "Estimated glomerular filtration rate (eGFR) was calculated with the Chronic Kidney Disease Epidemiology Collaboration (CKD-EPI) equation.\n",
      "4.703602809532016\n",
      "Renal function and risk factors were also analyzed.\n",
      "4.526795309696471\n",
      "For all 1062 subjects, the mean eGFR was 71.0 ± 24.8 mL/min/1.73 m(2), and the incidence rates of reduced renal function, proteinuria, hematuria and leukocyturia were 31.1%, 11.8%, 6.6% and 8.7%, respectively.\n",
      "4.259199478301495\n",
      "The eGFR values were 83.4 ± 28.4, 72.2 ± 22.9, 67.8 ± 24.3 and 58.8 ± 29.1 mL/min/1.73 m(2) in the groups of 60-69, 70-79, 80-89 and ≥90 years age group (F = 15.101, p = 0.000), respectively; while the incidences of reduced renal function were 12.8%, 27.0%, 37.8% and 51.7% (χ(2) = 36.143, p = 0.000).\n",
      "4.214514078956485\n",
      "Binary logistic regression analysis showed that hyperuricemia (OR = 4.62, p = 0.000), proteinuria (OR = 3.96, p = 0.000), urinary tumor (OR = 2.92, p = 0.015), anemia (OR = 2.45, p = 0.000), stroke (OR = 1.96, p = 0.000), hypertension (OR = 1.83, p = 0.006), renal cyst (OR = 1.64, p = 0.018), female (OR = 1.54, p = 0.015), coronary artery disease (OR = 1.53, p = 0.008) and age (OR = 1.05, p = 0.000) were the risk factors of reduced renal function.\n",
      "4.652562021419702\n",
      "In conclusion, eGFR values decreased by age, while the incidence of reduced renal function, proteinuria, hematuria and leukocyturia increased with age.\n",
      "4.665619830695951\n",
      "Treatment and control of comorbidities may slow the decline of renal function in elderly patients.\n",
      "4.645361745459402\n",
      " To investigate the risk factors for the short-term outcome of patients with hepatitis B virus (HBV)-related acute-on-chronic liver failure (ACLF), and to establish a risk model for predicting the short-term outcome of these patients.\n",
      "4.64096920306866\n",
      "A total of 338 patients with HBV-related ACLF who were admitted to 30 Lod hospital of PLA hospital from January 2010 to January 2014 were enrolled, and a prospective clinical follow-up was performed for them.\n",
      "4.645343122811153\n",
      "Multivariate logistic regression was used to determine the risk factors for short-term (12 weeks) outcome, the predictive model with logistic regression equation was established, and the predictive value of this model was evaluated.\n",
      "4.633959711814414\n",
      "The multivariate logistic regression analysis showed that age, a family history of hepatitis B, hepatic encephalopathy (HE), hepatorenal syndrome (HRS), white blood cell (WBC), platelet (PLT), international normalized ratio (INR), total bilirubin (TBil), total bile acid (TBA), creatinine, Na, HBV DNA, and HBeAg were the independent risk factors for the short-term outcome of these patients.\n",
      "4.645295173891129\n",
      "Logistic(p) = -4.466 + 1.192 age + 1.631 family history of hepatitis B + 1.091 HE + 1.631 HRS + 1.208 WBC -1.487 PLT + 1.092 INR + 1.446 TBil + 1.608 TBA -1.101 CHE + 1.279 CRE -1.713 Na + 1.032 HBV DNA + 0.833 HBeAg.\n",
      "4.643280759382476\n",
      "The area under the receiver operating characteristic curve of the model for the prediction of short-term outcome was 0.930, the cut-off value was 3.16, the sensitivity was 0.860, and the specificity was 0.871.\n",
      "4.670545481672191\n",
      "With the increasing scores of the equation, the mortality of patients tended to increase gradually.\n",
      "4.645465087890625\n",
      "Age, a family history of hepatitis B, HE, HRS, WBC, PLT, INR, TBil, TBA, CHE, CRE, Na, HBV DNA, and HBeAg are the independent risk factors for the short-term outcome of patients with HBV-related ACLF.\n",
      "4.654135311351103\n",
      "The model for predicting short-term outcome established on the basis of independent risk factors has a better clinical value in guiding clinical therapy.\n",
      "4.656609370790679\n",
      " Longitudinal studies are often applied in biomedical research and clinical trials to evaluate the treatment effect.\n",
      "4.655317976668075\n",
      "The association pattern within the subject must be considered in both sample size calculation and the analysis.\n",
      "4.62100549646326\n",
      "One of the most important approaches to analyze such a study is the generalized estimating equation (GEE) proposed by Liang and Zeger, in which \"working correlation structure\" is introduced and the association pattern within the subject depends on a vector of association parameters denoted by ρ.\n",
      "4.646333372438109\n",
      "The explicit sample size formulas for two-group comparison in linear and logistic regression models are obtained based on the GEE method by Liu and Liang.\n",
      "4.638526329627404\n",
      "For cluster randomized trials (CRTs), researchers proposed the optimal sample sizes at both the cluster and individual level as a function of sampling costs and the intracluster correlation coefficient (ICC).\n",
      "4.676413340111301\n",
      "In these approaches, the optimal sample sizes depend strongly on the ICC.\n",
      "4.6824780632467835\n",
      "However, the ICC is usually unknown for CRTs and multicenter trials.\n",
      "4.625463562011719\n",
      "To overcome this shortcoming, Van Breukelen et al.\n",
      "4.641310617713731\n",
      "consider a range of possible ICC values identified from literature reviews and present Maximin designs (MMDs) based on relative efficiency (RE) and efficiency under budget and cost constraints.\n",
      "4.6357170279699424\n",
      "In this paper, the optimal sample size and number of repeated measurements using GEE models with an exchangeable working correlation matrix is proposed under the considerations of fixed budget, where \"optimal\" refers to maximum power for a given sampling budget.\n",
      "4.583800166486258\n",
      "The equations of sample size and number of repeated measurements for a known parameter value ρ are derived and a straightforward algorithm for unknown ρ is developed.\n",
      "4.7428831442808495\n",
      "Applications in practice are discussed.\n",
      "4.666829329270583\n",
      "We also discuss the existence of the optimal design when an AR(1) working correlation matrix is assumed.\n",
      "4.658463187839674\n",
      "Our proposed method can be extended under the scenarios when the true and working correlation matrix are different.\n",
      "4.644557525224215\n",
      " The aim of this study was to develop a predictive model of objective oropharyngeal obstructive sleep apnea (OSA) surgery outcomes including success rate and apnea-hypopnea index (AHI) reduction ratio in adult OSA patients.\n",
      "4.7833030454574095\n",
      "Retrospective outcome research.\n",
      "4.64629995222572\n",
      "All subjects with OSA who underwent oropharyngeal and/or nasal surgery and were followed for at least 3 months were enrolled in this study.\n",
      "4.6532465237290115\n",
      "Demographic, anatomical [tonsil size (TS) and palate-tongue position (PTP) grade (Gr)], and polysomnographic parameters were analyzed.\n",
      "4.623432571339495\n",
      "The AHI reduction ratio (%) was defined as [(postoperative AHI-preoperative AHI) x 100 / postoperative AHI], and surgical success was defined as a ≥ 50% reduction in preoperative AHI with a postoperative AHI < 20.\n",
      "4.5807555647920974\n",
      "A total of 156 consecutive OSAS adult patients (mean age ± SD = 38.9 ± 9.6, M / F = 149 / 7) were included in this study.\n",
      "4.6385565423346184\n",
      "The best predictive equation by Forward Selection likelihood ratio (LR) logistic regression analysis was: [Formula: see text]The best predictive equation according to stepwise multiple linear regression analysis was: [Formula: see text] (TS/PTP Gr = 1 if TS/PTP Gr 3 or 4, TS/PTP Gr = 0 if TS/PTP Gr 1 or 2).\n",
      "4.646497002963362\n",
      "The predictive models for oropharyngeal surgery described in this study may be useful for planning surgical treatments and improving objective outcomes in adult OSA patients.\n",
      "4.645522999651555\n",
      " The purpose of this study was to evaluate the diagnostic efficiency for hepatocellular carcinoma (HCC) with the combined analysis of alpha-l-fucosidase (AFU), alpha-fetoprotein (AFP) and thymidine kinase 1 (TK1).\n",
      "4.646796909629876\n",
      "Serum levels of AFU, AFP and TK1 were measured in: 116 patients with HCC, 109 patients with benign hepatic diseases, and 104 normal subjects.\n",
      "4.6588454707976314\n",
      "The diagnostic value was analyzed using the logistic regression equation and receiver operating characteristic curves (ROC).\n",
      "4.534903110601963\n",
      "Statistical distribution of the three tested tumor markers in every group was non-normally distributed (Kolmogorov-Sminov test, Z = 0.156-0.517, P < 0.001).\n",
      "4.544013093647204\n",
      "The serum levels of AFP and TK1 in patients with HCC were significantly higher than those in patients with benign hepatic diseases (Mann-Whitney U test, Z = -8.570 to -5.943, all P < 0.001).\n",
      "4.511349846335018\n",
      "However, there was no statistically significant difference of AFU between these two groups (Mann-Whitney U test, Z = -1.820, P = 0.069).\n",
      "4.5264516062550735\n",
      "The levels of AFU were significantly higher in patients with benign hepatic diseases than in normal subjects (Mann-Whitney U test, Z = -7.984, P < 0.001).\n",
      "4.551868493477123\n",
      "Receiver operating characteristic curves (ROC) in patients with HCC versus those without HCC indicated the optimal cut-off value was 40.80 U/L for AFU, 10.86 μg/L for AFP and 1.92 pmol/L for TK1, respectively.\n",
      "4.649572933421416\n",
      "The area under ROC curve (AUC) was 0.718 for AFU, 0.832 for AFP, 0.773 for TK1 and 0.900 for the combination of the three tumor markers.\n",
      "4.678317379641842\n",
      "The combination resulted in a higher Youden index and a sensitivity of 85.3%.\n",
      "4.649024324044169\n",
      "The combined detection of serum AFU, AFP and TK1 could play a complementary role in the diagnosis of HCC, and could significantly improve the sensitivity for the diagnosis of HCC.\n",
      "4.6505716402236725\n",
      " Self-rated health is a robust predictor of several health outcomes, such as functional ability, health care utilization, morbidity and mortality.\n",
      "4.6456298828125\n",
      "The purpose of this study is to investigate and explore how health locus of control and disease burden relate to self-rated health among patients at risk for cardiovascular disease.\n",
      "4.64765188547486\n",
      "In 2009, 414 Swedish patients who were using statins completed a questionnaire about their health, diseases and their views on the three-dimensional health locus of control scale.\n",
      "4.649104787342584\n",
      "The scale determines which category of health locus of control - internal, chance or powerful others - a patient most identifies with.\n",
      "4.674193672511889\n",
      "The data was analyzed using logistic regression and a structural equation modeling approach.\n",
      "4.6382435038342456\n",
      "The analyses showed positive associations between internal health locus of control and self-rated health, and a negative association between health locus of control in chance and powerful others and self-rated health.\n",
      "4.640429119731104\n",
      "High internal health locus of control was negatively associated with the cumulative burden of diseases, while health locus of control in chance and powerful others were positively associated with burden of diseases.\n",
      "4.659361241227489\n",
      "In addition, age and education level had indirect associations with self-rated health through health locus of control.\n",
      "4.639528975527511\n",
      "This study suggests that self-rated health is positively correlated with internal locus of control and negatively associated with high locus of control in chance and powerful others in patients at high risk for cardiovascular disease.\n",
      "4.670967371323529\n",
      "Furthermore, disease burden seems to be negatively associated with self-rated health.\n",
      "4.656198185982464\n",
      " To establish the regression model predicting the probability of the capsular penetration according to the Chinese prostate cancer samples.\n",
      "4.644243315788312\n",
      "Men enrolled in the Fudan University Shanghai Cancer Centre and undergoing radical prostatectomy between January 2006 and April 2010 were used to establish the predicting model.\n",
      "4.64326698874587\n",
      "According to the pathology after radical prostatectomy, all cases were divided into two groups: organ confined disease group and locally advanced disease group, the difference of which were whether had the capsular penetration.\n",
      "4.690459696451823\n",
      "The cases with regional lymph node metastasis were excluded.\n",
      "4.669354393368676\n",
      "Serum prostate specific antigen level, Gleason grade, clinical stage were collected.\n",
      "4.6515936418013135\n",
      "Multiple Logistic regression model was established according to preoperative clinical data and postoperative pathological data to predict the incidence of capsular penetration.\n",
      "4.673547024197049\n",
      "Receiver operating characteristic curve was used for the internal validation of the model.\n",
      "4.588818768549232\n",
      "83 Chinese men were identified in the organ confined disease group with the age of 66.8 ± 5.8 years, and 36 in the locally advanced disease group with the age of 66.0 ± 6.8 years.\n",
      "4.662766366634729\n",
      "The difference of the age between the two groups were of no statistic significance (t = 0.650, P = 0.517).\n",
      "4.634620820945091\n",
      "The serum prostate specific antigen level (Wilcoxon W = 4562.0, P = 0.016), Gleason score (Wilcoxon W = 4586.5, P = 0.016), and clinical stage (Wilcoxon W = 4444.5, P = 0.001) of the locally advanced disease group were higher than the other group.\n",
      "4.574848390975088\n",
      "The equation of the multiple Logistic regression model was Logit P = 0.488 × Gleason score + 0.104 × clinical stage -6.187, with the freedom degree of two and the likelihood ratio χ(2) test of 11.263 (P = 0.001).\n",
      "4.649783944725094\n",
      "The area under the ROC curve (AUC) for capsular penetration was 0.696 (P = 0.001), with the 95% confidence interval of 0.598 - 0.793.\n",
      "4.636293841422872\n",
      "The multiple Logistic regression model based on the Chinese population can accurately predict the probability of capsular penetration of the prostate cancer and work on well with high internal accuracy when clinical decisions are made.\n",
      "4.648426402698863\n",
      " Inflammation may play an important role in the association between exposure to polycyclic aromatic hydrocarbons (PAHs) and atherosclerotic cardiovascular disease (ASCVD) risk.\n",
      "4.7099761962890625\n",
      "However, the underlying mechanisms remain unclear.\n",
      "4.645587944545629\n",
      "To investigate the association of PAHs exposure with ASCVD risk and effects of mean platelet volume (MPV) or Club cell secretory protein (CC16) on the association.\n",
      "4.65064811706543\n",
      "A total of 2022 subjects (689 men and 1333 women) were drawn from the baseline Wuhan residents of the Wuhan-Zhuhai Cohort study.\n",
      "4.676197960263207\n",
      "Data on demography and the physical examination were obtained from each participant.\n",
      "4.662462986937356\n",
      "Urinary monohydroxy PAH metabolites (OH-PAHs) levels were measured by a gas chromatography-mass spectrometry.\n",
      "4.640427774457789\n",
      "We estimated the association between each OH-PAHs and the 10-year ASCVD risk or coronary heart disease (CHD) risk using logistic regression models, and further analyze the mediating effect of MPV or plasma CC16 on the association by using structural equation modeling.\n",
      "4.465020529696253\n",
      "The results of multiple logistic regression models showed that some OH-PAHs were positively associated with ASCVD risk but not CHD risk, including 2-hydroxyfluoren (β = 1.761; 95% CI: 1.194-2.597), 9-hydroxyfluoren (β = 1.470; 95% CI: 1.139-1.898), 1-hydroxyphenanthrene (β = 1.480; 95% CI: 1.008-2.175) and ΣOH-PAHs levels (β = 1.699; 95% CI: 1.151-2.507).\n",
      "4.597582465277778\n",
      "The analysis of structural equation modeling shows that increased MPV and increased plasma CC16 levels contributed 13.6% and 15.1%, respectively, to the association between PAHs exposure and the 10-year ASCVD risk (p < 0.05).\n",
      "4.662695431014867\n",
      "Exposure to PAHs may increase the risk of atherosclerosis, which was partially mediated by MPV or CC16.\n",
      "4.642850809429415\n",
      " To assess respective roles of serum creatinine (SCr) alone and estimated glomerular filtration rate (eGFR) as an early predictor for contrast-induced nephropathy (CIN) in elderly patients with cancer.\n",
      "4.6516335227272725\n",
      "eGFR of 348 patients at 65years or older with malignancy who underwent contrast-enhanced computed tomography (CECT) were calculated.\n",
      "4.643702013739224\n",
      "eGFR was calculated based on the following three equations: Chronic Kidney Disease Epidemiology Collaboration equation (CKD-EPI); Modification of Diet in Renal Disease Study (MDRD); Cockcroft-Gault (CG).\n",
      "4.625186695772059\n",
      "CIN was subdivided into two groups: CIN<sub>25%</sub> (SCr increase >25% but ≤0.5mg/dl), and CIN<sub>0.5</sub> (SCr increase >0.5mg/dl).\n",
      "4.669117417446403\n",
      "The occurrence and clinical outcomes of CIN were determined according to SCr and eGFR.\n",
      "4.6593737098259655\n",
      "After CECT, CIN occurred in 50 (14.4%) patients, including 33 CIN<sub>25%</sub> patients and 17 CIN<sub>0.5</sub> patients.\n",
      "4.657273843254842\n",
      "CIN<sub>0.5</sub> was significantly correlated with prolonged hospitalizations and increased in-hospital mortality, but not CIN<sub>25%</sub>.\n",
      "4.639789599377962\n",
      "Despite SCr<1.5mg/dl, preexisting renal insufficiency (RI) was observed in 47 (13.5%) patients based on CKD-EPI equation, 50 (14.4%) patients based on MDRD equation, and 144 (41.4%) patients based on CG formula.\n",
      "4.637862311469184\n",
      "In preexisting RI, the prevalence of CIN<sub>0.5</sub> had an odds ratio of 15.02 (5.24 to 43.07) based on CKD-EPI equation, 13.73 (4.81 to 39.20) based on MDRD equation, and 5.03 (1.60 to 15.75) based on CG formula.\n",
      "4.639207356770833\n",
      "In elderly patients with cancer who visit the emergency department, renal assessment before CECT using CKD-EPI equation was superior to SCr alone, MDRD equation, or CG formula in predicting the occurrence of CIN related CECT.\n",
      "4.640240778688525\n",
      " This study aimed to develop a structural model for mammography adoption in Japanese middle-aged women by using constructs from the transtheoretical model (TTM), the theory of planned behavior (TPB), implementation intentions, and cancer worry.\n",
      "4.584911289499767\n",
      "Questionnaires based on items including TTM, TPB, implementation intentions, cancer worry-related variables, and demographic variables were distributed to 1000 adult women aged 40 to 59 years, with 641 subjects being used in the final analysis (response rate = 64.1%).\n",
      "4.6340824097625966\n",
      "Regarding the stage of adoption, 79 participants (12.3%) were at the precontemplation stage, 30 (4.7%) were at the relapse stage, 142 (22.2%) were at the contemplation stage, 88 (13.7%) were at the action stage, and 302 (47.1%) were at the maintenance stage.\n",
      "4.638912109375\n",
      "Our model, derived from structural equation modeling, revealed that the stage of mammography adoption was significantly affected by goal intentions, implementation intentions, perceived barriers, history of breast cancer screening, and relative risk.\n",
      "4.6203155517578125\n",
      "A logistic regression analysis revealed that goal intentions and implementation intentions significantly predicted mammography uptake within 1 year.\n",
      "4.643561247353242\n",
      "This study developed an integrated model constructed from TTM, TPB, implementation intentions, and cancer worry to account for mammography adoption in Japan, and also confirmed the predictive validity of the model.\n",
      "4.644105881911058\n",
      " We have used the leave-one-out (LOO) method and the area under the receiver operating characteristic (ROC) curve to validate logistic models with a sample of 167 patients with calvarial lesions.\n",
      "4.650164358956474\n",
      "Seven logistic regression models were developed from 12 clinical and radiological variables to predict the most common diagnoses separately.\n",
      "4.6963515743132564\n",
      "The LOO method was used to test the validity of the equations.\n",
      "4.666258821782377\n",
      "The discriminant power of every model was assessed by means of the area under the ROC curve (Az).\n",
      "4.6625807625906805\n",
      "The model with the greatest discrimination ability for the whole data set was the osteoma equation (Az = 0.951).\n",
      "4.648766326904297\n",
      "The discriminatory ability of the statistical models decreased significantly with the LOO procedure, having the malignancy model the highest value (Az = 0.931).\n",
      "4.654259195133132\n",
      "The LOO method can obtain a high benefit from small samples in order to validate prediction rules.\n",
      "4.660039918035523\n",
      "In studies with small samples, resampling techniques such as the LOO should be routinely used in predictive modeling.\n",
      "4.670109540566631\n",
      "This method may improve the forecast of infrequent diseases, such as calvarial lesions.\n",
      "4.649695260184152\n",
      " BACKGROUND Clinically, percutaneous vertebroplasty (PVP) is frequently applied to treat osteoporotic vertebral compression fracture (OVCF).\n",
      "4.650355625819493\n",
      "It is believed that new compression fractures are more likely to occur adjacent to the PVP-treated segment, typically within 1 month after PVP.\n",
      "4.6520575028431566\n",
      "The purpose of this study was to investigate risk factors for adjacent vertebral compression fractures (AVCF) after PVP in patients with OVCF after menopause.\n",
      "4.664583310976133\n",
      "MATERIAL AND METHODS Between Jun 2012 and Dec 2016, 412 patients were initially identified.\n",
      "4.684070696149553\n",
      "We enrolled 390 patients in this study, and 22 were lost to follow-up.\n",
      "4.687117847044076\n",
      "The medical records of the patients were retrospectively collected.\n",
      "4.66368697317023\n",
      "Patients were followed up for at least 6 months, with an average follow-up period of 18 months.\n",
      "4.6349148976105505\n",
      "The potential risk factors investigated in this study included age, duration of menopause (DoM), preoperative vertebral compression, number of preoperative vertebral fractures (NPVF), bone mineral density (BMD), surgical approach (unilateral or bilateral), anesthesia methods, bone cement dose, complications (including COPD), and anti-osteoporosis treatment.\n",
      "4.690759546616498\n",
      "Logistic regression analysis was used to determine the risk factors.\n",
      "4.661326688878677\n",
      "RESULTS Sixty-eight patients were observed to have suffered from AVCF after PVP at the last follow-up.\n",
      "4.649251058430015\n",
      "Univariate analysis showed that age, DoM, NPVF, BMD, COPD, and anti-osteoporosis treatment were the potential variables associated with the onset of AVCF (all P<0.05).\n",
      "4.583665691438268\n",
      "Binary logistic regression analysis showed that the logistic regression equation was as follows: logit P=-3.10-1.07×X2+0.99×X3+2.15×X4 (where X2=BMD; X3=DoM; X4=NPVF), and \"logit P\" stands for the likelihood of developing an AVCF following PVP.\n",
      "4.638089573636968\n",
      "CONCLUSIONS A long duration of menopause and preoperative multi-level vertebral fractures were the risk factors for AVCF in patients following PVP after menopause, while a high-level BMD acted in a protective role for AVCF development.\n",
      "4.649832309820713\n",
      " Scratch assays are used to study how a population of cells re-colonises a vacant region on a two-dimensional substrate after a cell monolayer is scratched.\n",
      "4.65635746360844\n",
      "These experiments are used in many applications including drug design for the treatment of cancer and chronic wounds.\n",
      "4.657973780776516\n",
      "To provide insights into the mechanisms that drive scratch assays, solutions of continuum reaction-diffusion models have been calibrated to data from scratch assays.\n",
      "4.64023217657731\n",
      "These models typically include a logistic source term to describe carrying capacity-limited proliferation; however, the choice of using a logistic source term is often made without examining whether it is valid.\n",
      "4.673252435378086\n",
      "Here we study the proliferation of PC-3 prostate cancer cells in a scratch assay.\n",
      "4.64590434155433\n",
      "All experimental results for the scratch assay are compared with equivalent results from a proliferation assay where the cell monolayer is not scratched.\n",
      "4.642053106949793\n",
      "Visual inspection of the time evolution of the cell density away from the location of the scratch reveals a series of sigmoid curves that could be naively calibrated to the solution of the logistic growth model.\n",
      "4.64157535718835\n",
      "However, careful analysis of the per capita growth rate as a function of density reveals several key differences between the proliferation of cells in scratch and proliferation assays.\n",
      "4.6609616960797995\n",
      "Our findings suggest that the logistic growth model is valid for the entire duration of the proliferation assay.\n",
      "4.635616513635839\n",
      "On the other hand, guided by data, we suggest that there are two phases of proliferation in a scratch assay; at short time, we have a disturbance phase where proliferation is not logistic, and this is followed by a growth phase where proliferation appears to be logistic.\n",
      "4.651368267768253\n",
      "These two phases are observed across a large number of experiments performed at different initial cell densities.\n",
      "4.644397673059682\n",
      "Overall our study shows that simply calibrating the solution of a continuum model to a scratch assay might produce misleading parameter estimates, and this issue can be resolved by making a distinction between the disturbance and growth phases.\n",
      "4.643191223144531\n",
      "Repeating our procedure for other scratch assays will provide insight into the roles of the disturbance and growth phases for different cell lines and scratch assays performed on different substrates.\n",
      "4.640668671706627\n",
      " Designing an appropriate tissue engineering solution for craniosynostosis (CS) necessitates determination of whether CS-derived cells differ from normal (wild-type, WT) cells and what assays are appropriate to test for differences.\n",
      "4.644125802176339\n",
      "Traditional methodologies to statistically compare cellular behavior may not accurately reflect biologically relevant differences because they poorly address variation.\n",
      "4.654041431568287\n",
      "Here, logistic regression was used to determine which assays could identify a biological difference between WT and CS progenitor cells.\n",
      "4.647513080116929\n",
      "Quantitative alkaline phosphatase and MTS proliferation assays were performed on adipose, muscle, and bone marrow-derived cells from WT and CS rabbits.\n",
      "4.693129016507056\n",
      "Data were stratified by assay, cell type, and days in culture.\n",
      "4.669239298502604\n",
      "Coefficients of variation were calculated and assay results coded as predictive variables.\n",
      "4.707050524259868\n",
      "Phenotype (WT or CS) was coded as the dependent variable.\n",
      "4.660520704530126\n",
      "Sensitivity-specificity curves, classification tables, and receiver operating characteristic curves were plotted for discriminating models.\n",
      "4.637683778297244\n",
      "Two data sets were utilized for subsequent analyses; one was used to develop the logistic regression models for prediction, and the other independent data set was used to determine the ability to predict group membership based on the predictive equation.\n",
      "4.668337902390813\n",
      "The resulting coefficients of variation were high for all differentiation measures.\n",
      "4.659071363844313\n",
      "Upon model implementation, bone marrow assays were observed to result in 72%-100% predictability for phenotype.\n",
      "4.652584105499031\n",
      "We found predictive differences in our muscle-derived and bone marrow-derived cells suggesting biologically relevant differences.\n",
      "4.638615145228216\n",
      "This data analysis methodology could help identify homogenous cells that do not differ between pathologic and normal individuals or cells that differ in their osteogenic potential, depending on the type of cell-based therapy being developed.\n",
      "4.704804556710379\n",
      " Pediatric sepsis is a burdensome public health problem.\n",
      "4.635314357337769\n",
      "Assessing the mortality risk of pediatric sepsis patients, offering effective treatment guidance, and improving prognosis to reduce mortality rates, are crucial.We extracted data derived from electronic medical records of pediatric sepsis patients that were collected during the first 24 hours after admission to the pediatric intensive care unit (PICU) of the Hunan Children's hospital from January 2012 to June 2014.\n",
      "4.663260904947917\n",
      "A total of 788 children were randomly divided into a training (592, 75%) and validation group (196, 25%).\n",
      "4.6624680122319795\n",
      "The risk factors for mortality among these patients were identified by conducting multivariate logistic regression in the training group.\n",
      "4.6351199637624685\n",
      "Based on the established logistic regression equation, the logit probabilities for all patients (in both groups) were calculated to verify the model's internal and external validities.According to the training group, 6 variables (brain natriuretic peptide, albumin, total bilirubin, D-dimer, lactate levels, and mechanical ventilation in 24 hours) were included in the final logistic regression model.\n",
      "4.6393484818307975\n",
      "The areas under the curves of the model were 0.854 (0.826, 0.881) and 0.844 (0.816, 0.873) in the training and validation groups, respectively.The Mortality Risk Model for Pediatric Sepsis we established in this study showed acceptable accuracy to predict the mortality risk in pediatric sepsis patients.\n",
      "4.660529891304348\n",
      " We aimed to generate equation to predict arterial lactate (a-Lac) using venous lactate (v-Lac) and other lab data.\n",
      "4.650606471181705\n",
      "A prospective cross-sectional study was conducted on emergency patients in the emergency department for 6 months at a general hospital in Tokyo, Japan.\n",
      "4.702129887599571\n",
      "We collected arterial and venous gas analysis data.\n",
      "4.655567443448733\n",
      "Patients were eligible for entry into the study if an arterial blood gas analysis was required for appropriate diagnostic care by the treating physician.\n",
      "4.66353505452474\n",
      "Univariate linear regression analysis was conducted to generate an equation to calculate a-Lac incorporating only v-Lac.\n",
      "4.643729570616094\n",
      "A multivariate forward stepwise logistic regression model (p-value of 0.05 for entry, 0.1 for removal) was used to generate an equation including v-Lac and other potentially relevant variables.\n",
      "4.666543454540019\n",
      "Bland-Altman plot was drawn and the two equations were compared for model fitting using R-squares.\n",
      "4.657179398970171\n",
      "Seventy-two arterial samples from 72 participants (61% male; mean age, 58.2 years) were included in the study.\n",
      "4.624471524866616\n",
      "An initial regression equation was derived from univariate linear regression analysis:\"(a-Lac) = -0.259 + (v-Lac) × 0.996\".\n",
      "4.6002197265625\n",
      "Subsequent multivariate forward stepwise logistic regression analysis, incorporating v-Lac and Po2, generated the following equation:\"(a-Lac) = -0.469+(venous Po2) × 0.005 + (v-Lac) × 0.997\".\n",
      "4.666295138272372\n",
      "Calculated R-squares by single and multiple regression were 0.94 and 0.96, respectively.\n",
      "4.64763676725476\n",
      "v-Lac estimates showed a high correlation with arterial values and our data provide two clinically useful equations to calculate a-Lac from v-Lac data.\n",
      "4.625983055601728\n",
      "Considering clinical flexibility, \"Lac = -0.259 + v-Lac × 0.996\" might be more useful while avoiding a time-consuming and invasive procedure.\n",
      "4.694611065204327\n",
      " Sex estimation is an integral aspect of biological anthropology.\n",
      "4.659792040215164\n",
      "Correctly estimating sex is the first step to many subsequent analyses, such as estimating living stature or age-at-death.\n",
      "4.939147362342248\n",
      "Klales et al.\n",
      "4.640609526298415\n",
      "(2012) [6] provided a revised version of the Phenice (1969) [3] method that expanded the original three traits (ventral arc, subpubic concavity/contour, and medial aspect of the ischio-pubic ramus) into five character states to capture varying degrees of expression within each trait.\n",
      "4.868315752814798\n",
      "The Klales et al.\n",
      "4.656162209706764\n",
      "(2012) [6] method also provided associated probabilities with each sex classification, which is of particular importance in forensic anthropology.\n",
      "4.647356652266143\n",
      "However, the external validity of this method must be tested prior to applying the method to different populations from which the method was developed.\n",
      "4.678503965720152\n",
      "A total of 1915 innominates from four diverse geographic populations: (1) U.S.\n",
      "4.647755940755208\n",
      "Blacks and Whites; (2) South African Blacks and Whites; (3) Thai; and (4) unidentified Hispanic border crossers were scored in accordance with Klales et al.\n",
      "5.006755135276101\n",
      "(2012) [6].\n",
      "4.666794680477528\n",
      "Trait scores for each innominate were entered into the equation provided by Klales et al.\n",
      "4.730604771205357\n",
      "(2012) [6] for external validation.\n",
      "4.651515080378606\n",
      "Additionally, recalibration equations were calculated with logistic regression for each population and for a pooled global sample.\n",
      "4.651283869667659\n",
      "Validation accuracies ranged from 87.5% to 95.6% and recalibration equation accuracies ranged from 89.6% to 98% total correct.\n",
      "4.724639198996804\n",
      "Pooling all samples and using Klales' et al.\n",
      "4.6793060302734375\n",
      "(2012) [6] equations achieved an overall validation accuracy of 93.5%.\n",
      "4.642378098893873\n",
      "The global recalibration model achieved 95.9% classification accuracy and can be employed in diverse worldwide populations for accurate sex estimation without the need for population specific equations.\n",
      "4.674560546875\n",
      " To develop and validate an empirical equation to screen for diabetes.\n",
      "4.651123438126001\n",
      "A predictive equation was developed using multiple logistic regression analysis and data collected from 1,032 Egyptian subjects with no history of diabetes.\n",
      "4.63879082862367\n",
      "The equation incorporated age, sex, BMI, postprandial time (self-reported number of hours since last food or drink other than water), and random capillary plasma glucose as independent covariates for prediction of undiagnosed diabetes.\n",
      "4.6476703718596815\n",
      "These covariates were based on a fasting plasma glucose level >/=126 mg/dl and/or a plasma glucose level 2 h after a 75-g oral glucose load >/=200 mg/dl.\n",
      "4.659948610791973\n",
      "The equation was validated using data collected from an independent sample of 1,065 American subjects.\n",
      "4.651692867279053\n",
      "Its performance was also compared with that of recommended and proposed static plasma glucose cut points for diabetes screening.\n",
      "4.634745922423246\n",
      "The predictive equation was calculated with the following logistic regression parameters: P = 1/(1 - e(-x)), where x = -10.0382 + [0.0331 (age in years) + 0.0308 (random plasma glucose in mg/dl) + 0.2500 (postprandial time assessed as 0 to >/=8 h) + 0.5620 (if female) + 0.0346 (BMI)].\n",
      "4.659289110888232\n",
      "The cut point for the prediction of previously undiagnosed diabetes was defined as a probability value >/=0.20.\n",
      "4.678654496387769\n",
      "The equation's sensitivity was 65%, specificity 96%, and positive predictive value (PPV) 67%.\n",
      "4.66885408100329\n",
      "When applied to a new sample, the equation's sensitivity was 62%, specificity 96%, and PPV 63%.\n",
      "4.637804103196914\n",
      "This multivariate logistic equation improves on currently recommended methods of screening for undiagnosed diabetes and can be easily implemented in a inexpensive handheld programmable calculator to predict previously undiagnosed diabetes.\n",
      "4.666586739676339\n",
      " To develop a multivariate prediction model for in-hospital mortality following aortic valve replacement.\n",
      "4.647451971883828\n",
      "Retrospective analysis of prospectively collected data on 4550 consecutive patients undergoing aortic valve replacement between 1 April 1997 and 31 March 2004 at four hospitals.\n",
      "4.653189143779115\n",
      "A multivariate logistic regression analysis was undertaken, using the forward stepwise technique, to identify independent risk factors for in-hospital mortality.\n",
      "4.656675707392332\n",
      "The area under the receiver operating characteristic (ROC) curve was calculated to assess the performance of the model.\n",
      "4.64506722538849\n",
      "The statistical model was internally validated using the technique of bootstrap resampling, which involved creating 100 random samples, with replacement, of 70% of the entire dataset.\n",
      "4.649418611704193\n",
      "The model was also validated on 816 consecutive patients undergoing aortic valve replacement between 1 April 2004 and 31 March 2005 from the same four hospitals.\n",
      "4.6994778817160086\n",
      "Two hundred and seven (4.6%) in-hospital deaths occurred.\n",
      "4.623736922148686\n",
      "Independent variables identified with in-hospital mortality are shown with relevant co-efficient values and p-values as follows: (1) age 70-75 years: 0.7046, p<0.001; (2) age 75-85 years: 1.1714, p<0.001; (3) age>85 years: 2.0339, p<0.001; (4) renal dysfunction: 1.2307, p<0.001; (5) New York Heart Association class IV: 0.5782, p=0.003; (6) hypertension: 0.4203, p=0.006; (7) atrial fibrillation: 0.604, p=0.002; (8) ejection fraction<30%: 0.571, p=0.012; (9) previous cardiac surgery: 0.9193, p<0.001; (10) non-elective surgery: 0.5735, p<0.001; (11) cardiogenic shock: 1.1291, p=0.009; (12) concomitant CABG: 0.6436, p<0.001.\n",
      "4.853640907689145\n",
      "Intercept: -4.8092.\n",
      "4.712182726178851\n",
      "A simplified additive scoring system was also developed.\n",
      "4.699774363684276\n",
      "The ROC curve was 0.78, indicating a good discrimination power.\n",
      "4.654215166645665\n",
      "Bootstrapping demonstrated that estimates were stable with an average ROC curve of 0.76, with a standard deviation of 0.025.\n",
      "4.647217266376202\n",
      "Validation on 2004-2005 data revealed a ROC curve of 0.78 and an expected mortality of 4.7% compared to the observed rate of 4.1%.\n",
      "4.661620093173668\n",
      "We developed a contemporaneous multivariate prediction model for in-hospital mortality following aortic valve replacement.\n",
      "4.652862916509789\n",
      "This tool can be used in day-to-day practice to calculate patient-specific risk by the logistic equation or a simple scoring system with an equivalent predicted risk.\n",
      "4.645895240420387\n",
      " The primary goal of tailored medicine is to presymptomatically identify individuals at high risk for disease using information of each individual's genetic profile and collection of environmental risk factors.\n",
      "4.6467030035755625\n",
      "Recently, algorithms were given the strong recognition of several replicated risk factors for age-related macular degeneration (AMD), this distant goal is beginning to seem less mysterious.\n",
      "4.685751971076517\n",
      "The purpose of the study was to develop a statistical model for AMD.\n",
      "4.7324699988731975\n",
      "This study includes total 106 subjects.\n",
      "4.662959831805269\n",
      "To identify the risk of earlier diagnosis of suspected AMD patients, 22 independent variables were included in the study.\n",
      "4.662335512449416\n",
      "Forward stepwise (likelihood ratio) binary logistic regression has been used to find significant variables associated with the risk of AMD.\n",
      "4.673426156092172\n",
      "Prediction equation, based on significant risk factors, and model authenticity have been developed.\n",
      "4.622042278910792\n",
      "Hosmer-Lemeshow goodness of fit statistic (χ(2)=0.143, df=8, p=1.0), which is nonsignificant, indicates the appropriateness of the logistic regression model to predict AMD.\n",
      "4.632268905639648\n",
      "After going through stepwise logistic regression, only 6 variables out of the 22 independent variables, namely, serum complement factor H (CFH), serum chemokine (C-C motif) ligand 2 (CCL2), serum superoxide dismutase 1 (SOD1), polymorphism in CCL2 (rs4586), stress, and comorbidity were found to be significant (p<0.05).\n",
      "4.635827966638513\n",
      "The binary logistic regression model is an appropriate tool to predict AMD in the presence of serum CFH, serum CCL2, serum SOD1, polymorphism in CCL2 (rs4586), stress, and comorbidity with high specificity and sensitivity.\n",
      "4.639459783380682\n",
      "The area under the receiver operating characteristic curve (0.909, p=0.001) with less standard error of 0.034 and close 95% confidence intervals (0.842-0.976) further validates the model.\n",
      "4.65201416015625\n",
      " To explore the influencing factors of elderly outpatient visits and to provide evidence for poverty reduction in health in the poor rural areas.\n",
      "4.644913873752626\n",
      "Through stratified sampling, a total of 1 271 aged people in four poverty Qi/County of Ulanqabcity were surveyed, including Qahar Right Wing Front Banner, Qahar Right Wing Middle Banner, Qahar Right Wing Rear Banner and Liangcheng County.\n",
      "4.623096251755618\n",
      "Their socioeconomic and demographic characteristics, daily consumption, EuroQol five dimensions questionnaire(EQ-5D) and visual analogue scale (VAS),social support, health service needs and utilization were collected through cross-sectional household questionnaires.\n",
      "4.653339967889301\n",
      "1 039 aged people who had experienced physical discomfort in the past 30 days were selected as subjects for the study.\n",
      "4.680493971880744\n",
      "The differences between the groups were analyzed by chi-square test.\n",
      "4.624274758731618\n",
      "A Logistic regression equation and a decision tree of elderly visits were built to find factors influencing decisionmaking of the aged.\n",
      "4.651946521196209\n",
      "The average age of the research subjects was 71.8 years, with 52.2% being illiterate and 85.8% with middle social support.\n",
      "4.655514569349692\n",
      "58.5% of the subjects living with their spouses, mostly living in 15 min medical circle and without any financial support from their children.\n",
      "4.700154318738339\n",
      "The 30-day visiting rate when having physical discomfort was 31.0%.\n",
      "4.636416976178278\n",
      "The chi-square test showed that the differences in visit rates among age, ethnic, residence patterns, daily consumption index, housing types, social support scores, grown children's economic assistance, travel time to medical institutions, and health self-assessment scores were statistically significant.\n",
      "4.670801962575605\n",
      "Compared with Logistic analysis, the decision tree showed lower error rate of classification.\n",
      "4.634959883072051\n",
      "Logistic regression model's error rate of classification was 31.4%, showing that the differences in visit rates among age, ethnic, residence patterns, daily consumption index, social support scores, travel time to medical institutions, and health self-assessment scores were statistically significant.\n",
      "4.644586019189639\n",
      "The decision tree model's error rate of classification was 28.6%, showing six main influencing factors, including the travel time to medical institutions, cohabitants, education level, age, whether adult children provide economic support and social support score.\n",
      "4.668511763862941\n",
      "The importance of these predictors were 0.42, 0.21, 0.13, 0.11, 0.07 and 0.06, respectively.\n",
      "4.6476757539717175\n",
      "In poor rural areas, medical resources, economic affordability, family and individual socio-demographic characteristics are the key factors affecting decision-making for the aged.\n",
      "4.656904602050782\n",
      "It is necessary to integrate the improvement of the health care of the aged into the overall development of the society.\n",
      "4.668695955194979\n",
      "And comprehensive interventions should be adopted to improve the outpatient utilization for aged in poor rural areas.\n",
      "4.654566838191106\n",
      " Polycyclic aromatic hydrocarbons (PAHs) are potent atmospheric pollutants produced by incomplete combustion of organic materials.\n",
      "4.6440026324728265\n",
      "Pre-clinical and occupational studies have reported a positive association of PAHs with oxidative stress, inflammation and subsequent development of atherosclerosis, a major underlying risk factor for cardiovascular disease (CVD).\n",
      "4.641345656061747\n",
      "The aim of the current study is to estimate the association between levels of PAH biomarkers and CVD in a national representative sample of United States (US) adults.\n",
      "4.623255932424951\n",
      "We examined adult participants (≥20years of age) from the merged US National Health and Nutrition Examination Survey 2001-2010.\n",
      "4.663270803598257\n",
      "Logistic regression models were used to estimate the associations of each urinary PAH biomarker and CVD.\n",
      "4.641292747007597\n",
      "Post-exploratory structural equation modeling was then used to address the interdependent response variables (angina, heart attack, stroke and coronary heart disease) as well as the interdependencies of PAH biomarkers.\n",
      "4.647415617982785\n",
      "PAH biomarkers were positively associated with cardiovascular disease in multiple logistic regression models, although some associations were not statistically robust.\n",
      "4.619173916903409\n",
      "Using structural equation modeling, latent PAH exposure variable was positively associated with latent CVD level variable in the multivariable adjusted model (β=0.12; 95% CI: 0.03, 0.20).\n",
      "4.662790818647905\n",
      "A modest association between levels of PAH biomarkers and CVD was detected in US adults.\n",
      "4.6636965912167385\n",
      "Further prospective studies with adequate sample size are needed to replicate or refute our findings.\n",
      "4.637794179364669\n",
      " The purpose of our study was to estimate the future incidence rate (IR) and volume of primary total knee arthroplasty (TKA) in the United States from 2015 to 2050 using a conservative projection model that assumes a maximum IR of procedures.\n",
      "4.652644716460129\n",
      "Furthermore, our study compared these projections to a model assuming exponential growth, as done in previous studies, for illustrative purposes.\n",
      "4.656232280115927\n",
      "A population based epidemiological study was conducted using data from US National Inpatient Sample (NIS) and Census Bureau.\n",
      "4.670917349801937\n",
      "Primary TKA procedures performed between 1993 and 2012 were identified.\n",
      "4.643789672851563\n",
      "The IR, 95% confidence intervals (CI), or prediction intervals (PI) of TKA per 100,000 US citizens over the age of 40 years were calculated.\n",
      "4.64709964875252\n",
      "The estimated IR was used as the outcome of a regression modelling with a logistic regression (i.e., conservative model) and Poisson regression equation (i.e., exponential growth model).\n",
      "4.641638630971858\n",
      "Logistic regression modelling suggests the IR of TKA is expected to increase 69% by 2050 compared to 2012, from 429 (95%CI 374-453) procedures/100,000 in 2012 to 725 (95%PI 121-1041) in 2050.\n",
      "4.695689216988986\n",
      "This translates into a 143% projected increase in TKA volume.\n",
      "4.644130872643513\n",
      "Using the Poisson model, the IR in 2050 was projected to increase 565%, to 2854 (95%CI 2278-4004) procedures/100,000 IR, which is an 855% projected increase in volume compared to 2012.\n",
      "4.647419706304023\n",
      "Even after using a conservative projection approach, the number of TKAs in the US, which already has the highest IR of knee arthroplasty in the world, is expected to increase 143% by 2050.\n",
      "4.656812693974743\n",
      " The need for mechanical ventilation (MV) in acute bronchiolitis (AB) by respiratory syncytial virus (RSV) varies depending on the series (6-18%).\n",
      "4.651629638671875\n",
      "Our goal is to determine the admissions to PICU for MV in patients under 6 months with AB and define the risk factors for building a prediction model.\n",
      "4.656344491464121\n",
      "Retrospective study of patients younger than 6 months admitted by BA-VRS between the periods April 1, 2010 and March 31, 2015 was made.\n",
      "4.710727267795139\n",
      "The primary variable was the admission to PICU for MV.\n",
      "4.660743044133772\n",
      "Related addition, to find risk factors in a model of binary logistic regression clinical variables were collected.\n",
      "4.680439843071832\n",
      "A ROC curve model was developed and optimal cutoff point was identified.\n",
      "4.691852634235964\n",
      "In 695 cases, the need of MV in the PICU (Y) was 56 (8.1%).\n",
      "4.661800420851934\n",
      "Risk factors (Xi) included in the equation were: 1. male sex (OR 4.27) 2. postmenstrual age (OR: 0.76) 3.\n",
      "4.674329020182292\n",
      "Weight income less than p3 (OR: 5.53) 4. intake lees than 50% (OR: 12.4) 5.\n",
      "4.639471163415605\n",
      "Severity by scale (OR: 1.58) 6. apneas before admission (OR: 25.5) 7. bacterial superinfection (OR 5.03) and 8. gestational age more than 37 weeks OR (0.32).\n",
      "4.669097244098622\n",
      "The area under the curve, sensitivity and specificity were 0.943, 0.84 and 0.93 respectively.\n",
      "4.665146537449049\n",
      "The PICU admission for MV was 8.1 in every 100 healthy infants hospitalized for AB and year.\n",
      "4.664584759584407\n",
      "The prediction model equation can help to predict patients at increased risk of severe evolution.\n",
      "4.646037746120143\n",
      " The standard model for the dynamics of a fragmented density-dependent population is built from several local logistic models coupled by migrations.\n",
      "4.652390252976191\n",
      "First introduced in the 1970s and used in innumerable articles, this standard model applied to a two-patch situation has never been fully analyzed.\n",
      "4.643115301817161\n",
      "Here, we complete this analysis and we delineate the conditions under which fragmentation associated with dispersal is either favorable or unfavorable to total population abundance.\n",
      "4.651012361358484\n",
      "We pay special attention to the case of asymmetric dispersal, i.e., the situation in which the dispersal rate from patch 1 to patch 2 is not equal to the dispersal rate from patch 2 to patch 1.\n",
      "4.673694728576031\n",
      "We show that this asymmetry can have a crucial quantitative influence on the effect of dispersal.\n",
      "4.659562037541316\n",
      " Black individuals are far more likely than white individuals to develop end stage renal disease (ESRD).\n",
      "4.658399669402236\n",
      "However, earlier stages of chronic kidney disease (CKD) have been reported to be less prevalent among blacks.\n",
      "4.739071729706555\n",
      "This disparity remains poorly understood.\n",
      "4.635299504499027\n",
      "The objective of this study was to evaluate whether the lower prevalence of CKD among blacks in early stages of CKD might be due in part to an inability of the MDRD equation to accurately determine early stages of CKD in both the black and white population.\n",
      "4.632816995507259\n",
      "We conducted a retrospective cohort study of 97, 451 patients seen in primary care clinic in Veterans Integrated Service Network 2 (VISN 2) over a 7 year period to determine the prevalence of CKD using both the Modification of Diet in Renal Disease (MDRD) Study equation and the more recently developed CKD Epidemiology Collaboration (CKD-EPI) equation.\n",
      "4.66598450903799\n",
      "Demographic data, comorbid conditions, prescription of medications, and laboratory data were recorded.\n",
      "4.6435583968188885\n",
      "Logistic regression and quantile regression models were used to compare the prevalence of estimated glomerular filtration rate (eGFR) categories between black and white individuals.\n",
      "4.67772216796875\n",
      "The overall prevalence of CKD was lower when the CKD-EPI equation was used.\n",
      "4.647754414876302\n",
      "Prevalence of CKD in whites was 53.2% by MDRD and 48.4% by CKD-EPI, versus 34.1% by MDRD and 34.5% by CKD-EPI in blacks.\n",
      "4.636360875571646\n",
      "The cumulative logistic regression and quantile regression showed that when eGFR was calculated by the EPI method, blacks were as likely to present with an eGFR value less than 60 mL/min/1.73 m2 as whites.\n",
      "4.665201532273065\n",
      "Using the CKD-EPI equation, blacks were more likely than white individuals to have stage 3b, 4 and 5 CKD.\n",
      "4.661287213316058\n",
      "Using the MDRD method, the prevalence in blacks was only higher than in whites for stage 4 and 5 CKD.\n",
      "4.66666331189744\n",
      "Similar results were obtained when the analysis was confined to patients over 65 years of age.\n",
      "4.645904743118791\n",
      "The MDRD equation overestimates the prevalence of CKD among whites and underestimates the prevalence of CKD in blacks compared to the CKD-EPI equation.\n",
      "4.607019295964216\n",
      " A Box-Behnken design was used to determine the effect of protein concentration (0, 5, or 10g of casein/100g), fat (0, 3, or 6g of corn oil/100g), a<sub>w</sub> (0.900, 0.945, or 0.990), pH (3.5, 5.0, or 6.5), concentration of cinnamon essential oil (CEO, 0, 200, or 400μL/kg) and incubation temperature (15, 25, or 35°C) on the growth of Aspergillus flavus during 50days of incubation.\n",
      "4.65694865774601\n",
      "Mold response under the evaluated conditions was modeled by the modified Gompertz equation, logistic regression, and time-to-detection model.\n",
      "4.637948665978773\n",
      "The obtained polynomial regression models allow the significant coefficients (p<0.05) for linear, quadratic and interaction effects for the Gompertz equation's parameters to be identified, which adequately described (R<sup>2</sup>>0.967) the studied mold responses.\n",
      "4.63745232711455\n",
      "After 50days of incubation, every tested model system was classified according to the observed response as 1 (growth) or 0 (no growth), then a binary logistic regression was utilized to model A. flavus growth interface, allowing to predict the probability of mold growth under selected combinations of tested factors.\n",
      "4.669952985152458\n",
      "The time-to-detection model was utilized to estimate the time at which A. flavus visible growth begins.\n",
      "4.667384637850467\n",
      "Water activity, temperature, and CEO concentration were the most important factors affecting fungal growth.\n",
      "4.636923623251748\n",
      "It was observed that there is a range of possible combinations that may induce growth, such that incubation conditions and the amount of essential oil necessary for fungal growth inhibition strongly depend on protein and fat concentrations as well as on the pH of studied model systems.\n",
      "4.641747398714049\n",
      "The probabilistic model and the time-to-detection models constitute another option to determine appropriate storage/processing conditions and accurately predict the probability and/or the time at which A. flavus growth occurs.\n",
      "4.655377534269555\n",
      " Aging worsens outcome in traumatic brain injury (TBI), but available studies may not provide accurate outcomes predictions due to confounding associated injuries.\n",
      "4.65709976688508\n",
      "Our goal was to develop a predictive tool using variables available at admission to predict outcomes related to severity of brain injury in aging patients.\n",
      "4.651557303763725\n",
      "Characteristics and outcomes of blunt trauma patients, aged 50 or older, with isolated TBI, in the National Trauma Data Bank (NTDB), were evaluated.\n",
      "4.651498568260063\n",
      "Equations predicting survival and independence at discharge (IDC) were developed and validated using patients from our trauma registry, comparing predicted with actual outcomes.\n",
      "4.6515606649560866\n",
      "Logistic regression for survival and IDC was performed in 57,588 patients using age, sex, Glasgow Coma Scale score (GCS), and Revised Trauma Score (RTS).\n",
      "4.7076004316221995\n",
      "All variables were independent predictors of outcome.\n",
      "4.727562128111374\n",
      "Two models were developed using these data.\n",
      "4.748664237357475\n",
      "The first included age, sex, and GCS.\n",
      "4.756594412667411\n",
      "The second substituted RTS for GCS.\n",
      "4.66860536087391\n",
      "C statistics from the models for survival and IDC were 0.90 and 0.82 in the GCS model.\n",
      "4.704551086425782\n",
      "In the RTS model, C statistics were 0.80 and 0.67.\n",
      "4.6721758674172795\n",
      "The use of GCS provided better discrimination and was chosen for further examination.\n",
      "4.645252692005622\n",
      "Using a predictive equation derived from the logistic regression model, outcome probabilities were calculated for 894 similar patients from our trauma registry (January 2012 to March 2016).\n",
      "4.677859966571514\n",
      "The survival and IDC models both showed excellent discrimination (p < 0.0001).\n",
      "4.635613098144531\n",
      "Survival and IDC generally decreased by decade: age 50 to 59 (80% IDC, 6.5% mortality), 60 to 69 (82% IDC, 7.0% mortality), 70 to 79 (76% IDC, 8.9% mortality), and 80 to 89 (67% IDC, 13.4% mortality).\n",
      "4.671324786017923\n",
      "These models can assist in predicting the probability of survival and IDC for aging patients with TBI.\n",
      "4.6674927421238115\n",
      "This provides important data for loved ones of these patients when addressing goals of care.\n",
      "4.636775735430243\n",
      " To explore the application of the generalized estimating equation in the ordinal repeated measures data and hence provide methodology reference for the analysis of repeated measures data in the clinical trials.\n",
      "4.651970667554843\n",
      "An example was illustrated by modeling generalized estimating equation using the GENMOD command in comparison with the independent logistic regression.\n",
      "4.651366218687996\n",
      "All parameters and their standard error were estimated, so every factor could be dealt with intuitive estimation of parameter.\n",
      "4.6503247247226\n",
      "The standard errors of coefficients in generalized estimating equation are generally greater than that in independent logistic regression.\n",
      "4.632291127400226\n",
      "Generalized estimating equation can solve the correlation between the dependent data by using working correlation matrix, and it can control strata correlation, repeated measures factor and other confounding factors effectively, so generalized estimating equation provides an effective method for the ordinal repeated measures data.\n",
      "4.64575933412064\n",
      " Previous risk prediction models of mortality after ruptured abdominal aortic aneurysm (rAAA) repair have been limited by imprecision, complexity, or inclusion of variables not available in the preoperative setting.\n",
      "4.64604546613754\n",
      "Most importantly, these prediction models have been derived and validated before the adoption of endovascular aneurysm repair (EVAR) as a treatment for rAAA.\n",
      "4.648325497342139\n",
      "We sought to derive and validate a new risk-prediction tool using only easily obtainable preoperative variables in patients with rAAA who are being considered for repair in the endovascular era.\n",
      "4.659175028327767\n",
      "We used the Vascular Study Group of New England (VSGNE) database to identify all patients who underwent repair of RAAA (2006-2015).\n",
      "4.65690869140625\n",
      "Variables were entered into a multivariable logistic regression model to identify independent predictors of 30-day mortality.\n",
      "4.671882042518029\n",
      "Linear regression was then used to develop an equation to predict risk of 30-day mortality.\n",
      "4.644820952079665\n",
      "During the study period, 649 patients underwent repair of rAAA; of these, 247 (38.1%) underwent EVAR and 402 (61.9%) underwent an open repair.\n",
      "4.669515219079443\n",
      "The overall mortality associated with rAAA was 30.7% (open, 33.4% and EVAR, 26.2%).\n",
      "4.4180238305068595\n",
      "On multivariate modeling, the primary determinants of 30-day mortality were advanced age (>76 vs. ≤76 years, odds ratio [OR] = 2.91 and CI: 2.0-4.24), elevated creatinine (>1.5 mg/dL vs. ≤1.5 mg/dL, OR = 1.57 and CI: 1.05-2.34), and lowest systolic blood pressure (SBP) (BP <70 mm Hg vs. ≥70 mm Hg, OR = 2.65 and CI: 1.79-3.92).\n",
      "4.682588413783482\n",
      "The logistic regression model had an area under a c-statistic of 0.69.\n",
      "4.6347487624343096\n",
      "The corresponding linear model used to provide a point estimate of 30-day mortality (%) was % mortality = 14 + 22 * (age >76) + 9 * (creatinine >1.5) + 20 * (bp <70) Using this model, patients can be stratified into different groups, each with a specific estimated risk of 30-day mortality ranging from a low of 14% to a high of 65%.\n",
      "4.63449528902897\n",
      "In the endovascular era where both open and endovascular treatment are offered for the treatment of rAAA three variables, easily obtained in an emergency setting, accurately predict 30-day mortality for patients operated on for rAAA.\n",
      "4.647742158623152\n",
      "This simple risk prediction tool could be used as a point of care decision aid to help the clinician in counseling patients and their families on treatment of those presenting with rAAA.\n",
      "4.641680178434952\n",
      " The aim of this study was to create a model to predict the implantation of transferred embryos based on information contained in the morphokinetic parameters of time-lapse monitoring.\n",
      "4.647603049207089\n",
      "An analysis of time-lapse recordings of 410 embryos transferred in 343 cycles of in vitro fertilization (IVF) treatment was performed.\n",
      "4.6908421834309895\n",
      "The study was conducted between June 2012 and November 2014.\n",
      "4.637093708647191\n",
      "For each embryo, the following data were collected: the duration of time from the intracytoplasmic sperm injection (ICSI) procedure to further division for two, three, four, and five blastomeres, time intervals between successive divisions, and the level of fragmentation assessed in successive time-points.\n",
      "4.667710596201371\n",
      "Principal component analysis (PCA) and logistic regression were used to create a predictive model.\n",
      "4.65885400390625\n",
      "Based on the results of principal component analysis and logistic regression analysis, a predictive equation was constructed.\n",
      "4.525283871494772\n",
      "Statistically significant differences (p < 0.001) in the size of the created parameter between the implanted group (the median value: Me = -5.18 and quartiles: Q 1= -5.61; Q 3 = -4.79) and the non-implanted group (Me = -5.69, Q 1 = -6.34; Q 3 = -5.16) were found.\n",
      "4.660595079408075\n",
      "A receiver operating characteristic (ROC) curve constructed for the considered model showed the good quality of this predictive equation.\n",
      "4.660297393798828\n",
      "The area under the ROC curve was AUC = 0.70 with a 95% confidence interval (0.64, 0.75).\n",
      "4.654757140112705\n",
      "The presented model has been validated on an independent data set, illustrating that the model is reliable and repeatable.\n",
      "4.665536755713347\n",
      "Morphokinetic parameters contain information useful in the process of creating pregnancy prediction models.\n",
      "4.640894975611772\n",
      "However, embryo quality is not the only factor responsible for implantation, and, thus, the power of prediction of the considered model is not as high as in models for blastocyst formation.\n",
      "4.645688278610642\n",
      "Nevertheless, as illustrated by the results of this study, the application of advanced data-mining methods in reproductive medicine allows one to create more accurate and useful models.\n",
      "4.658096036044034\n",
      " This study describes a novel pediatric upper limb motion index (PULMI) for children with cerebral palsy (CP).\n",
      "4.655912611219618\n",
      "The PULMI is based on three-dimensional kinematics and provides quantitative information about upper limb motion during the Reach & Grasp Cycle.\n",
      "4.665047607421875\n",
      "We also report key temporal-spatial parameters for children with spastic, dyskinetic, and ataxic CP.\n",
      "4.59958001999628\n",
      "Participants included 30 typically-developing (TD) children (age=10.9±4.1 years) and 25 children with CP and upper limb involvement (age=12.3±3.7 years), Manual Ability Classification System (MACS) levels I-IV.\n",
      "4.620429790839947\n",
      "The PULMI is calculated from the root-mean-square difference for eight kinematic variables between each child with CP and the average TD values, and scaled such that the TD PULMI is 100±10.\n",
      "4.658758040961869\n",
      "The PULMI was significantly lower among children with CP compared to TD children (Wilcoxon Z=-5.06, p<.0001).\n",
      "4.6585339997944075\n",
      "PULMI scores were significantly lower among children with dyskinetic CP compared to spastic CP (Z=-2.47, p<.0135).\n",
      "4.655253092447917\n",
      "There was a strong negative correlation between PULMI and MACS among children with CP (Spearman's rho=-.78, p<.0001).\n",
      "4.629700796944754\n",
      "Temporal-spatial values were significantly different between CP and TD children: movement time (Z=4.06, p<.0001), index of curvature during reach (Z=3.68, p=.0002), number of movement units (Z=3.72, p=.0002), angular velocity of elbow extension during reach (Z=-3.96, p<.0001), and transport(1):reach peak velocities (Z=-2.48, p=.0129).\n",
      "4.642643049651501\n",
      "A logistic regression of four temporal-spatial parameters, the Pediatric Upper Limb Temporal-Spatial Equation (PULTSE), correctly predicted 19/22 movement disorder subtypes (spastic versus dyskinetic CP).\n",
      "4.6454700816761365\n",
      "The PULMI, PULTSE, and key temporal-spatial parameters of the Reach & Grasp Cycle offer a quantitative approach to analyzing upper limb function in children with CP.\n",
      "4.654141909116275\n",
      " Allometric scalings and a logistic equation assume that whole-plant photosynthetic rate under resource-unlimited conditions is proportional to leaf area.\n",
      "4.689098182091346\n",
      "We tested this proportionality for the herb Helianthus tuberosus.\n",
      "4.650096033349891\n",
      "During growth, we repeatedly measured the percentage of leaves with high, medium, and low photosynthetic capacity to estimate the whole-plant sum of photosynthetic capacity.\n",
      "4.648092416616587\n",
      "We found that the whole-plant sum of the light-saturated photosynthetic rate of leaves is proportional to the whole-plant leaf area, disregarding the dynamics of the leaf population.\n",
      "4.64971923828125\n",
      "We also found that the daily photosynthesis of each leaf appeared as a linear function of the light-saturated photosynthetic rate of that leaf, as predicted by the optimization theory.\n",
      "4.645503373579546\n",
      "Using those results, we expressed whole-plant photosynthetic rate as a product of the light-saturated whole-plant photosynthetic rate and an efficiency index that reflects resource limitation as in the logistic equation.\n",
      "4.677868124879437\n",
      "This efficiency decreased with increasing leaf area, reflecting light limitation.\n",
      "4.672612807329963\n",
      "Therefore, realized whole-plant photosynthetic rate is not proportional to leaf area.\n",
      "4.667054363500292\n",
      "These \"diminishing returns\" are well explained by a simple saturating curve, such as the logistic equation.\n",
      "4.6374969482421875\n",
      " Many regression analyses involve explanatory variables that are measured with error, and failing to account for this error is well known to lead to biased point and interval estimates of the regression coefficients.\n",
      "4.675363030232174\n",
      "We present here a new general method for adjusting for covariate error.\n",
      "4.645648102262127\n",
      "Our method consists of an approximate version of the Stefanski-Nakamura corrected score approach, using the method of regularization to obtain an approximate solution of the relevant integral equation.\n",
      "4.64974650930851\n",
      "We develop the theory in the setting of classical likelihood models; this setting covers, for example, linear regression, nonlinear regression, logistic regression, and Poisson regression.\n",
      "4.645363987082302\n",
      "The method is extremely general in terms of the types of measurement error models covered, and is a functional method in the sense of not involving assumptions on the distribution of the true covariate.\n",
      "4.656337841137035\n",
      "We discuss the theoretical properties of the method and present simulation results in the logistic regression setting (univariate and multivariate).\n",
      "4.644131316441923\n",
      "For illustration, we apply the method to data from the Harvard Nurses' Health Study concerning the relationship between physical activity and breast cancer mortality in the period following a diagnosis of breast cancer.\n"
     ]
    }
   ],
   "source": [
    "reuters_model.eval()\n",
    "THRESHOLD =  1.8332151545300774 * 2\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in reuters_dataset.char2index\n",
    "    )\n",
    "\n",
    "# get the top N stuff\n",
    "\n",
    "# \n",
    "for line in training_examples:\n",
    "    \n",
    "    example_loss = get_loss_on_line(eval_model, unicodeToAscii(line))/len(line )\n",
    "    print(example_loss)\n",
    "\n",
    "    if (example_loss > THRESHOLD):\n",
    "        print(line)\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# some more powerful model: uses LSTM as well as additional fields and operators!\n",
    "# ok, so now let us just iterate the text file\n",
    "# with open(os.path.join(\"data\",\"test-cases.txt\"), \"r\") as file:\n",
    "#     for line in file:\n",
    "#         example_loss = get_loss_on_line(eval_model, line)/len(line )\n",
    "#         if (example_loss > THRESHOLD):\n",
    "#             print(Fore.RED + line)\n",
    "#         else:\n",
    "#             print(Fore.BLUE + line)\n",
    "        \n",
    "#         print(\"loss\" + str(example_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
